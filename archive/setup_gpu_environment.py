#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPUç¯å¢ƒè®¾ç½®è„šæœ¬ - å¸®åŠ©é…ç½®GPUè®­ç»ƒç¯å¢ƒ
"""

import torch
import subprocess
import sys
import os

def check_cuda_installation():
    """æ£€æŸ¥CUDAå®‰è£…æƒ…å†µ"""
    print("=" * 60)
    print("CUDAå®‰è£…æ£€æŸ¥")
    print("=" * 60)
    
    try:
        # æ£€æŸ¥nvidia-smiå‘½ä»¤
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIAé©±åŠ¨å·²å®‰è£…")
            print("GPUä¿¡æ¯:")
            print(result.stdout)
            return True
        else:
            print("âŒ nvidia-smiå‘½ä»¤å¤±è´¥")
            return False
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ°nvidia-smiå‘½ä»¤")
        print("è¯·å®‰è£…NVIDIAé©±åŠ¨ç¨‹åº")
        return False

def check_pytorch_cuda():
    """æ£€æŸ¥PyTorch CUDAæ”¯æŒ"""
    print("\n" + "=" * 60)
    print("PyTorch CUDAæ”¯æŒæ£€æŸ¥")
    print("=" * 60)
    
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version()}")
        return True
    else:
        print("âŒ PyTorchä¸æ”¯æŒCUDA")
        return False

def get_installation_commands():
    """è·å–å®‰è£…å‘½ä»¤"""
    print("\n" + "=" * 60)
    print("GPUç¯å¢ƒå®‰è£…æŒ‡å—")
    print("=" * 60)
    
    print("1. å®‰è£…NVIDIAé©±åŠ¨ (å¦‚æœæœªå®‰è£…):")
    print("   - è®¿é—®: https://www.nvidia.com/drivers/")
    print("   - ä¸‹è½½å¹¶å®‰è£…é€‚åˆæ‚¨æ˜¾å¡çš„é©±åŠ¨")
    
    print("\n2. å®‰è£…CUDA Toolkit (æ¨èç‰ˆæœ¬: 11.8 æˆ– 12.1):")
    print("   - è®¿é—®: https://developer.nvidia.com/cuda-toolkit")
    print("   - ä¸‹è½½å¹¶å®‰è£…CUDA Toolkit")
    
    print("\n3. å®‰è£…æ”¯æŒCUDAçš„PyTorch:")
    print("   å¯¹äºCUDA 11.8:")
    print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    print("\n   å¯¹äºCUDA 12.1:")
    print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    
    print("\n4. éªŒè¯å®‰è£…:")
    print("   python -c \"import torch; print(torch.cuda.is_available())\"")

def create_gpu_config():
    """åˆ›å»ºGPUé…ç½®æ–‡ä»¶"""
    gpu_config = {
        "use_gpu": torch.cuda.is_available(),
        "gpu_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
        "mixed_precision": torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 7 if torch.cuda.is_available() else False,
        "memory_fraction": 0.8,
        "benchmark_mode": True
    }
    
    config_path = "gpu_config.json"
    import json
    with open(config_path, 'w') as f:
        json.dump(gpu_config, f, indent=2)
    
    print(f"\nâœ… GPUé…ç½®å·²ä¿å­˜è‡³: {config_path}")
    return gpu_config

def main():
    """ä¸»å‡½æ•°"""
    print("GPUç¯å¢ƒè®¾ç½®åŠ©æ‰‹")
    
    # æ£€æŸ¥CUDA
    cuda_available = check_cuda_installation()
    
    # æ£€æŸ¥PyTorch
    pytorch_cuda = check_pytorch_cuda()
    
    # åˆ›å»ºé…ç½®
    config = create_gpu_config()
    
    print("\n" + "=" * 60)
    print("è®¾ç½®æ€»ç»“")
    print("=" * 60)
    
    if cuda_available and pytorch_cuda:
        print("ğŸ‰ GPUç¯å¢ƒé…ç½®å®Œæˆï¼")
        print("âœ… å¯ä»¥ä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒ")
        if config["mixed_precision"]:
            print("âœ… æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ")
    elif cuda_available and not pytorch_cuda:
        print("âš ï¸  CUDAå·²å®‰è£…ï¼Œä½†PyTorchä¸æ”¯æŒCUDA")
        print("è¯·é‡æ–°å®‰è£…æ”¯æŒCUDAçš„PyTorchç‰ˆæœ¬")
        get_installation_commands()
    else:
        print("âŒ GPUç¯å¢ƒæœªé…ç½®")
        get_installation_commands()

if __name__ == "__main__":
    main()
