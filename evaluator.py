# -*- coding: utf-8 -*-
# æ–‡ä»¶å: evaluator.py
# æè¿°: æ¨¡å‹è¯„ä¼°å’Œæ¨ç†æ¨¡å—ï¼Œæ”¯æŒå•æ¨¡å‹æ¨ç†å’Œé›†æˆæ¨ç†

import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
import time
import numpy as np
import torch
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from typing import List, Union, Optional

# æœ¬åœ°æ¨¡å—å¯¼å…¥
from entities import UAV, Target
from scenarios import get_balanced_scenario, get_small_scenario, get_complex_scenario
from environment import UAVTaskEnv, DirectedGraph
from networks import create_network
from config import Config
from evaluate import evaluate_plan
from collections import defaultdict
from matplotlib.font_manager import FontProperties, findfont
from datetime import datetime

# =============================================================================
# ä»main-old.pyè¿ç§»çš„æ ¸å¿ƒå¤„ç†ç±»
# =============================================================================

def set_chinese_font():
    """æŸ¥æ‰¾å¹¶è®¾ç½®ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“ï¼Œä»¥è§£å†³matplotlibä¸­æ–‡ä¹±ç é—®é¢˜ã€‚"""
    # å¸¸è§çš„Windows/Linux/MacOSä¸­æ–‡å­—ä½“åˆ—è¡¨
    font_names = ['SimHei', 'Microsoft YaHei', 'Heiti TC', 'Arial Unicode MS']
    
    for font_name in font_names:
        if font_name in [f.name for f in fm.fontManager.ttflist]:
            plt.rcParams['font.sans-serif'] = [font_name]
            plt.rcParams['axes.unicode_minus'] = False
            # print(f"âœ… ä¸­æ–‡å­—ä½“ '{font_name}' è®¾ç½®æˆåŠŸã€‚")
            return
    
    print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„ä¸­æ–‡å­—ä½“ (SimHei, Microsoft YaHeiç­‰)ï¼Œå›¾è¡¨ä¸­çš„ä¸­æ–‡å¯èƒ½æ˜¾ç¤ºä¸ºä¹±ç ã€‚")


class PlanVisualizer:
    """æ–¹æ¡ˆå¯è§†åŒ–å™¨ - ä»main-old.pyè¿ç§»"""
    
    def __init__(self, config):
        self.config = config
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        set_chinese_font()
    
    def save(self, final_plan, uavs, targets, obstacles, scenario_name, training_time, 
             plan_generation_time, evaluation_metrics=None, deadlocked_tasks=None, suffix="", inference_mode="å•æ¨¡å‹æ¨ç†"):
        """ä¿å­˜å¯è§†åŒ–æ–¹æ¡ˆ - ä¸main-old.pyæ ¼å¼å®Œå…¨ä¸€è‡´"""
        
        # èµ„æºæ¶ˆè€—ç²¾ç¡®æ¨¡æ‹Ÿ
        temp_uav_resources = {u.id: u.initial_resources.copy().astype(float) for u in uavs}
        temp_target_resources = {t.id: t.resources.copy().astype(float) for t in targets}

        # æŒ‰äº‹ä»¶åˆ†ç»„å¤„ç†ååŒä»»åŠ¡
        events = defaultdict(list)
        for uav_id, tasks in final_plan.items():
            for task in tasks:
                event_key = (task.get('arrival_time', 0), task['target_id'])
                events[event_key].append({'uav_id': uav_id, 'task_ref': task})
        
        sorted_event_keys = sorted(events.keys())

        # ååŒäº‹ä»¶æ—¥å¿—
        collaboration_log = "\n\nååŒäº‹ä»¶æ—¥å¿— (æ­ç¤ºèµ„æºç«äº‰):\n" + "-"*36 + "\n"

        # æŒ‰äº‹ä»¶é¡ºåºå¤„ç†åä½œ
        for event_key in sorted_event_keys:
            arrival_time, target_id = event_key
            collaborating_steps = events[event_key]
            
            target_remaining_need_before = temp_target_resources[target_id].copy()
            collaboration_log += f" * äº‹ä»¶: åœ¨ t={arrival_time:.2f}s, æ— äººæœº(UAVs) {', '.join([str(s['uav_id']) for s in collaborating_steps])} åˆ°è¾¾ ç›®æ ‡ {target_id}\n"
            collaboration_log += f"   - ç›®æ ‡åˆå§‹éœ€æ±‚: {target_remaining_need_before}\n"

            for step in collaborating_steps:
                uav_id = step['uav_id']
                task = step['task_ref']

                uav_available_resources = temp_uav_resources[uav_id]
                actual_contribution = np.minimum(target_remaining_need_before, uav_available_resources)
                
                if np.all(actual_contribution < 1e-6):
                    task['resource_cost'] = np.zeros_like(uav_available_resources)
                    collaboration_log += f"     - UAV {uav_id} å°è¯•è´¡çŒ®ï¼Œä½†ç›®æ ‡éœ€æ±‚å·²æ»¡è¶³ã€‚è´¡çŒ®: [0. 0.]\n"
                    continue

                temp_uav_resources[uav_id] -= actual_contribution
                target_remaining_need_before -= actual_contribution
                task['resource_cost'] = actual_contribution
                collaboration_log += f"     - UAV {uav_id} è´¡çŒ® {actual_contribution}, å‰©ä½™èµ„æº {temp_uav_resources[uav_id]}\n"
                
            temp_target_resources[target_id] = target_remaining_need_before
            collaboration_log += f"   - äº‹ä»¶ç»“æŸï¼Œç›®æ ‡å‰©ä½™éœ€æ±‚: {target_remaining_need_before}\n\n"

        # åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
        fig, ax = plt.subplots(figsize=(22, 14))
        ax.set_facecolor("#f0f0f0")
        
        # ç»˜åˆ¶éšœç¢ç‰©
        for obs in obstacles:
            obs.draw(ax)

        # è®¡ç®—ç›®æ ‡åä½œè¯¦æƒ…
        target_collaborators_details = defaultdict(list)
        for uav_id, tasks in final_plan.items():
            for task in sorted(tasks, key=lambda x: x.get('step', 0)):
                target_id = task['target_id']
                resource_cost = task.get('resource_cost', np.zeros_like(uavs[0].resources))
                target_collaborators_details[target_id].append({
                    'uav_id': uav_id, 
                    'arrival_time': task.get('arrival_time', 0), 
                    'resource_cost': resource_cost
                })

        # è®¡ç®—æ€»ä½“èµ„æºæ»¡è¶³æƒ…å†µ
        summary_text = ""
        if targets:
            satisfied_targets_count = 0
            resource_types = len(targets[0].resources) if targets else 2
            total_demand_all = np.sum([t.resources for t in targets], axis=0)

            all_resource_costs = [d['resource_cost'] for details in target_collaborators_details.values() for d in details]
            if not all_resource_costs:
                total_contribution_all_for_summary = np.zeros(resource_types)
            else:
                total_contribution_all_for_summary = np.sum(all_resource_costs, axis=0)

            for t in targets:
                current_target_contribution_sum = np.sum([d['resource_cost'] for d in target_collaborators_details.get(t.id, [])], axis=0)
                if np.all(current_target_contribution_sum >= t.resources - 1e-5):
                    satisfied_targets_count += 1
            
            num_targets = len(targets)
            satisfaction_rate_percent = (satisfied_targets_count / num_targets * 100) if num_targets > 0 else 100
            total_demand_safe = total_demand_all.copy()
            total_demand_safe[total_demand_safe == 0] = 1e-6
            overall_completion_rate_percent = np.mean(np.minimum(total_contribution_all_for_summary, total_demand_all) / total_demand_safe) * 100
            
            # è®¡ç®—èµ„æºå¯Œè£•åº¦
            total_supply_all = np.sum([u.initial_resources for u in uavs], axis=0)
            resource_surplus = total_supply_all - total_demand_all
            resource_abundance_rate = (resource_surplus / total_demand_safe) * 100
            
            summary_text = (f"æ€»ä½“èµ„æºæ»¡è¶³æƒ…å†µ:\n--------------------------\n"
                          f"- æ€»éœ€æ±‚/æ€»è´¡çŒ®: {np.array2string(total_demand_all, formatter={'float_kind':lambda x: '%.0f' % x})} / {np.array2string(total_contribution_all_for_summary, formatter={'float_kind':lambda x: '%.1f' % x})}\n"
                          f"- æ€»ä¾›ç»™/èµ„æºå¯Œè£•åº¦: {np.array2string(total_supply_all, formatter={'float_kind':lambda x: '%.0f' % x})} / {np.array2string(resource_abundance_rate, formatter={'float_kind':lambda x: '%.1f%%' % x})}\n"
                          f"- å·²æ»¡è¶³ç›®æ ‡: {satisfied_targets_count} / {num_targets} ({satisfaction_rate_percent:.1f}%)\n"
                          f"- æ»¡è¶³ç‡: {overall_completion_rate_percent:.1f}% (æ˜¾ç¤ºç”¨ï¼Œæ–‡ä»¶åä½¿ç”¨æ ‡å‡†è¯„ä¼°æŒ‡æ ‡)")

        # ç»˜åˆ¶æ— äººæœºèµ·ç‚¹
        ax.scatter([u.position[0] for u in uavs], [u.position[1] for u in uavs], 
                  c='blue', marker='s', s=150, label='æ— äººæœºèµ·ç‚¹', zorder=5, edgecolors='black')
        
        for u in uavs:
            ax.annotate(f"UAV{u.id}", xy=(u.position[0], u.position[1]), fontsize=12, fontweight='bold', 
                       xytext=(0, -25), textcoords='offset points', ha='center', va='top')
            ax.annotate(f"åˆå§‹: {np.array2string(u.initial_resources, formatter={'float_kind': lambda x: f'{x:.0f}'})}", 
                       xy=(u.position[0], u.position[1]), fontsize=8, xytext=(15, 10), 
                       textcoords='offset points', ha='left', color='navy')

        # ç»˜åˆ¶ç›®æ ‡
        ax.scatter([t.position[0] for t in targets], [t.position[1] for t in targets], 
                  c='red', marker='o', s=150, label='ç›®æ ‡', zorder=5, edgecolors='black')
        
        for t in targets:
            demand_str = np.array2string(t.resources, formatter={'float_kind': lambda x: "%.0f" % x})
            annotation_text = f"ç›®æ ‡ {t.id}\næ€»éœ€æ±‚: {demand_str}\n------------------"
            
            total_contribution = np.sum([d['resource_cost'] for d in target_collaborators_details.get(t.id, [])], axis=0)
            details_text = sorted(target_collaborators_details.get(t.id, []), key=lambda x: x['arrival_time'])
            
            if not details_text:
                annotation_text += "\næœªåˆ†é…æ— äººæœº"
            else:
                for detail in details_text:
                    annotation_text += f"\nUAV {detail['uav_id']} (T:{detail['arrival_time']:.1f}s) è´¡çŒ®:{np.array2string(detail['resource_cost'], formatter={'float_kind': lambda x: '%.1f' % x})}"
            
            if np.all(total_contribution >= t.resources - 1e-5):
                satisfaction_str, bbox_color = "[OK] éœ€æ±‚æ»¡è¶³", 'lightgreen'
            else:
                satisfaction_str, bbox_color = "[NG] èµ„æºä¸è¶³", 'mistyrose'
            
            annotation_text += f"\n------------------\nçŠ¶æ€: {satisfaction_str}"
            
            ax.annotate(f"T{t.id}", xy=(t.position[0], t.position[1]), fontsize=12, fontweight='bold', 
                       xytext=(0, 18), textcoords='offset points', ha='center', va='bottom')
            ax.annotate(annotation_text, xy=(t.position[0], t.position[1]), fontsize=7, 
                       xytext=(15, -15), textcoords='offset points', ha='left', va='top', 
                       bbox=dict(boxstyle='round,pad=0.4', fc=bbox_color, ec='black', alpha=0.9, lw=0.5), zorder=8)

        # ç»˜åˆ¶è·¯å¾„ - ä¿®å¤ï¼šç»˜åˆ¶è¿ç»­çš„ä»»åŠ¡è·¯å¾„
        colors = plt.cm.gist_rainbow(np.linspace(0, 1, len(uavs))) if uavs else []
        uav_color_map = {u.id: colors[i] for i, u in enumerate(uavs)}
        
        for uav_id, tasks in final_plan.items():
            uav_color = uav_color_map.get(uav_id, 'gray')
            temp_resources = next(u for u in uavs if u.id == uav_id).initial_resources.copy().astype(float)
            
            # è·å–æ— äººæœºèµ·å§‹ä½ç½®
            uav = next(u for u in uavs if u.id == uav_id)
            current_pos = uav.position
            
            # æŒ‰æ­¥éª¤é¡ºåºæ’åºä»»åŠ¡
            sorted_tasks = sorted(tasks, key=lambda x: x.get('step', 0))
            
            # ç»˜åˆ¶è¿ç»­è·¯å¾„
            for i, task in enumerate(sorted_tasks):
                # è·å–ç›®æ ‡ä½ç½®
                target_id = task['target_id']
                target = next(t for t in targets if t.id == target_id)
                target_pos = target.position
                
                # ä½¿ç”¨PH-RRTç®—æ³•ç”Ÿæˆæ›²çº¿è·¯å¾„
                try:
                    from path_planning import PHCurveRRTPlanner
                    
                    # åˆ›å»ºPH-RRTè§„åˆ’å™¨
                    planner = PHCurveRRTPlanner(
                        start=current_pos,
                        goal=target_pos,
                        start_heading=0.0,  # å¯ä»¥ä»UAVè·å–å®é™…æœå‘
                        goal_heading=0.0,   # ç›®æ ‡æœå‘
                        obstacles=obstacles,
                        config=self.config
                    )
                    
                    # æ‰§è¡Œè·¯å¾„è§„åˆ’è·å–PHæ›²çº¿
                    result = planner.plan()
                    
                    if result is not None:
                        path_points, distance = result
                        path_points = np.array(path_points)
                    else:
                        # è§„åˆ’å¤±è´¥æ—¶ç”Ÿæˆå¹³æ»‘æ›²çº¿
                        path_points = self._generate_smooth_curve(current_pos, target_pos)
                        
                except Exception as e:
                    print(f"PH-RRTè§„åˆ’å¤±è´¥: {e}ï¼Œä½¿ç”¨å¹³æ»‘æ›²çº¿")
                    path_points = self._generate_smooth_curve(current_pos, target_pos)
                
                # ç»˜åˆ¶è·¯å¾„
                ax.plot(path_points[:, 0], path_points[:, 1], 
                       color=uav_color, 
                       linestyle='-' if task.get('is_sync_feasible', True) else '--', 
                       linewidth=2, alpha=0.9, zorder=3)
                
                # æ·»åŠ æ­¥éª¤æ ‡è®° - ä¼˜åŒ–ï¼šæ”¹è¿›åºåˆ—é¡ºåºçš„æ˜¾ç¤ºæ¸…æ™°åº¦
                mid_pos = path_points[len(path_points) // 2]
                step_number = task.get('step', i+1)
                
                # ä¸»æ­¥éª¤æ ‡è®°ï¼ˆå¤§åœ†åœˆï¼‰
                ax.text(mid_pos[0], mid_pos[1], str(step_number), 
                       color='white', backgroundcolor=uav_color, ha='center', va='center', 
                       fontsize=11, fontweight='bold', 
                       bbox=dict(boxstyle='circle,pad=0.3', fc=uav_color, ec='white', linewidth=2), zorder=6)
                
                # æ­¥éª¤ç®­å¤´æŒ‡ç¤ºï¼ˆæ˜¾ç¤ºæ–¹å‘ï¼‰
                if len(path_points) > 1:
                    # åœ¨è·¯å¾„çš„æ–¹å‘ä¸Šæ·»åŠ ç®­å¤´
                    arrow_start_idx = int(len(path_points) * 0.7)
                    arrow_end_idx = min(arrow_start_idx + 5, len(path_points) - 1)
                    
                    if arrow_start_idx < arrow_end_idx:
                        start_point = path_points[arrow_start_idx]
                        end_point = path_points[arrow_end_idx]
                        
                        ax.annotate('', xy=end_point, xytext=start_point,
                                   arrowprops=dict(arrowstyle='->', color=uav_color, lw=2, alpha=0.8),
                                   zorder=5)
                
                # åœ¨è·¯å¾„èµ·å§‹ç‚¹æ·»åŠ å°å‹æ­¥éª¤æ ‡è®°
                if i == 0:  # ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼Œæ˜¾ç¤ºâ€œèµ·â€
                    start_pos = path_points[0]
                    ax.text(start_pos[0], start_pos[1], 'èµ·', 
                           color=uav_color, ha='center', va='center', 
                           fontsize=8, fontweight='bold', 
                           bbox=dict(boxstyle='round,pad=0.2', fc='white', ec=uav_color, alpha=0.9), zorder=5)
                
                # åœ¨è·¯å¾„ç»“æŸç‚¹æ·»åŠ å°å‹æ­¥éª¤æ ‡è®°
                end_pos = path_points[-1]
                if i == len(sorted_tasks) - 1:  # æœ€åä¸€ä¸ªä»»åŠ¡ï¼Œæ˜¾ç¤ºâ€œç»ˆâ€
                    ax.text(end_pos[0], end_pos[1], 'ç»ˆ', 
                           color=uav_color, ha='center', va='center', 
                           fontsize=8, fontweight='bold', 
                           bbox=dict(boxstyle='round,pad=0.2', fc='white', ec=uav_color, alpha=0.9), zorder=5)
                else:
                    # ä¸­é—´ä»»åŠ¡ï¼Œæ˜¾ç¤ºä¸‹ä¸€æ­¥éª¤çš„æ–¹å‘
                    next_step = step_number + 1
                    ax.text(end_pos[0], end_pos[1], f'â†’{next_step}', 
                           color=uav_color, ha='center', va='center', 
                           fontsize=7, fontweight='bold', 
                           bbox=dict(boxstyle='round,pad=0.15', fc='lightyellow', ec=uav_color, alpha=0.8), zorder=5)
                
                # æ·»åŠ èµ„æºä¿¡æ¯
                resource_cost = task.get('resource_cost', np.zeros_like(temp_resources))
                temp_resources -= resource_cost
                end_pos = path_points[-1]
                remaining_res_str = f"R: {np.array2string(temp_resources.clip(0), formatter={'float_kind': lambda x: f'{x:.0f}'})}"
                ax.annotate(remaining_res_str, xy=(end_pos[0], end_pos[1]),
                           color=uav_color, ha='center', va='center', 
                           fontsize=7, fontweight='bold', 
                           bbox=dict(boxstyle='round,pad=0.15', fc='white', ec=uav_color, alpha=0.8, lw=0.5), 
                           xytext=(10, -10), textcoords='offset points', zorder=7)
                
                # æ›´æ–°å½“å‰ä½ç½®ä¸ºç›®æ ‡ä½ç½®ï¼Œä¸ºä¸‹ä¸€ä¸ªä»»åŠ¡åšå‡†å¤‡
                current_pos = target_pos

        # æ­»é”æ£€æµ‹ä¿¡æ¯
        deadlock_summary_text = ""
        if deadlocked_tasks and any(deadlocked_tasks.values()):
            deadlock_summary_text += "!!! æ­»é”æ£€æµ‹ !!!\n--------------------------\nä»¥ä¸‹æ— äººæœºæœªèƒ½å®Œæˆå…¶ä»»åŠ¡åºåˆ—ï¼Œå¯èƒ½é™·å…¥æ­»é”ï¼š\n"
            for uav_id, tasks in deadlocked_tasks.items():
                if tasks:
                    deadlock_summary_text += f"- UAV {uav_id}: ç­‰å¾…æ‰§è¡Œ -> {' -> '.join([f'T{t[0]}' for t in tasks])}\n"
            deadlock_summary_text += ("-"*30) + "\n\n"

        # æŠ¥å‘Šå¤´éƒ¨
        report_header = f"---------- {scenario_name} æ‰§è¡ŒæŠ¥å‘Š ----------\n\n" + deadlock_summary_text
        if summary_text:
            report_header += summary_text + "\n" + ("-"*30) + "\n\n"
        
        # æ·»åŠ è¯„ä¼°æŒ‡æ ‡åˆ°æŠ¥å‘Šä¸­
        if evaluation_metrics:
            report_header += "è¯„ä¼°æŒ‡æ ‡:\n--------------------------\n"
            # å®šä¹‰æŒ‡æ ‡çš„ä¸­æ–‡åç§°æ˜ å°„
            metric_names = {
                'resource_utilization_rate': 'èµ„æºåˆ©ç”¨ç‡',
                'completion_rate': 'èµ„æºæ»¡è¶³ç‡',
                'sync_feasibility_rate': 'åŒæ­¥å¯è¡Œç‡',
                'load_balance_score': 'è´Ÿè½½å‡è¡¡åº¦'
            }
            
            # ä¼˜å…ˆæ˜¾ç¤ºèµ„æºåˆ©ç”¨ç‡ï¼Œå»æ‰å½’ä¸€åŒ–ä¿¡æ¯
            priority_metrics = ['resource_utilization_rate']
            other_metrics = ['sync_feasibility_rate', 'load_balance_score']
            
            # ä¼˜å…ˆæ˜¾ç¤ºèµ„æºåˆ©ç”¨ç‡
            for key in priority_metrics:
                if key in evaluation_metrics:
                    value = evaluation_metrics[key]
                    report_header += f"  - {metric_names.get(key, key)}: {value:.4f}\n"
            
            # æ˜¾ç¤ºå…¶ä»–æŒ‡æ ‡
            for key in other_metrics:
                if key in evaluation_metrics:
                    value = evaluation_metrics[key]
                    report_header += f"  - {metric_names.get(key, key)}: {value:.4f}\n"
            
            report_header += "-" * 20 + "\n\n"

        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report_body_image = ""
        report_body_file = ""
        
        for uav in uavs:
            uav_header = f"* æ— äººæœº {uav.id} (åˆå§‹èµ„æº: {np.array2string(uav.initial_resources, formatter={'float_kind': lambda x: f'{x:.0f}'})})\n"
            report_body_image += uav_header
            report_body_file += uav_header
            
            details = sorted(final_plan.get(uav.id, []), key=lambda x: x.get('step', 0))
            if not details:
                no_task_str = "  - æœªåˆ†é…ä»»ä½•ä»»åŠ¡\n"
                report_body_image += no_task_str
                report_body_file += no_task_str
            else:
                temp_resources_report = uav.initial_resources.copy().astype(float)
                for detail in details:
                    resource_cost = detail.get('resource_cost', np.zeros_like(temp_resources_report))
                    temp_resources_report -= resource_cost
                    sync_status = "" if detail.get('is_sync_feasible', True) else " (è­¦å‘Š: æ— æ³•åŒæ­¥)"
                    
                    common_report_part = f"  {detail.get('step', 0)}. é£å‘ç›®æ ‡ {detail['target_id']}{sync_status}:\n"
                    common_report_part += f"     - é£è¡Œè·ç¦»: {detail.get('distance', 0):.2f} m, é€Ÿåº¦: {detail.get('speed', 15):.2f} m/s, åˆ°è¾¾æ—¶é—´ç‚¹: {detail.get('arrival_time', 0):.2f} s\n"
                    common_report_part += f"     - æ¶ˆè€—èµ„æº: {np.array2string(resource_cost, formatter={'float_kind': lambda x: '%.1f' % x})}\n"
                    common_report_part += f"     - å‰©ä½™èµ„æº: {np.array2string(temp_resources_report.clip(0), formatter={'float_kind': lambda x: f'{x:.1f}'})}\n"
                    
                    report_body_image += common_report_part
                    report_body_file += common_report_part
            
            report_body_image += "\n"
            report_body_file += "\n"

        final_report_for_image = report_header + report_body_image
        final_report_for_file = report_header + report_body_file + collaboration_log

        # æ·»åŠ æŠ¥å‘Šåˆ°å›¾ç‰‡
        plt.subplots_adjust(right=0.75)
        fig.text(0.77, 0.95, final_report_for_image, transform=plt.gcf().transFigure, 
                ha="left", va="top", fontsize=9, 
                bbox=dict(boxstyle='round,pad=0.5', fc='aliceblue', ec='grey', alpha=0.9))

        # å¤„ç†training_timeæ ¼å¼åŒ–
        if isinstance(training_time, (tuple, list)):
            actual_episodes = len(training_time[0]) if training_time and len(training_time) > 0 else 0
            estimated_time = actual_episodes * 0.13
            training_time_str = f"{estimated_time:.2f}s ({actual_episodes}è½®)"
        else:
            training_time_str = f"{training_time:.2f}s"

        train_mode_str = 'é«˜ç²¾åº¦PH-RRT' if getattr(self.config, 'USE_PHRRT_DURING_TRAINING', False) else 'å¿«é€Ÿè¿‘ä¼¼'
        plan_mode_str = 'é«˜ç²¾åº¦PH-RRT' if getattr(self.config, 'USE_PHRRT_DURING_PLANNING', False) else 'å¿«é€Ÿè¿‘ä¼¼'
        
        title_text = (
            f"å¤šæ— äººæœºä»»åŠ¡åˆ†é…ä¸è·¯å¾„è§„åˆ’ - {scenario_name} ({inference_mode})\n"
            f"UAV: {len(uavs)}, ç›®æ ‡: {len(targets)}, éšœç¢: {len(obstacles)} | è®­ç»ƒ: {train_mode_str} | è§„åˆ’: {plan_mode_str}\n"
            f"æ¨¡å‹è®­ç»ƒè€—æ—¶: {training_time_str} | æ–¹æ¡ˆç”Ÿæˆè€—æ—¶: {plan_generation_time:.2f}s"
        )
        ax.set_title(title_text, fontsize=12, fontweight='bold', pad=20)

        ax.set_xlabel("Xåæ ‡ (m)", fontsize=14)
        ax.set_ylabel("Yåæ ‡ (m)", fontsize=14)
        ax.legend(loc="lower left")
        ax.grid(True, linestyle='--', alpha=0.5, zorder=0)
        ax.set_aspect('equal', adjustable='box')

        # ä¿å­˜å›¾ç‰‡ - æ·»åŠ å®Œæˆç‡ä¿¡æ¯åˆ°æ–‡ä»¶å
        output_dir = "output/images"
        os.makedirs(output_dir, exist_ok=True)
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        clean_scenario_name = scenario_name.replace(' ', '_').replace(':', '')
        
        # è·å–å®Œæˆç‡ä¿¡æ¯ç”¨äºæ–‡ä»¶å - ä¿®å¤ï¼šç¡®ä¿ä½¿ç”¨æ ‡å‡†è¯„ä¼°æŒ‡æ ‡ä¸­çš„å®Œæˆç‡
        completion_rate_for_filename = 0.0
        if evaluation_metrics:
            completion_rate_for_filename = evaluation_metrics.get('completion_rate', 0.0)
        else:
            # å¦‚æœæ²¡æœ‰evaluation_metricsï¼Œä½¿ç”¨PlanVisualizerè®¡ç®—çš„å®Œæˆç‡ä½œä¸ºå¤‡é€‰
            completion_rate_for_filename = overall_completion_rate_percent / 100.0 if 'overall_completion_rate_percent' in locals() else 0.0
        
        # æ„å»ºåŒ…å«å®Œæˆç‡ä¿¡æ¯çš„æ–‡ä»¶å
        completion_str = f"comp{completion_rate_for_filename:.3f}"
        base_filename = f"{clean_scenario_name}_{timestamp}_{completion_str}{suffix}"
        img_filepath = os.path.join(output_dir, f"{base_filename}.jpg")
        
        try:
            plt.savefig(img_filepath, dpi=300, format='jpg')
            # ç§»é™¤é‡å¤çš„è¾“å‡ºï¼Œåªåœ¨ResultSaverä¸­è¾“å‡º
        except Exception as e:
            print(f"âŒ é”™è¯¯ï¼šæ— æ³•ä¿å­˜ç»“æœå›¾è‡³ {img_filepath}")
            print(f"ğŸ“„ æ–‡ä»¶å†™å…¥é”™è¯¯è¯¦æƒ…ï¼š")
            print(f"   - æ–‡ä»¶å: {base_filename}.jpg")
            print(f"   - å­˜å‚¨ä½ç½®: {output_dir}")
            print(f"   - å®Œæ•´è·¯å¾„: {img_filepath}")
            print(f"   - å›¾è¡¨å°ºå¯¸: {fig.get_size_inches()}")
            print(f"   - é”™è¯¯åŸå› : {e}")
            print(f"   - é”™è¯¯ç±»å‹: {type(e).__name__}")
            
            # å°è¯•è¾“å‡ºå›¾è¡¨å†…å®¹ä¿¡æ¯
            try:
                print(f"   - å›¾è¡¨è½´æ•°é‡: {len(fig.axes)}")
                print(f"   - å›¾è¡¨DPI: {fig.dpi}")
                print(f"   - è¾“å‡ºç›®å½•æ˜¯å¦å­˜åœ¨: {os.path.exists(output_dir)}")
                print(f"   - è¾“å‡ºç›®å½•æƒé™: {os.access(output_dir, os.W_OK) if os.path.exists(output_dir) else 'N/A'}")
            except Exception as inner_e:
                print(f"   - æ— æ³•è·å–è¯¦ç»†ä¿¡æ¯: {inner_e}")
        
        plt.close(fig)
        
        return final_report_for_file, img_filepath

    def _generate_smooth_curve(self, start_pos, end_pos):
        """ç”Ÿæˆå¹³æ»‘æ›²çº¿è·¯å¾„ä½œä¸ºPH-RRTçš„å¤‡é€‰æ–¹æ¡ˆ"""
        start_pos = np.array(start_pos)
        end_pos = np.array(end_pos)
        
        distance = np.linalg.norm(end_pos - start_pos)
        num_points = max(10, int(distance / 20))  # æ¯20ç±³ä¸€ä¸ªç‚¹
        
        path_points = []
        for i in range(num_points + 1):
            t = i / num_points
            
            # åŸºç¡€ç›´çº¿æ’å€¼
            base_point = start_pos + t * (end_pos - start_pos)
            
            # æ·»åŠ è´å¡å°”æ›²çº¿æ ·å¼çš„åç§»
            if i > 0 and i < num_points:
                # è®¡ç®—å‚ç›´äºç›´çº¿æ–¹å‘çš„å‘é‡
                direction = end_pos - start_pos
                perpendicular = np.array([-direction[1], direction[0]])
                if np.linalg.norm(perpendicular) > 0:
                    perpendicular = perpendicular / np.linalg.norm(perpendicular)
                
                # ä½¿ç”¨è´å¡å°”æ›²çº¿çš„æ§åˆ¶ç‚¹é€»è¾‘
                curve_factor = 4 * t * (1 - t)  # è´å¡å°”æ›²çº¿æƒé‡
                curve_offset = curve_factor * min(30, distance * 0.15)  # åŠ¨æ€åç§»é‡
                
                base_point += perpendicular * curve_offset
            
            path_points.append(base_point)
        
        return np.array(path_points)


class ResultSaver:
    """ç»“æœä¿å­˜å™¨ - ä»main-old.pyè¿ç§»"""
    
    def __init__(self, config):
        self.config = config
    
    def save_plan_details(self, report_content, scenario_name, timestamp=None, evaluation_metrics=None, suffix=""):
        """ä¿å­˜æ–¹æ¡ˆè¯¦æƒ…æ–‡ä»¶ - ä¿®æ”¹ä¸ºä¿å­˜åˆ°output/images/ç›®å½•ï¼Œå¹¶åˆå¹¶è¯„ä¼°æŒ‡æ ‡"""
        if timestamp is None:
            timestamp = time.strftime("%Y%m%d-%H%M%S")
        
        # ä¿®æ”¹ä¿å­˜è·¯å¾„åˆ°imagesç›®å½•
        report_dir = "output/images"
        os.makedirs(report_dir, exist_ok=True)
        
        clean_scenario_name = scenario_name.replace(' ', '_').replace(':', '')
        
        # è·å–å®Œæˆç‡ä¿¡æ¯ç”¨äºæ–‡ä»¶å
        completion_rate_for_filename = 0.0
        if evaluation_metrics:
            completion_rate_for_filename = evaluation_metrics.get('completion_rate', 0.0)
        
        # æ„å»ºåŒ…å«å®Œæˆç‡ä¿¡æ¯çš„æ–‡ä»¶å
        completion_str = f"comp{completion_rate_for_filename:.3f}"
        base_filename = f"{clean_scenario_name}_{timestamp}_{completion_str}{suffix}"
        report_filepath = os.path.join(report_dir, f"{base_filename}.txt")
        
        try:
            # åˆå¹¶è¯„ä¼°æŒ‡æ ‡åˆ°æŠ¥å‘Šå†…å®¹æœ«å°¾
            combined_content = report_content
            if evaluation_metrics:
                combined_content += "\n\n" + "=" * 80 + "\n"
                combined_content += "è¯„ä¼°æŒ‡æ ‡è¯¦æƒ…\n"
                combined_content += "=" * 80 + "\n"
                for key, value in evaluation_metrics.items():
                    if isinstance(value, float):
                        combined_content += f"{key}: {value:.4f}\n"
                    else:
                        combined_content += f"{key}: {value}\n"
                combined_content += "=" * 80 + "\n"
            
            with open(report_filepath, 'w', encoding='utf-8') as f:
                f.write(combined_content)
            print(f"è¯¦ç»†æ–¹æ¡ˆæŠ¥å‘Šå·²ä¿å­˜è‡³: {report_filepath}")
            return report_filepath
        except Exception as e:
            print(f"âŒ é”™è¯¯ï¼šæ— æ³•ä¿å­˜ä»»åŠ¡æŠ¥å‘Šè‡³ {report_filepath}")
            print(f"ğŸ“„ æ–‡ä»¶å†™å…¥é”™è¯¯è¯¦æƒ…ï¼š")
            print(f"   - æ–‡ä»¶å: {base_filename}.txt")
            print(f"   - å­˜å‚¨ä½ç½®: {report_dir}")
            print(f"   - å®Œæ•´è·¯å¾„: {report_filepath}")
            print(f"   - å†…å®¹é•¿åº¦: {len(combined_content)} å­—ç¬¦")
            print(f"   - å†…å®¹å‰100å­—ç¬¦: {combined_content[:100]}...")
            print(f"   - é”™è¯¯åŸå› : {e}")
            print(f"   - é”™è¯¯ç±»å‹: {type(e).__name__}")
            
            # å°è¯•è¾“å‡ºç›®å½•å’Œæƒé™ä¿¡æ¯
            try:
                print(f"   - ç›®å½•æ˜¯å¦å­˜åœ¨: {os.path.exists(report_dir)}")
                print(f"   - ç›®å½•æƒé™: {os.access(report_dir, os.W_OK) if os.path.exists(report_dir) else 'N/A'}")
                if hasattr(os, 'statvfs'):
                    stat = os.statvfs(report_dir)
                    free_space = stat.f_bavail * stat.f_frsize / (1024**3)
                    print(f"   - ç£ç›˜ç©ºé—´: {free_space:.2f} GB")
                else:
                    print(f"   - ç£ç›˜ç©ºé—´: æ— æ³•æ£€æµ‹")
            except Exception as inner_e:
                print(f"   - æ— æ³•è·å–è¯¦ç»†ä¿¡æ¯: {inner_e}")
            
            return None

class ModelEvaluator:
    """æ¨¡å‹è¯„ä¼°å™¨ - æ”¯æŒå•æ¨¡å‹å’Œé›†æˆæ¨ç†"""
    
    def __init__(self, config: Config):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"è¯„ä¼°è®¾å¤‡: {self.device}")
        
        # è¯„ä¼°ç»Ÿè®¡
        self.evaluation_stats = {
            'scenario_results': [],
            'average_completion_rate': 0.0,
            'average_efficiency': 0.0,
            'evaluation_time': 0.0
        }

    def _generate_complete_visualization(self, scenario_name: str, inference_mode: str, 
                                    uavs, targets, obstacles, results, suffix: str = ""):
        """ç”Ÿæˆå®Œæ•´çš„å¯è§†åŒ–ç»“æœ - é›†æˆPlanVisualizerå’ŒResultSaver"""
        try:
            # æ„å»ºfinal_planæ ¼å¼ï¼ˆä»æ¨ç†ç»“æœè½¬æ¢ï¼‰
            final_plan = self._convert_results_to_plan(results, uavs, targets)
            
            # åˆ›å»ºå¯è§†åŒ–å™¨å’Œä¿å­˜å™¨
            visualizer = PlanVisualizer(self.config)
            saver = ResultSaver(self.config)
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            final_uav_states = results.get('final_uav_states', None)
            evaluation_metrics = evaluate_plan(final_plan, uavs, targets, final_uav_states=final_uav_states)
            
            # ã€é‡è¦ä¿®æ”¹ã€‘ä»¥æ¨ç†ç»“æœä¸ºå‡†ï¼Œæ¨ç†ç»“æœå°±æ˜¯æœ€ç»ˆçš„åˆ†é…æ–¹æ¡ˆ
            if results and 'completion_rate' in results:
                # ä½¿ç”¨æ¨ç†ç»“æœä¸­çš„å®Œæˆç‡ä½œä¸ºæœ€ç»ˆç»“æœ
                evaluation_metrics['completion_rate'] = results['completion_rate']
                print(f"[DEBUG] ä½¿ç”¨æ¨ç†ç»“æœä¸­çš„å®Œæˆç‡: {results['completion_rate']:.4f}")
                
                # å¦‚æœæœ‰æ¨ç†ä»»åŠ¡åˆ†é…æ–¹æ¡ˆï¼Œä½¿ç”¨æ¨ç†ç»“æœè¦†ç›–evaluate_plançš„ç»“æœ
                if 'inference_task_assignments' in results and 'inference_target_status' in results:
                    print(f"[DEBUG] ä½¿ç”¨æ¨ç†ä»»åŠ¡åˆ†é…æ–¹æ¡ˆä½œä¸ºæœ€ç»ˆç»“æœ")
                    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ é€»è¾‘æ¥ä½¿ç”¨æ¨ç†ç»“æœè¦†ç›–evaluate_plançš„æŸäº›æŒ‡æ ‡
            else:
                print(f"[DEBUG] ä½¿ç”¨evaluate_planè®¡ç®—çš„å®Œæˆç‡: {evaluation_metrics.get('completion_rate', 0):.4f}")
            
            # ç”Ÿæˆå¯è§†åŒ–å’ŒæŠ¥å‘Š
            training_time = 0.0  # æ¨ç†é˜¶æ®µæ— è®­ç»ƒæ—¶é—´
            plan_generation_time = self.evaluation_stats['evaluation_time']
            
            # ä¼ é€’suffixå’Œæ¨ç†æ–¹å¼å‚æ•°
            report_content, img_filepath = visualizer.save(
                final_plan, uavs, targets, obstacles, scenario_name,
                training_time, plan_generation_time, evaluation_metrics, None, suffix, inference_mode
            )
            
            # ä¿å­˜è¯¦ç»†æŠ¥å‘Šï¼ŒåŒ…å«è¯„ä¼°æŒ‡æ ‡
            timestamp = time.strftime("%Y%m%d-%H%M%S")
            report_filepath = saver.save_plan_details(report_content, scenario_name, timestamp, evaluation_metrics, suffix)
            
            print(f"å®Œæ•´å¯è§†åŒ–ç»“æœå·²ç”Ÿæˆ: {scenario_name}")
            
        except Exception as e:
            print(f"ç”Ÿæˆå®Œæ•´å¯è§†åŒ–æ—¶å‡ºé”™: {e}")

    def _build_plan_from_inference_results(self, results, uavs, targets):
        """
        ä»æ¨ç†ç»“æœæ„å»ºæ‰§è¡Œè®¡åˆ’
        
        Args:
            results: æ¨ç†ç»“æœå­—å…¸
            uavs: UAVåˆ—è¡¨
            targets: ç›®æ ‡åˆ—è¡¨
            
        Returns:
            dict: æ‰§è¡Œè®¡åˆ’
        """
        final_plan = {uav.id: [] for uav in uavs}
        
        inference_assignments = results.get('inference_task_assignments', {})
        inference_targets = results.get('inference_target_status', {})
        
        print(f"[DEBUG] ä»æ¨ç†ç»“æœæ„å»ºæ‰§è¡Œè®¡åˆ’:")
        print(f"  - UAVåˆ†é…æ–¹æ¡ˆæ•°é‡: {len(inference_assignments)}")
        print(f"  - ç›®æ ‡çŠ¶æ€æ•°é‡: {len(inference_targets)}")
        
        # ä¸ºæ¯ä¸ªUAVæ„å»ºä»»åŠ¡åºåˆ—
        for uav_id, uav_info in inference_assignments.items():
            consumed_resources = uav_info['consumed_resources']
            initial_resources = uav_info['initial_resources']
            
            # æ‰¾åˆ°è¯¥UAVè´¡çŒ®èµ„æºçš„ç›®æ ‡
            uav_tasks = []
            for target_id, target_info in inference_targets.items():
                contributed_resources = target_info['contributed_resources']
                
                # æ£€æŸ¥è¯¥UAVæ˜¯å¦å‘æ­¤ç›®æ ‡è´¡çŒ®äº†èµ„æº
                if np.any(contributed_resources > 0):
                    # è®¡ç®—è¯¥UAVå¯¹æ­¤ç›®æ ‡çš„è´¡çŒ®æ¯”ä¾‹
                    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå‡è®¾UAVæŒ‰æ¯”ä¾‹è´¡çŒ®èµ„æº
                    contribution_ratio = np.mean(contributed_resources / (initial_resources + 1e-6))
                    
                    if contribution_ratio > 0.1:  # å¦‚æœè´¡çŒ®æ¯”ä¾‹è¶…è¿‡10%ï¼Œè®¤ä¸ºè¯¥UAVå‚ä¸äº†æ­¤ç›®æ ‡
                        # æ‰¾åˆ°å¯¹åº”çš„ç›®æ ‡å¯¹è±¡
                        target_obj = next((t for t in targets if t.id == target_id), None)
                        uav_obj = next((u for u in uavs if u.id == uav_id), None)
                        
                        if target_obj and uav_obj:
                            distance = np.linalg.norm(uav_obj.position - target_obj.position)
                            speed = 15.0  # é»˜è®¤é€Ÿåº¦
                            
                            task = {
                                'target_id': target_id,
                                'step': len(uav_tasks) + 1,
                                'distance': distance,
                                'speed': speed,
                                'arrival_time': distance / speed,
                                'resource_cost': contributed_resources,
                                'is_sync_feasible': True  # æ¨ç†ç»“æœè®¤ä¸ºå¯è¡Œ
                            }
                            uav_tasks.append(task)
            
            final_plan[uav_id] = uav_tasks
            print(f"  - UAV {uav_id}: åˆ†é…äº† {len(uav_tasks)} ä¸ªä»»åŠ¡")
        
        return final_plan

    def _convert_results_to_plan(self, results, uavs, targets):
        """å°†æ¨ç†ç»“æœè½¬æ¢ä¸ºfinal_planæ ¼å¼"""
        final_plan = {uav.id: [] for uav in uavs}        
        
        # ä¼˜å…ˆä½¿ç”¨æ¨ç†ç»“æŸæ—¶ç›´æ¥è®°å½•çš„ã€æœ€å‡†ç¡®çš„ä»»åŠ¡åˆ†é…æ–¹æ¡ˆ
        if 'inference_task_assignments' in results and 'inference_target_status' in results:
            print(f"[DEBUG] ä½¿ç”¨æ¨ç†ç»“æŸæ—¶è®°å½•çš„æœ€ç»ˆåˆ†é…æ–¹æ¡ˆæ„å»ºæ‰§è¡Œè®¡åˆ’")
            return self._build_plan_from_inference_results(results, uavs, targets)
        
        # åå¤‡æ–¹æ¡ˆï¼šé€šè¿‡æ¨¡æ‹Ÿaction_sequenceæ¥é‡å»ºä»»åŠ¡åˆ†é…
        final_plan = {uav.id: [] for uav in uavs}
        action_sequence = results.get('action_sequence', [])
        print(f"[DEBUG] é€šè¿‡æ¨¡æ‹Ÿaction_sequenceé‡å»ºæ‰§è¡Œè®¡åˆ’ï¼ŒåŠ¨ä½œæ•°é‡: {len(action_sequence)}")

        # --- åˆ›å»ºç¯å¢ƒçŠ¶æ€çš„æ·±æ‹·è´ç”¨äºæ¨¡æ‹Ÿ ---
        import copy
        temp_uavs = {u.id: copy.deepcopy(u) for u in uavs}
        temp_targets = {t.id: copy.deepcopy(t) for t in targets}
        
        step_counter = 0
        for action_idx in action_sequence:
            try:
                # è§£ç åŠ¨ä½œ
                n_uavs = len(uavs)
                n_targets = len(targets)
                n_phi = getattr(self.config, 'GRAPH_N_PHI', 1)
                
                if n_uavs == 0 or n_targets == 0 or n_phi == 0: continue
                
                target_idx = action_idx // (n_uavs * n_phi)
                uav_idx = (action_idx % (n_uavs * n_phi)) // n_phi
                
                if not (target_idx < n_targets and uav_idx < n_uavs): continue

                target = targets[target_idx]
                uav = uavs[uav_idx]

                # è·å–æ¨¡æ‹Ÿä¸­çš„å½“å‰çŠ¶æ€
                sim_uav = temp_uavs[uav.id]
                sim_target = temp_targets[target.id]

                # --- [æ–°å¢] æ£€æŸ¥åŠ¨ä½œåœ¨å½“å‰æ¨¡æ‹ŸçŠ¶æ€ä¸‹æ˜¯å¦æœ‰æ•ˆ ---
                actual_contribution = np.minimum(sim_uav.resources, sim_target.remaining_resources)
                
                if np.sum(actual_contribution) > 1e-6:
                    # åªæœ‰å½“åŠ¨ä½œèƒ½äº§ç”Ÿå®é™…è´¡çŒ®æ—¶ï¼Œæ‰è®°å½•åˆ°æœ€ç»ˆæ–¹æ¡ˆä¸­
                    step_counter += 1
                    distance = np.linalg.norm(sim_uav.current_position - sim_target.position)
                    
                    task = {
                        'target_id': target.id,
                        'step': step_counter,
                        'distance': distance,
                        'speed': 15.0, # é»˜è®¤é€Ÿåº¦
                        'arrival_time': step_counter * (distance / 15.0), # ç®€åŒ–åˆ°è¾¾æ—¶é—´
                        'is_sync_feasible': True,
                        'resource_cost': actual_contribution,
                    }
                    final_plan[uav.id].append(task)
                    
                    # --- [æ–°å¢] æ›´æ–°æ¨¡æ‹ŸçŠ¶æ€ ---
                    sim_uav.resources -= actual_contribution
                    sim_target.remaining_resources -= actual_contribution
                    sim_uav.current_position = sim_target.position # æ›´æ–°UAVä½ç½®

            except Exception as e:
                print(f"åœ¨æ¨¡æ‹ŸåŠ¨ä½œåºåˆ—é‡å»ºæ–¹æ¡ˆæ—¶å‡ºé”™: {e}")
                continue
        
        return final_plan

    def start_evaluation(self, model_paths: Union[str, List[str]], scenario_name: str = "small"):
        """
        å¯åŠ¨è¯„ä¼°è¿‡ç¨‹
        
        Args:
            model_paths (Union[str, List[str]]): æ¨¡å‹è·¯å¾„ï¼Œå•ä¸ªè·¯å¾„æˆ–è·¯å¾„åˆ—è¡¨
            scenario_name (str): åœºæ™¯åç§°
        """
        print("=" * 60)
        print("å¼€å§‹æ¨¡å‹è¯„ä¼°")
        print("=" * 60)
        
        # å¤„ç†æ¨¡å‹è·¯å¾„å¹¶å®šä¹‰æ–‡ä»¶ååç¼€
        if isinstance(model_paths, str):
            model_paths = [model_paths]
            inference_mode = "å•æ¨¡å‹æ¨ç†"
            suffix = '_single_inference'  # æ–°å¢ï¼šå•æ¨¡å‹æ¨ç†åç¼€
        elif len(model_paths) == 1:
            # åªæœ‰ä¸€ä¸ªæ¨¡å‹çš„æƒ…å†µï¼Œä¹Ÿè®¤ä¸ºæ˜¯å•æ¨¡å‹æ¨ç†
            inference_mode = "å•æ¨¡å‹æ¨ç†"
            suffix = '_single_inference'  # å•æ¨¡å‹æ¨ç†åç¼€
        else:
            inference_mode = "é›†æˆæ¨ç†"
            suffix = '_ensemble_inference'  # æ–°å¢ï¼šé›†æˆæ¨ç†åç¼€
        
        print(f"æ¨ç†æ¨¡å¼: {inference_mode}")
        print(f"æ¨¡å‹æ•°é‡: {len(model_paths)}")
        print(f"è¯„ä¼°åœºæ™¯: {scenario_name}")
        
        # æ˜¾ç¤ºè·¯å¾„è§„åˆ’ç®—æ³•ä¿¡æ¯
        train_algo = "é«˜ç²¾åº¦PH-RRT" if getattr(self.config, 'USE_PHRRT_DURING_TRAINING', False) else "å¿«é€Ÿè¿‘ä¼¼"
        plan_algo = "é«˜ç²¾åº¦PH-RRT" if getattr(self.config, 'USE_PHRRT_DURING_PLANNING', False) else "å¿«é€Ÿè¿‘ä¼¼"
        print(f"è®­ç»ƒç®—æ³•: {train_algo}")
        print(f"è§„åˆ’ç®—æ³•: {plan_algo}")
        print("=" * 60)
        
        start_time = time.time()
        
        # åŠ è½½åœºæ™¯
        uavs, targets, obstacles = self._load_scenario(scenario_name)
        
        if len(model_paths) == 1:
            results = self._single_model_inference(model_paths[0], uavs, targets, obstacles, scenario_name)
        else:
            results = self._ensemble_inference(model_paths, uavs, targets, obstacles, scenario_name)
        
        end_time = time.time()
        self.evaluation_stats['evaluation_time'] = end_time - start_time
        
        # --- å•ä¸€æ•°æ®æºå¤„ç†æµç¨‹ ---
        if results:
            # 1. é‡å»ºå¸¦æœ‰æ­£ç¡®èµ„æºæ¶ˆè€—çš„è§„åˆ’æ–¹æ¡ˆ
            final_plan = self._convert_results_to_plan(results, uavs, targets)
            
            # 2. è°ƒç”¨æƒå¨è¯„ä¼°å‡½æ•°ï¼Œç”Ÿæˆå”¯ä¸€çš„è¯„ä¼°æŒ‡æ ‡
            evaluation_metrics = evaluate_plan(
                final_plan, uavs, targets, final_uav_states=results.get('final_uav_states')
            )
            
            # 3. å°†æƒå¨è¯„ä¼°ç»“æœåˆå¹¶åˆ°resultsä¸­ï¼Œä½œä¸ºå”¯ä¸€æ•°æ®æº
            results.update(evaluation_metrics)

            # 4. å¤„ç†è¯„ä¼°ç»“æœï¼ˆç”¨äºæ§åˆ¶å°è¾“å‡ºï¼‰
            self._process_evaluation_results(results)

            # 5. ç”Ÿæˆå®Œæ•´çš„å¯è§†åŒ–ç»“æœï¼ˆç”¨äºæŠ¥å‘Šå’Œå›¾ç‰‡ï¼‰
            self._generate_complete_visualization(scenario_name, inference_mode, uavs, targets, obstacles, results, suffix)

        print(f"\nè¯„ä¼°å®Œæˆ! æ€»è€—æ—¶: {self.evaluation_stats['evaluation_time']:.2f}ç§’")
    
    def _load_scenario(self, scenario_name: str):
        """
        åŠ è½½æŒ‡å®šåœºæ™¯ - æ”¯æŒé™æ€å’ŒåŠ¨æ€åœºæ™¯
        
        Args:
            scenario_name (str): åœºæ™¯åç§°
            
        Returns:
            tuple: (uavs, targets, obstacles)
        """
        obstacle_tolerance = getattr(self.config, 'OBSTACLE_TOLERANCE', 50.0)
        
        # é™æ€é¢„å®šä¹‰åœºæ™¯
        if scenario_name == "balanced":
            return get_balanced_scenario(obstacle_tolerance)
        elif scenario_name == "small":
            print(f"ä½¿ç”¨é™æ€smallåœºæ™¯è¿›è¡Œæ¨ç†")
            return get_small_scenario(obstacle_tolerance)
        elif scenario_name == "complex":
            return get_complex_scenario(obstacle_tolerance)
        # åŠ¨æ€åœºæ™¯
        elif scenario_name in ["easy", "medium", "hard"]:
            print(f"ä½¿ç”¨åŠ¨æ€{scenario_name}åœºæ™¯è¿›è¡Œæ¨ç†")
            # å¯¹äºåŠ¨æ€åœºæ™¯ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚
            # çœŸæ­£çš„åœºæ™¯å°†åœ¨ env.reset() è°ƒç”¨ä¸­ç”Ÿæˆã€‚
            return [], [], []
            # # åˆ›å»ºä¸´æ—¶ç¯å¢ƒæ¥ç”ŸæˆåŠ¨æ€åœºæ™¯
            # from environment import UAVTaskEnv
            # # ç›´æ¥åˆ›å»ºä¸´æ—¶ç¯å¢ƒï¼Œè®©ç¯å¢ƒå†…éƒ¨å¤„ç†å›¾åˆ›å»º
            # temp_env = UAVTaskEnv([], [], None, [], self.config, obs_mode="graph")
            # temp_env._initialize_entities(scenario_name)
            # return temp_env.uavs, temp_env.targets, temp_env.obstacles
        else:
            print(f"æœªçŸ¥åœºæ™¯åç§°: {scenario_name}ï¼Œä½¿ç”¨é»˜è®¤smallåœºæ™¯")
            return get_small_scenario(obstacle_tolerance)
    
    def _single_model_inference(self, model_path: str, uavs, targets, obstacles, scenario_name='easy'):
        """
        å•æ¨¡å‹æ¨ç†ï¼ˆä½¿ç”¨Softmaxé‡‡æ ·ï¼‰
        
        Args:
            model_path (str): æ¨¡å‹è·¯å¾„
            uavs: UAVåˆ—è¡¨
            targets: ç›®æ ‡åˆ—è¡¨
            obstacles: éšœç¢ç‰©åˆ—è¡¨
            scenario_name (str): åœºæ™¯åç§°ï¼Œç”¨äºç¯å¢ƒé‡ç½®
            
        Returns:
            dict: æ¨ç†ç»“æœ
        """
        print(f"æ‰§è¡Œå•æ¨¡å‹æ¨ç†: {model_path}")
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            print(f"é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ - {model_path}")
            return None
        
        # åˆ›å»ºå›¾å’Œç¯å¢ƒ
        graph = DirectedGraph(uavs, targets, self.config.GRAPH_N_PHI, obstacles, self.config)
        
        # è®¡ç®—è¾“å…¥è¾“å‡ºç»´åº¦
        if self.config.NETWORK_TYPE == "ZeroShotGNN":
            obs_mode = "graph"
            i_dim = 64  # å ä½å€¼
            o_dim = len(targets) * len(uavs) * graph.n_phi

            if o_dim <= 0 and scenario_name in ["easy", "medium", "hard"]:
                # å¦‚æœæ˜¯åŠ¨æ€åœºæ™¯ä¸”åˆå§‹ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§å®ä½“æ•°æ¥åˆ›å»ºç½‘ç»œ
                max_o_dim = self.config.MAX_TARGETS * self.config.MAX_UAVS * self.config.GRAPH_N_PHI
                o_dim = max_o_dim
                # ä¸ºäº†åŒºåˆ†ï¼Œå¯ä»¥åœ¨æ—¥å¿—ä¸­æ·»åŠ ä¸åŒçš„æç¤º
                if "_ensemble" in self.start_evaluation.__name__: # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„åˆ¤æ–­ï¼Œå®é™…åº”çœ‹è°ƒç”¨æ ˆ
                     print(f"åŠ¨æ€åœºæ™¯é›†æˆæ¨ç†ï¼šä½¿ç”¨æœ€å¤§åŠ¨ä½œç©ºé—´å ä½ç¬¦ o_dim={o_dim}")
                else:
                     print(f"åŠ¨æ€åœºæ™¯å•æ¨¡å‹æ¨ç†ï¼šä½¿ç”¨æœ€å¤§åŠ¨ä½œç©ºé—´å ä½ç¬¦ o_dim={o_dim}")

        else:
            obs_mode = "flat"
            target_dim = 7 * len(targets)
            uav_dim = 8 * len(uavs)
            collaboration_dim = len(targets) * len(uavs)
            global_dim = 10
            i_dim = target_dim + uav_dim + collaboration_dim + global_dim
            o_dim = len(targets) * len(uavs) * graph.n_phi
        
        # åˆ›å»ºç½‘ç»œå¹¶åŠ è½½æ¨¡å‹
        network = create_network(
            self.config.NETWORK_TYPE, 
            i_dim, 
            self.config.hyperparameters.hidden_dim, 
            o_dim, 
            self.config
        ).to(self.device)
        
        try:
            # åŠ è½½æ¨¡å‹æ–‡ä»¶
            try:
                # é¦–å…ˆå°è¯•ä½¿ç”¨weights_only=FalseåŠ è½½
                try:
                    model_data = torch.load(model_path, map_location=self.device, weights_only=False)
                except TypeError as type_error:
                    # å¤„ç†PyTorch 2.6ç‰ˆæœ¬ä¸­weights_onlyå‚æ•°çš„å˜åŒ–
                    if "got an unexpected keyword argument 'weights_only'" in str(type_error):
                        print(f"å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒweights_onlyå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°åŠ è½½")
                        model_data = torch.load(model_path, map_location=self.device)
                    else:
                        raise
                except Exception as check_error:
                    print(f"æ ¼å¼æ£€æŸ¥æ—¶ä½¿ç”¨weights_only=FalseåŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨weights_only=True: {check_error}")
                    try:
                        model_data = torch.load(model_path, map_location=self.device, weights_only=True)
                    except TypeError as type_error:
                        # å¤„ç†PyTorch 2.6ç‰ˆæœ¬ä¸­weights_onlyå‚æ•°çš„å˜åŒ–
                        if "got an unexpected keyword argument 'weights_only'" in str(type_error):
                            print(f"å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒweights_onlyå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°åŠ è½½")
                            model_data = torch.load(model_path, map_location=self.device)
                        else:
                            raise
            except Exception as load_error:
                # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨weights_only=TrueåŠ è½½
                print(f"ä½¿ç”¨weights_only=FalseåŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨weights_only=True: {load_error}")
                try:
                    model_data = torch.load(model_path, map_location=self.device, weights_only=True)
                except TypeError as type_error:
                    # å¤„ç†PyTorch 2.6ç‰ˆæœ¬ä¸­weights_onlyå‚æ•°çš„å˜åŒ–
                    if "got an unexpected keyword argument 'weights_only'" in str(type_error):
                        print(f"å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒweights_onlyå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°åŠ è½½")
                        model_data = torch.load(model_path, map_location=self.device)
                    else:
                        raise
            
            # æ£€æŸ¥æ¨¡å‹æ•°æ®æ ¼å¼
            if isinstance(model_data, dict) and 'model_state_dict' in model_data:
                # æ–°æ ¼å¼ï¼šåŒ…å«æ¨¡å‹çŠ¶æ€å’Œé¢å¤–ä¿¡æ¯
                network.load_state_dict(model_data['model_state_dict'])
                print(f"æ¨¡å‹åŠ è½½æˆåŠŸ(æ–°æ ¼å¼): {os.path.basename(model_path)}")
            else:
                # æ—§æ ¼å¼ï¼šç›´æ¥æ˜¯çŠ¶æ€å­—å…¸
                network.load_state_dict(model_data)
                print(f"æ¨¡å‹åŠ è½½æˆåŠŸ(æ—§æ ¼å¼): {os.path.basename(model_path)}")
            
            network.eval()
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"å°è¯•æ£€æŸ¥æ¨¡å‹æ ¼å¼...")
            try:
                model_data = torch.load(model_path, map_location=self.device, weights_only=False)
                print(f"æ¨¡å‹æ•°æ®ç±»å‹: {type(model_data)}")
                if isinstance(model_data, dict):
                    print(f"æ¨¡å‹æ•°æ®é”®: {list(model_data.keys())}")
            except Exception as inner_e:
                print(f"æ¨¡å‹æ ¼å¼æ£€æŸ¥å¤±è´¥: {inner_e}")
            return None
        
        # åˆ›å»ºç¯å¢ƒ
        env = UAVTaskEnv(uavs, targets, graph, obstacles, self.config, obs_mode=obs_mode)
        
        # æ‰§è¡Œæ¨ç†ï¼Œä¼ é€’scenario_nameå‚æ•°
        results = self._run_inference(network, env, use_softmax_sampling=True, scenario_name=scenario_name)
        
        return results
    
    def _ensemble_inference(self, model_paths: List[str], uavs, targets, obstacles, scenario_name='easy'):
        """
        é›†æˆæ¨ç†ï¼ˆé›†æˆSoftmaxï¼‰
        
        Args:
            model_paths (List[str]): æ¨¡å‹è·¯å¾„åˆ—è¡¨
            uavs: UAVåˆ—è¡¨
            targets: ç›®æ ‡åˆ—è¡¨
            obstacles: éšœç¢ç‰©åˆ—è¡¨
            scenario_name (str): åœºæ™¯åç§°ï¼Œç”¨äºç¯å¢ƒé‡ç½®
            
        Returns:
            dict: æ¨ç†ç»“æœ
        """
        print(f"æ‰§è¡Œé›†æˆæ¨ç†ï¼Œæ¨¡å‹æ•°é‡: {len(model_paths)}")
        
        # æ£€æŸ¥æ‰€æœ‰æ¨¡å‹æ–‡ä»¶
        valid_models = []
        for path in model_paths:
            if os.path.exists(path):
                valid_models.append(path)
            else:
                print(f"è­¦å‘Š: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ - {path}")
        
        if not valid_models:
            print("é”™è¯¯: æ²¡æœ‰æœ‰æ•ˆçš„æ¨¡å‹æ–‡ä»¶")
            return None
        
        print(f"æœ‰æ•ˆæ¨¡å‹æ•°é‡: {len(valid_models)}")
        
        # åˆ›å»ºå›¾å’Œç¯å¢ƒ
        graph = DirectedGraph(uavs, targets, self.config.GRAPH_N_PHI, obstacles, self.config)
        
        # è®¡ç®—è¾“å…¥è¾“å‡ºç»´åº¦
        if self.config.NETWORK_TYPE == "ZeroShotGNN":
            obs_mode = "graph"
            i_dim = 64
            o_dim = len(targets) * len(uavs) * graph.n_phi
            if o_dim <= 0 and scenario_name in ["easy", "medium", "hard"]:
                # å¦‚æœæ˜¯åŠ¨æ€åœºæ™¯ä¸”åˆå§‹ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§å®ä½“æ•°æ¥åˆ›å»ºç½‘ç»œ
                max_o_dim = self.config.MAX_TARGETS * self.config.MAX_UAVS * self.config.GRAPH_N_PHI
                o_dim = max_o_dim
                # ä¸ºäº†åŒºåˆ†ï¼Œå¯ä»¥åœ¨æ—¥å¿—ä¸­æ·»åŠ ä¸åŒçš„æç¤º
                if "_ensemble" in self.start_evaluation.__name__: # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„åˆ¤æ–­ï¼Œå®é™…åº”çœ‹è°ƒç”¨æ ˆ
                     print(f"åŠ¨æ€åœºæ™¯é›†æˆæ¨ç†ï¼šä½¿ç”¨æœ€å¤§åŠ¨ä½œç©ºé—´å ä½ç¬¦ o_dim={o_dim}")
                else:
                     print(f"åŠ¨æ€åœºæ™¯å•æ¨¡å‹æ¨ç†ï¼šä½¿ç”¨æœ€å¤§åŠ¨ä½œç©ºé—´å ä½ç¬¦ o_dim={o_dim}")

        else:
            obs_mode = "flat"
            target_dim = 7 * len(targets)
            uav_dim = 8 * len(uavs)
            collaboration_dim = len(targets) * len(uavs)
            global_dim = 10
            i_dim = target_dim + uav_dim + collaboration_dim + global_dim
            o_dim = len(targets) * len(uavs) * graph.n_phi
        
        # åŠ è½½æ‰€æœ‰æ¨¡å‹
        networks = []
        for model_path in valid_models:
            network = create_network(
                self.config.NETWORK_TYPE,
                i_dim,
                self.config.hyperparameters.hidden_dim,
                o_dim,
                self.config
            ).to(self.device)
            
            try:
                # åŠ è½½æ¨¡å‹æ–‡ä»¶
                try:
                    # é¦–å…ˆå°è¯•ä½¿ç”¨weights_only=FalseåŠ è½½
                    model_data = torch.load(model_path, map_location=self.device, weights_only=False)
                except TypeError as type_error:
                    # å¤„ç†PyTorch 2.6ç‰ˆæœ¬ä¸­weights_onlyå‚æ•°çš„å˜åŒ–
                    if "got an unexpected keyword argument 'weights_only'" in str(type_error):
                        print(f"å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒweights_onlyå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°åŠ è½½")
                        model_data = torch.load(model_path, map_location=self.device)
                    else:
                        raise
                except Exception as load_error:
                    # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨weights_only=TrueåŠ è½½
                    print(f"ä½¿ç”¨weights_only=FalseåŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨weights_only=True: {load_error}")
                    try:
                        model_data = torch.load(model_path, map_location=self.device, weights_only=True)
                    except TypeError as type_error:
                        # å¤„ç†PyTorch 2.6ç‰ˆæœ¬ä¸­weights_onlyå‚æ•°çš„å˜åŒ–
                        if "got an unexpected keyword argument 'weights_only'" in str(type_error):
                            print(f"å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒweights_onlyå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°åŠ è½½")
                            model_data = torch.load(model_path, map_location=self.device)
                        else:
                            raise
                
                # æ£€æŸ¥æ¨¡å‹æ•°æ®æ ¼å¼
                if isinstance(model_data, dict) and 'model_state_dict' in model_data:
                    # æ–°æ ¼å¼ï¼šåŒ…å«æ¨¡å‹çŠ¶æ€å’Œé¢å¤–ä¿¡æ¯
                    network.load_state_dict(model_data['model_state_dict'])
                    print(f"æ¨¡å‹åŠ è½½æˆåŠŸ(æ–°æ ¼å¼): {os.path.basename(model_path)}")
                else:
                    # æ—§æ ¼å¼ï¼šç›´æ¥æ˜¯çŠ¶æ€å­—å…¸
                    network.load_state_dict(model_data)
                    print(f"æ¨¡å‹åŠ è½½æˆåŠŸ(æ—§æ ¼å¼): {os.path.basename(model_path)}")
                
                network.eval()
                networks.append(network)
            except Exception as e:
                print(f"æ¨¡å‹åŠ è½½å¤±è´¥ {model_path}: {e}")
                print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                print(f"å°è¯•æ£€æŸ¥æ¨¡å‹æ ¼å¼...")
                try:
                    model_data = torch.load(model_path, map_location=self.device, weights_only=False)
                    print(f"æ¨¡å‹æ•°æ®ç±»å‹: {type(model_data)}")
                    if isinstance(model_data, dict):
                        print(f"æ¨¡å‹æ•°æ®é”®: {list(model_data.keys())}")
                except Exception as inner_e:
                    print(f"æ¨¡å‹æ ¼å¼æ£€æŸ¥å¤±è´¥: {inner_e}")
        
        if not networks:
            print("é”™è¯¯: æ²¡æœ‰æˆåŠŸåŠ è½½çš„æ¨¡å‹")
            return None
        
        # åˆ›å»ºç¯å¢ƒ
        env = UAVTaskEnv(uavs, targets, graph, obstacles, self.config, obs_mode=obs_mode)
        
        # æ‰§è¡Œé›†æˆæ¨ç†ï¼Œä¼ é€’scenario_nameå‚æ•°
        results = self._run_ensemble_inference(networks, env, scenario_name)
        
        return results
    
    def _run_inference(self, network, env, use_softmax_sampling=True, scenario_name='easy'):
        """
        è¿è¡Œå•æ¨¡å‹æ¨ç†
        
        Args:
            network: ç¥ç»ç½‘ç»œæ¨¡å‹
            env: ç¯å¢ƒ
            use_softmax_sampling (bool): æ˜¯å¦ä½¿ç”¨Softmaxé‡‡æ ·
            scenario_name (str): åœºæ™¯åç§°ï¼Œç”¨äºç¯å¢ƒé‡ç½®
            
        Returns:
            dict: æ¨ç†ç»“æœ
        """
        # ã€ä¿®å¤ã€‘åœ¨ç¯å¢ƒé‡ç½®æ—¶ä¼ é€’æ­£ç¡®çš„scenario_nameå‚æ•°ï¼Œæ¨ç†æ—¶é™é»˜é‡ç½®
        reset_options = {'scenario_name': scenario_name, 'silent_reset': True}
        reset_result = env.reset(options=reset_options)
        # å¤„ç†resetè¿”å›çš„tupleæ ¼å¼ (state, info)
        if isinstance(reset_result, tuple):
            state = reset_result[0]
        else:
            state = reset_result
        total_reward = 0.0
        step_count = 0
        max_steps = 100
        action_sequence = []
        
        with torch.no_grad():
            while step_count < max_steps:
                # å‡†å¤‡çŠ¶æ€å¼ é‡
                if env.obs_mode == "flat":
                    state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)
                else:  # graph mode
                    state_tensor = {}
                    for key, value in state.items():
                        if key == "masks":
                            mask_tensor = {}
                            for mask_key, mask_value in value.items():
                                mask_tensor[mask_key] = torch.tensor(mask_value).unsqueeze(0).to(self.device)
                            state_tensor[key] = mask_tensor
                        else:
                            state_tensor[key] = torch.FloatTensor(value).unsqueeze(0).to(self.device)
                
                # è·å–Qå€¼
                q_values = network(state_tensor)
                
                # è·å–åŠ¨ä½œæ©ç 
                action_mask = env.get_action_mask()
                valid_actions = np.where(action_mask)[0]
                
                if len(valid_actions) == 0:
                    break
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºåŠ¨ä½œå€™é€‰åˆ—è¡¨
                if self.config.ENABLE_DEBUG:
                    print(f"\n[DEBUG] æ­¥éª¤ {step_count + 1} åŠ¨ä½œå€™é€‰åˆ—è¡¨: "
                          f"  æœ‰æ•ˆåŠ¨ä½œæ•°é‡: {len(valid_actions)}"
                          f"  æœ‰æ•ˆåŠ¨ä½œç´¢å¼•: {valid_actions.tolist()}")
                    
                    # æ˜¾ç¤ºæ‰€æœ‰åŠ¨ä½œçš„è¯¦ç»†ä¿¡æ¯
                    for i, action_idx in enumerate(valid_actions):
                        try:
                            target_idx, uav_idx, phi_idx = env._action_to_assignment(action_idx)
                            target = env.targets[target_idx]
                            uav = env.uavs[uav_idx]
                            q_value = q_values[0][action_idx].item()
                            
                            # è®¡ç®—è·ç¦»å’Œèµ„æºä¿¡æ¯
                            uav_pos = uav.position
                            target_pos = target.position
                            distance = np.linalg.norm(uav_pos - target_pos)
                            
                            # è·å–UAVå½“å‰èµ„æºå’Œç›®æ ‡éœ€æ±‚
                            uav_resources = uav.resources
                            target_needs = target.resources
                            
                            # è®¡ç®—å¯èƒ½çš„èµ„æºè´¡çŒ®
                            possible_contribution = np.minimum(uav_resources, target_needs)
                            total_possible = np.sum(possible_contribution)
                        

                            print(f"    åŠ¨ä½œ{i+1} (ç´¢å¼•{action_idx}): UAV{uav.id}->Target{target.id}"
                                  f"      - Qå€¼: {q_value:.3f}"
                                  f"      - è·ç¦»: {distance:.2f}m"
                                  f"      - UAVèµ„æº: {uav_resources}"
                                  f"      - ç›®æ ‡éœ€æ±‚: {target_needs}"
                                  f"      - å¯èƒ½è´¡çŒ®: {possible_contribution} (æ€»è®¡: {total_possible:.1f})")

                        except Exception as e:
                            print(f"    åŠ¨ä½œ{i+1} (ç´¢å¼•{action_idx}): è§£æå¤±è´¥ - {e}"
                                  f"      - Qå€¼: {q_values[0][action_idx].item():.3f}")
                
                # é€‰æ‹©åŠ¨ä½œ
                if use_softmax_sampling:
                    # Softmaxé‡‡æ ·
                    valid_q_values = q_values[0][valid_actions]
                    probs = torch.softmax(valid_q_values / 0.1, dim=0)  # æ¸©åº¦å‚æ•°0.1
                    action_idx = torch.multinomial(probs, 1).item()
                    action = valid_actions[action_idx]
                    
                    # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºé€‰æ‹©è¿‡ç¨‹
                    if self.config.ENABLE_DEBUG:
                        selected_prob = probs[action_idx].item()
                        print(f"  [DEBUG] Softmaxé‡‡æ ·é€‰æ‹©è¿‡ç¨‹:" 
                            f"    - æœ‰æ•ˆQå€¼: {valid_q_values.tolist()}"
                            f"    - é€‰æ‹©æ¦‚ç‡: {probs.tolist()}"
                            f"    - é€‰æ‹©ç´¢å¼•: {action_idx} \n"
                            f"    - æœ€ç»ˆåŠ¨ä½œ: {action}, æ¦‚ç‡: {selected_prob:.4f}")
                else:
                    # è´ªå©ªé€‰æ‹©
                    masked_q_values = q_values[0].clone()
                    masked_q_values[~torch.tensor(action_mask, dtype=torch.bool)] = float('-inf')
                    action = masked_q_values.argmax().item()
                    
                    # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºè´ªå©ªé€‰æ‹©
                    if self.config.ENABLE_DEBUG:
                        max_q_value = masked_q_values[action].item()
                        print(f"  [DEBUG] è´ªå©ªé€‰æ‹©è¿‡ç¨‹:")
                        print(f"    - æœ€å¤§Qå€¼: {max_q_value:.3f}")
                        print(f"    - é€‰æ‹©åŠ¨ä½œ: {action}")
                
                # æ‰§è¡ŒåŠ¨ä½œå‰æ£€æŸ¥æ˜¯å¦æœ‰å®é™…è´¡çŒ®ï¼ˆåŒé‡éªŒè¯ï¼‰
                target_idx, uav_idx, phi_idx = env._action_to_assignment(action)
                target = env.targets[target_idx]
                uav = env.uavs[uav_idx]
                
                # åŒé‡æ£€æŸ¥ï¼šç¡®ä¿åŠ¨ä½œæœ‰æ•ˆä¸”æœ‰å®é™…è´¡çŒ®
                if not env._is_valid_action(target, uav, phi_idx) or not env._has_actual_contribution(target, uav):
                    # è·³è¿‡æ— æ•ˆæˆ–æ— è´¡çŒ®çš„åŠ¨ä½œ
                    print(f"âš ï¸ è·³è¿‡æ— æ•ˆåŠ¨ä½œ: UAV{uav.id} -> Target{target.id} (æ— èµ„æºè´¡çŒ®)")
                    continue
                
                # æ‰§è¡ŒåŠ¨ä½œ
                next_state, reward, done, truncated, info = env.step(action)
                # ä»infoä¸­æå–reward_breakdown
                reward_breakdown = info.get('reward_breakdown', {})

                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                if self.config.ENABLE_DEBUG:
                    print(f"[DEBUG] æ­¥éª¤ {step_count + 1}: UAV{uav.id} -> Target{target.id}, åŠ¨ä½œ={action}, å¥–åŠ±={reward:.2f}")

                # å¦‚æœå¥–åŠ±å¼‚å¸¸ï¼ˆå°äº-100ï¼‰ï¼Œæ‰“å°è¯¦ç»†çš„å¥–åŠ±åˆ†è§£
                if reward < -100:
                    print(f"\n[DEBUG] å¼‚å¸¸å¥–åŠ±æ£€æµ‹! å¥–åŠ±å€¼: {reward:.2f}")
                    print("è¯¦ç»†å¥–åŠ±åˆ†è§£:")
                    if reward_breakdown:
                        # æ‰“å°ç¬¬ä¸€å±‚å¥–åŠ±åˆ†è§£
                        if 'layer1_breakdown' in reward_breakdown:
                            print("  ç¬¬ä¸€å±‚å¥–åŠ± (èµ„æºåŒ¹é…):")
                            for key, value in reward_breakdown['layer1_breakdown'].items():
                                print(f"    {key}: {value:.4f}")
                            print(f"  ç¬¬ä¸€å±‚æ€»è®¡: {reward_breakdown.get('layer1_total', 0):.4f}")
                        
                        # æ‰“å°ç¬¬äºŒå±‚å¥–åŠ±åˆ†è§£
                        if 'layer2_breakdown' in reward_breakdown:
                            print("  ç¬¬äºŒå±‚å¥–åŠ± (ä¼˜åŒ–é€‰æ‹©):")
                            for key, value in reward_breakdown['layer2_breakdown'].items():
                                print(f"    {key}: {value:.4f}")
                            print(f"  ç¬¬äºŒå±‚æ€»è®¡: {reward_breakdown.get('layer2_total', 0):.4f}")
                        
                        # æ‰“å°å…¶ä»–å¥–åŠ±ä¿¡æ¯
                        other_keys = ['base_reward', 'shaping_reward', 'final_total_reward', 'was_clipped']
                        for key in other_keys:
                            if key in reward_breakdown:
                                print(f"  {key}: {reward_breakdown[key]}")
                    else:
                        print("  æœªæ‰¾åˆ°è¯¦ç»†å¥–åŠ±åˆ†è§£ä¿¡æ¯")
                    print()

                total_reward += reward
                action_sequence.append(action)
                state = next_state
                step_count += 1
                
                if done or truncated:
                    break
        
        # ã€é‡è¦ä¿®å¤ã€‘ä»¥æ¨ç†ç»“æœä¸ºå‡†ï¼Œè®°å½•æ¨ç†ç»“æŸæ—¶çš„ä»»åŠ¡åˆ†é…æ–¹æ¡ˆ
        # æ¨ç†è¿‡ç¨‹å·²ç»å®Œæˆäº†ä»»åŠ¡åˆ†é…å†³ç­–ï¼Œå®é™…æ‰§è¡Œåªæ˜¯è¿›è¡Œè·¯å¾„è§„åˆ’ç­‰åç»­å·¥ä½œ
        
        # è®¡ç®—æ¨ç†ç»“æŸæ—¶çš„å®Œæˆç‡ï¼ˆåŸºäºæ¨ç†ç»“æœï¼‰
        total_demand = np.sum([t.resources for t in env.targets], axis=0)
        total_contribution = np.zeros_like(total_demand, dtype=np.float64)
        for target in env.targets:
            target_contribution = target.resources - target.remaining_resources
            total_contribution += target_contribution.astype(np.float64)
        
        total_demand_sum = np.sum(total_demand)
        total_contribution_sum = np.sum(total_contribution)
        completion_rate = total_contribution_sum / total_demand_sum if total_demand_sum > 0 else 1.0
        
        # ã€è°ƒè¯•ã€‘æ˜¾ç¤ºæ¨ç†ç»“æŸæ—¶çš„ä»»åŠ¡åˆ†é…ç»“æœ
        print(f"[DEBUG] æ¨ç†ä»»åŠ¡åˆ†é…ç»“æœ:")
        print(f"  - æ€»éœ€æ±‚: {total_demand} (æ€»å’Œ: {total_demand_sum})")
        print(f"  - æ¨ç†åˆ†é…æ€»è´¡çŒ®: {total_contribution} (æ€»å’Œ: {total_contribution_sum})")
        print(f"  - æ¨ç†å®Œæˆç‡: {completion_rate:.4f}")
        
        # è®¡ç®—ç›®æ ‡å®Œæˆç‡ï¼ˆå®Œå…¨æ»¡è¶³çš„ç›®æ ‡æ•°é‡æ¯”ä¾‹ï¼‰
        satisfied_targets = sum(1 for t in env.targets if np.all(t.remaining_resources <= 1e-6))
        total_targets = len(env.targets)
        target_completion_rate = satisfied_targets / total_targets if total_targets > 0 else 1.0
        print(f"  - æ¨ç†æ—¶å®Œå…¨æ»¡è¶³ç›®æ ‡æ•°: {satisfied_targets}/{total_targets}")
        print(f"  - æ¨ç†æ—¶ç›®æ ‡å®Œæˆç‡: {target_completion_rate:.4f}")
        
        # æ˜¾ç¤ºæ¯ä¸ªç›®æ ‡çš„è¯¦ç»†çŠ¶æ€
        for i, target in enumerate(env.targets):
            remaining = target.remaining_resources
            is_satisfied = np.all(remaining <= 1e-6)
            print(f"  - ç›®æ ‡{i+1}: å‰©ä½™éœ€æ±‚{remaining}, å®Œå…¨æ»¡è¶³: {is_satisfied}")
        
        # è®°å½•æ¨ç†ç»“æŸæ—¶çš„ä»»åŠ¡åˆ†é…æ–¹æ¡ˆ
        inference_task_assignments = {}
        for uav in env.uavs:
            inference_task_assignments[uav.id] = {
                'initial_resources': uav.initial_resources.copy(),
                'final_resources': uav.resources.copy(),
                'consumed_resources': uav.initial_resources - uav.resources
            }
        
        inference_target_status = {}
        for target in env.targets:
            inference_target_status[target.id] = {
                'required_resources': target.resources.copy(),
                'remaining_resources': target.remaining_resources.copy(),
                'contributed_resources': target.resources - target.remaining_resources
            }
        
        print(f"[DEBUG] æ¨ç†ä»»åŠ¡åˆ†é…æ–¹æ¡ˆå·²è®°å½•ï¼ŒåŒ…å«{len(inference_task_assignments)}ä¸ªUAVå’Œ{len(inference_target_status)}ä¸ªç›®æ ‡")
    
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºåŠ¨ä½œåºåˆ—
        if self.config.ENABLE_DEBUG:
            print(f"\n[DEBUG] æ¨ç†å®Œæˆï¼ŒåŠ¨ä½œåºåˆ—: {action_sequence}")
            print(f"[DEBUG] æ€»æ­¥æ•°: {step_count}, æ€»å¥–åŠ±: {total_reward:.2f}, å®Œæˆç‡: {completion_rate:.4f}")
        
        # ä¿å­˜æ¨ç†å®Œæˆåçš„UAVçŠ¶æ€ï¼Œç”¨äºèµ„æºåˆ©ç”¨ç‡è®¡ç®—
        final_uav_states = []
        for uav in env.uavs:
            final_uav_states.append({
                'id': uav.id,
                'initial_resources': uav.initial_resources.copy(),
                'final_resources': uav.resources.copy()
            })
        
        return {
            'total_reward': total_reward,
            'completion_rate': completion_rate,  # åŸºäºæ¨ç†ç»“æœè®¡ç®—çš„å®Œæˆç‡
            'step_count': step_count,
            'action_sequence': action_sequence,
            'final_state': state,
            'final_uav_states': final_uav_states,
            'inference_task_assignments': inference_task_assignments,  # æ¨ç†ä»»åŠ¡åˆ†é…æ–¹æ¡ˆ
            'inference_target_status': inference_target_status  # æ¨ç†ç›®æ ‡çŠ¶æ€
        }
    
    def _run_ensemble_inference(self, networks, env, scenario_name='easy'):
        """
        è¿è¡Œé›†æˆæ¨ç†
        
        Args:
            networks: ç½‘ç»œæ¨¡å‹åˆ—è¡¨
            env: ç¯å¢ƒ
            scenario_name (str): åœºæ™¯åç§°ï¼Œç”¨äºç¯å¢ƒé‡ç½®
            
        Returns:
            dict: æ¨ç†ç»“æœ
        """
        # ã€ä¿®å¤ã€‘åœ¨ç¯å¢ƒé‡ç½®æ—¶ä¼ é€’æ­£ç¡®çš„scenario_nameå‚æ•°ï¼Œæ¨ç†æ—¶é™é»˜é‡ç½®
        reset_options = {'scenario_name': scenario_name, 'silent_reset': True}
        reset_result = env.reset(options=reset_options)
        # å¤„ç†resetè¿”å›çš„tupleæ ¼å¼ (state, info)
        if isinstance(reset_result, tuple):
            state = reset_result[0]
        else:
            state = reset_result
        total_reward = 0.0
        step_count = 0
        max_steps = 100
        action_sequence = []
        
        with torch.no_grad():
            while step_count < max_steps:
                # å‡†å¤‡çŠ¶æ€å¼ é‡
                if env.obs_mode == "flat":
                    state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)
                else:  # graph mode
                    state_tensor = {}
                    for key, value in state.items():
                        if key == "masks":
                            mask_tensor = {}
                            for mask_key, mask_value in value.items():
                                mask_tensor[mask_key] = torch.tensor(mask_value).unsqueeze(0).to(self.device)
                            state_tensor[key] = mask_tensor
                        else:
                            state_tensor[key] = torch.FloatTensor(value).unsqueeze(0).to(self.device)
                
                # è·å–æ‰€æœ‰æ¨¡å‹çš„Qå€¼å¹¶å¹³å‡
                ensemble_q_values = None
                for network in networks:
                    q_values = network(state_tensor)
                    if ensemble_q_values is None:
                        ensemble_q_values = q_values
                    else:
                        ensemble_q_values += q_values
                
                ensemble_q_values /= len(networks)
                
                # è·å–åŠ¨ä½œæ©ç 
                action_mask = env.get_action_mask()
                valid_actions = np.where(action_mask)[0]
                
                if len(valid_actions) == 0:
                    break
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºåŠ¨ä½œå€™é€‰åˆ—è¡¨
                if self.config.ENABLE_DEBUG:
                    print(f"\n[DEBUG] é›†æˆæ¨ç†æ­¥éª¤ {step_count + 1} åŠ¨ä½œå€™é€‰åˆ—è¡¨:")
                    print(f"  æœ‰æ•ˆåŠ¨ä½œæ•°é‡: {len(valid_actions)}")
                    print(f"  æœ‰æ•ˆåŠ¨ä½œç´¢å¼•: {valid_actions.tolist()}")
                    
                    # æ˜¾ç¤ºæ‰€æœ‰åŠ¨ä½œçš„è¯¦ç»†ä¿¡æ¯
                    for i, action_idx in enumerate(valid_actions):
                        try:
                            target_idx, uav_idx, phi_idx = env._action_to_assignment(action_idx)
                            target = env.targets[target_idx]
                            uav = env.uavs[uav_idx]
                            q_value = ensemble_q_values[0][action_idx].item()
                            
                            # è®¡ç®—è·ç¦»å’Œèµ„æºä¿¡æ¯
                            uav_pos = uav.position
                            target_pos = target.position
                            distance = np.linalg.norm(uav_pos - target_pos)
                            
                            # è·å–UAVå½“å‰èµ„æºå’Œç›®æ ‡éœ€æ±‚
                            uav_resources = uav.resources
                            target_needs = target.resources
                            
                            # è®¡ç®—å¯èƒ½çš„èµ„æºè´¡çŒ®
                            possible_contribution = np.minimum(uav_resources, target_needs)
                            total_possible = np.sum(possible_contribution)
                            
                            print(f"    åŠ¨ä½œ{i+1} (ç´¢å¼•{action_idx}): UAV{uav.id}->Target{target.id}")
                            print(f"      - Qå€¼: {q_value:.3f}")
                            print(f"      - è·ç¦»: {distance:.2f}m")
                            print(f"      - UAVèµ„æº: {uav_resources}")
                            print(f"      - ç›®æ ‡éœ€æ±‚: {target_needs}")
                            print(f"      - å¯èƒ½è´¡çŒ®: {possible_contribution} (æ€»è®¡: {total_possible:.1f})")
                        except Exception as e:
                            print(f"    åŠ¨ä½œ{i+1} (ç´¢å¼•{action_idx}): è§£æå¤±è´¥ - {e}")
                            print(f"      - Qå€¼: {ensemble_q_values[0][action_idx].item():.3f}")
                
                # é›†æˆSoftmaxé‡‡æ ·
                valid_q_values = ensemble_q_values[0][valid_actions]
                probs = torch.softmax(valid_q_values / 0.1, dim=0)
                action_idx = torch.multinomial(probs, 1).item()
                action = valid_actions[action_idx]
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºé€‰æ‹©è¿‡ç¨‹
                if self.config.ENABLE_DEBUG:
                    selected_prob = probs[action_idx].item()
                    print(f"  [DEBUG] é›†æˆSoftmaxé‡‡æ ·é€‰æ‹©è¿‡ç¨‹:")
                    print(f"    - æœ‰æ•ˆQå€¼: {valid_q_values.tolist()}")
                    print(f"    - é€‰æ‹©æ¦‚ç‡: {probs.tolist()}")
                    print(f"    - é€‰æ‹©ç´¢å¼•: {action_idx}")
                    print(f"    - æœ€ç»ˆåŠ¨ä½œ: {action}, æ¦‚ç‡: {selected_prob:.4f}")
                
                # æ‰§è¡ŒåŠ¨ä½œå‰æ£€æŸ¥æ˜¯å¦æœ‰å®é™…è´¡çŒ®ï¼ˆåŒé‡éªŒè¯ï¼‰
                target_idx, uav_idx, phi_idx = env._action_to_assignment(action)
                target = env.targets[target_idx]
                uav = env.uavs[uav_idx]
                
                # åŒé‡æ£€æŸ¥ï¼šç¡®ä¿åŠ¨ä½œæœ‰æ•ˆä¸”æœ‰å®é™…è´¡çŒ®
                if not env._is_valid_action(target, uav, phi_idx) or not env._has_actual_contribution(target, uav):
                    # è·³è¿‡æ— æ•ˆæˆ–æ— è´¡çŒ®çš„åŠ¨ä½œ
                    print(f"âš ï¸ è·³è¿‡æ— æ•ˆåŠ¨ä½œ: UAV{uav.id} -> Target{target.id} (æ— èµ„æºè´¡çŒ®)")
                    continue
                
                # æ‰§è¡ŒåŠ¨ä½œ
                next_state, reward, done, truncated, info = env.step(action)
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                if self.config.ENABLE_DEBUG:
                    print(f"[DEBUG] æ­¥éª¤ {step_count + 1}: UAV{uav.id} -> Target{target.id}, åŠ¨ä½œ={action}, å¥–åŠ±={reward:.2f}")
                
                total_reward += reward
                action_sequence.append(action)
                state = next_state
                step_count += 1
                
                if done or truncated:
                    break
        
        # è®¡ç®—å®Œæˆç‡ - ä¿®å¤ï¼šä½¿ç”¨æ ‡å‡†è¯„ä¼°æŒ‡æ ‡çš„è®¡ç®—æ–¹å¼
        # åŸºäºèµ„æºè´¡çŒ®ä¸éœ€æ±‚çš„æ¯”ç‡ï¼Œè€Œä¸æ˜¯ç®€å•çš„ç›®æ ‡æ•°é‡æ¯”ç‡
        total_demand = np.sum([t.resources for t in env.targets], axis=0)
        total_demand_safe = np.maximum(total_demand, 1e-6)
        
        # è®¡ç®—å®é™…èµ„æºè´¡çŒ® - ä¿®å¤ï¼šç¡®ä¿ä½¿ç”¨floatç±»å‹é¿å…æ•°æ®ç±»å‹ä¸åŒ¹é…
        total_contribution = np.zeros_like(total_demand, dtype=np.float64)
        for target in env.targets:
            target_contribution = target.resources - target.remaining_resources
            total_contribution += target_contribution.astype(np.float64)
        
            # ã€ä¿®æ”¹ã€‘ä½¿ç”¨â€œæ€»è´¡çŒ®/æ€»éœ€æ±‚â€çš„æ ‡å‡†æ–¹æ³•è®¡ç®—å®Œæˆç‡
            total_demand_sum = np.sum(total_demand)
            total_contribution_sum = np.sum(np.minimum(total_contribution, total_demand))
            completion_rate = total_contribution_sum / total_demand_sum if total_demand_sum > 0 else 1.0
       
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºåŠ¨ä½œåºåˆ—
        if self.config.ENABLE_DEBUG:
            print(f"\n[DEBUG] é›†æˆæ¨ç†å®Œæˆï¼ŒåŠ¨ä½œåºåˆ—: {action_sequence}")
            print(f"[DEBUG] æ€»æ­¥æ•°: {step_count}, æ€»å¥–åŠ±: {total_reward:.2f}, å®Œæˆç‡: {completion_rate:.4f}")
        
        # ä¿å­˜æ¨ç†å®Œæˆåçš„UAVçŠ¶æ€ï¼Œç”¨äºèµ„æºåˆ©ç”¨ç‡è®¡ç®—
        final_uav_states = []
        for uav in env.uavs:
            final_uav_states.append({
                'id': uav.id,
                'initial_resources': uav.initial_resources.copy(),
                'final_resources': uav.resources.copy()
            })
        
        return {
            'total_reward': total_reward,
            'completion_rate': completion_rate,
            'step_count': step_count,
            'action_sequence': action_sequence,
            'final_state': state,
            'ensemble_size': len(networks),
            'final_uav_states': final_uav_states
        }
    
    def _process_evaluation_results(self, results):
        """å¤„ç†è¯„ä¼°ç»“æœ"""
        if results is None:
            print("è¯„ä¼°å¤±è´¥ï¼Œæ— æœ‰æ•ˆç»“æœ")
            return
        
        self.evaluation_stats['scenario_results'].append(results)
        self.evaluation_stats['average_completion_rate'] = results['completion_rate']
        
        # è®¡ç®—æ•ˆç‡ï¼ˆå¥–åŠ±/æ­¥æ•°ï¼‰
        efficiency = results['total_reward'] / max(results['step_count'], 1)
        self.evaluation_stats['average_efficiency'] = efficiency
        
        print(f"\nè¯„ä¼°ç»“æœ:"
            f"  æ€»å¥–åŠ±: {results['total_reward']:.2f}"
            f"  æ»¡è¶³ç‡: {results['completion_rate']:.3f}"
            f"  æ­¥æ•°: {results['step_count']}"
            f"  æ•ˆç‡: {efficiency:.2f}")
        
        if 'ensemble_size' in results:
            print(f"  é›†æˆè§„æ¨¡: {results['ensemble_size']}")
    



def start_evaluation(config: Config, model_paths: Union[str, List[str]], scenario_name: str = "small"):
    """
    è¯„ä¼°å…¥å£å‡½æ•°
    
    Args:
        config (Config): é…ç½®å¯¹è±¡
        model_paths (Union[str, List[str]]): æ¨¡å‹è·¯å¾„
        scenario_name (str): åœºæ™¯åç§°
    """
    evaluator = ModelEvaluator(config)
    evaluator.start_evaluation(model_paths, scenario_name)