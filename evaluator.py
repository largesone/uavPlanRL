# -*- coding: utf-8 -*-
# æ–‡ä»¶å: evaluator.py
# æè¿°: æ¨¡å‹è¯„ä¼°å’Œæ¨ç†æ¨¡å—ï¼Œæ”¯æŒå•æ¨¡å‹æ¨ç†å’Œé›†æˆæ¨ç†

import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
import time
import copy
import numpy as np
import torch
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from typing import List, Union, Optional

# æœ¬åœ°æ¨¡å—å¯¼å…¥
from entities import UAV, Target
from scenarios import get_balanced_scenario, get_small_scenario, get_complex_scenario
from environment import UAVTaskEnv, DirectedGraph
from networks import create_network
from config import Config
from evaluate import evaluate_plan
from collections import defaultdict
from matplotlib.font_manager import FontProperties, findfont
from datetime import datetime

# =============================================================================
# ä»main-old.pyè¿ç§»çš„æ ¸å¿ƒå¤„ç†ç±»
# =============================================================================

def set_chinese_font():
    """æŸ¥æ‰¾å¹¶è®¾ç½®ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“ï¼Œä»¥è§£å†³matplotlibä¸­æ–‡ä¹±ç é—®é¢˜ã€‚"""
    # æ‰©å±•çš„ä¸­æ–‡å­—ä½“åˆ—è¡¨ï¼ŒåŒ…å«æ›´å¤šå¸¸è§å­—ä½“
    font_names = [
        'SimHei', 'Microsoft YaHei', 'Microsoft YaHei UI', 
        'Heiti TC', 'Arial Unicode MS', 'DejaVu Sans',
        'WenQuanYi Micro Hei', 'Noto Sans CJK SC', 'Source Han Sans SC'
    ]
    
    # è·å–ç³»ç»Ÿå¯ç”¨å­—ä½“åˆ—è¡¨
    available_fonts = [f.name for f in fm.fontManager.ttflist]
    
    for font_name in font_names:
        if font_name in available_fonts:
            plt.rcParams['font.sans-serif'] = [font_name]
            plt.rcParams['axes.unicode_minus'] = False
            print(f"[DEBUG] ä¸­æ–‡å­—ä½“è®¾ç½®æˆåŠŸ: {font_name}")
            return font_name
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸“é—¨çš„ä¸­æ–‡å­—ä½“ï¼Œå°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“
    try:
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False
        print("[WARNING] æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“ï¼Œå¯èƒ½å­˜åœ¨ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜")
        return "Default"
    except Exception as e:
        print(f"[ERROR] å­—ä½“è®¾ç½®å¤±è´¥: {e}")
        return None


class PlanVisualizer:
    """æ–¹æ¡ˆå¯è§†åŒ–å™¨ - ä»main-old.pyè¿ç§»"""
    
    def __init__(self, config):
        self.config = config
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        set_chinese_font()
    
    def save(self, final_plan, uavs, targets, obstacles, scenario_name, training_time, 
             plan_generation_time, evaluation_metrics=None, deadlocked_tasks=None, suffix="", inference_mode="å•æ¨¡å‹æ¨ç†"):
        """
        ä¿å­˜å¯è§†åŒ–æ–¹æ¡ˆ - é‡æ„åç‰ˆæœ¬ï¼Œç¡®ä¿æ•°æ®æºå”¯ä¸€æ€§
        
        é‡æ„è¯´æ˜ï¼š
        - åˆ é™¤äº†å†…éƒ¨çš„èµ„æºæ¶ˆè€—ç²¾ç¡®æ¨¡æ‹Ÿé€»è¾‘ï¼Œé¿å…é‡å¤è®¡ç®—
        - ç›´æ¥ä½¿ç”¨ final_plan ä¸­çš„ resource_cost æ•°æ®ä½œä¸ºå”¯ä¸€æ•°æ®æº
        - ç®€åŒ–äº†ååŒäº‹ä»¶å¤„ç†ï¼Œåªè´Ÿè´£æ•°æ®æ ¼å¼åŒ–ä¸å¯è§†åŒ–å±•ç¤º
        - æ·»åŠ äº†æ•°æ®éªŒè¯å’Œè­¦å‘Šæœºåˆ¶
        
        Args:
            final_plan: ä»»åŠ¡åˆ†é…æ–¹æ¡ˆï¼ŒåŒ…å«æ¥è‡ªæ¨ç†ç»“æœçš„ resource_cost æ•°æ®
            uavs: æ— äººæœºåˆ—è¡¨
            targets: ç›®æ ‡åˆ—è¡¨
            obstacles: éšœç¢ç‰©åˆ—è¡¨
            scenario_name: åœºæ™¯åç§°
            training_time: è®­ç»ƒæ—¶é—´
            plan_generation_time: æ–¹æ¡ˆç”Ÿæˆæ—¶é—´
            evaluation_metrics: è¯„ä¼°æŒ‡æ ‡ï¼ˆå¯é€‰ï¼‰
            deadlocked_tasks: æ­»é”ä»»åŠ¡ï¼ˆå¯é€‰ï¼‰
            suffix: æ–‡ä»¶ååç¼€
            inference_mode: æ¨ç†æ¨¡å¼
            
        Returns:
            tuple: (æŠ¥å‘Šå†…å®¹, å›¾ç‰‡æ–‡ä»¶è·¯å¾„)
        """
        
        # ã€é‡æ„ä¿®æ”¹ã€‘ååŒäº‹ä»¶æ—¥å¿— - åŸºäºå·²æœ‰æ•°æ®ç”Ÿæˆï¼Œä¸è¿›è¡Œé‡å¤è®¡ç®—
        # åˆ é™¤äº†åŸæœ‰çš„ temp_uav_resources å’Œ temp_target_resources ç‹¬ç«‹è®¡ç®—é€»è¾‘
        # ç°åœ¨ç›´æ¥ä½¿ç”¨æ¨ç†ç»“æœä¸­çš„ resource_cost æ•°æ®ï¼Œç¡®ä¿æ•°æ®æºå”¯ä¸€æ€§
        collaboration_log = "\n\nååŒäº‹ä»¶æ—¥å¿— (åŸºäºæ¨ç†ç»“æœ):\n" + "-"*36 + "\n"
        
        # æŒ‰äº‹ä»¶åˆ†ç»„å¤„ç†ååŒä»»åŠ¡ - ä»…ç”¨äºæ—¥å¿—å±•ç¤º
        events = defaultdict(list)
        for uav_id, tasks in final_plan.items():
            for task in tasks:
                event_key = (task.get('arrival_time', 0), task['target_id'])
                events[event_key].append({'uav_id': uav_id, 'task_ref': task})
        
        sorted_event_keys = sorted(events.keys())

        # ç”ŸæˆååŒäº‹ä»¶æ—¥å¿— - ç›´æ¥ä½¿ç”¨æ¨ç†ç»“æœæ•°æ®
        for event_key in sorted_event_keys:
            arrival_time, target_id = event_key
            collaborating_steps = events[event_key]
            
            # è·å–ç›®æ ‡çš„åŸå§‹éœ€æ±‚
            target = next((t for t in targets if t.id == target_id), None)
            if target:
                target_demand = target.resources
                collaboration_log += f" * äº‹ä»¶: åœ¨ t={arrival_time:.2f}s, æ— äººæœº(UAVs) {', '.join([str(s['uav_id']) for s in collaborating_steps])} åˆ°è¾¾ ç›®æ ‡ {target_id}\n"
                collaboration_log += f"   - ç›®æ ‡éœ€æ±‚: {target_demand}\n"

                for step in collaborating_steps:
                    uav_id = step['uav_id']
                    task = step['task_ref']

                    # ç›´æ¥ä½¿ç”¨æ¨ç†ç»“æœä¸­çš„ resource_cost æ•°æ®
                    if 'resource_cost' in task and task['resource_cost'] is not None:
                        actual_contribution = task['resource_cost']
                        collaboration_log += f"     - UAV {uav_id} è´¡çŒ® {actual_contribution} (æ¥è‡ªæ¨ç†ç»“æœ)\n"
                    else:
                        # è®°å½•è¯¦ç»†è­¦å‘Šä¿¡æ¯
                        print(f"[WARNING] ååŒäº‹ä»¶æ•°æ®ä¸å®Œæ•´: UAV {uav_id} åˆ°è¾¾ç›®æ ‡ {target_id} çš„ä»»åŠ¡ç¼ºå°‘ resource_cost")
                        print(f"[WARNING] è¿™å¯èƒ½è¡¨æ˜æ¨ç†è¿‡ç¨‹ä¸­çš„æ•°æ®è®°å½•é—®é¢˜")
                        collaboration_log += f"     - UAV {uav_id} è´¡çŒ®æ•°æ®ç¼ºå¤± (è­¦å‘Š: æ•°æ®ä¸å®Œæ•´)\n"
                
                collaboration_log += f"   - äº‹ä»¶å¤„ç†å®Œæˆ\n\n"

        # åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
        fig, ax = plt.subplots(figsize=(22, 14))
        ax.set_facecolor("#f0f0f0")
        
        # ã€ä¿®å¤ä¸­æ–‡ä¹±ç ã€‘ç¡®ä¿æ¯æ¬¡ç»˜å›¾å‰éƒ½æ­£ç¡®è®¾ç½®ä¸­æ–‡å­—ä½“
        font_name = set_chinese_font()
        if font_name:
            print(f"[DEBUG] å›¾è¡¨ä½¿ç”¨å­—ä½“: {font_name}")
        else:
            print("[WARNING] å­—ä½“è®¾ç½®å¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œä¸­æ–‡æ˜¾ç¤ºå¯èƒ½å¼‚å¸¸")
        
        # ç»˜åˆ¶éšœç¢ç‰©
        for obs in obstacles:
            obs.draw(ax)

        # ã€é‡æ„ä¿®æ”¹ã€‘è®¡ç®—ç›®æ ‡åä½œè¯¦æƒ… - ç›´æ¥ä½¿ç”¨æ¨ç†ç»“æœæ•°æ®
        # ä¼˜å…ˆä½¿ç”¨æ¨ç†ç»“æœä¸­çš„ resource_costï¼Œæ·»åŠ æ•°æ®éªŒè¯æœºåˆ¶
        target_collaborators_details = defaultdict(list)
        for uav_id, tasks in final_plan.items():
            for task in sorted(tasks, key=lambda x: x.get('step', 0)):
                target_id = task['target_id']
                # ä¼˜å…ˆä½¿ç”¨æ¨ç†ç»“æœä¸­çš„ resource_costï¼Œæ·»åŠ æ•°æ®éªŒè¯
                if 'resource_cost' in task and task['resource_cost'] is not None:
                    resource_cost = task['resource_cost']
                else:
                    # è®°å½•è¯¦ç»†è­¦å‘Šä¿¡æ¯ï¼Œå¸®åŠ©é—®é¢˜è¯Šæ–­
                    print(f"[WARNING] æ•°æ®å®Œæ•´æ€§é—®é¢˜: UAV {uav_id} çš„ä»»åŠ¡ç¼ºå°‘ resource_cost æ•°æ®")
                    print(f"[WARNING] ä»»åŠ¡è¯¦æƒ…: target_id={task.get('target_id', 'N/A')}, step={task.get('step', 'N/A')}")
                    print(f"[WARNING] ä½¿ç”¨é›¶å‘é‡ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆï¼Œå¯èƒ½å½±å“å¯è§†åŒ–å‡†ç¡®æ€§")
                    resource_cost = np.zeros_like(uavs[0].resources) if uavs else np.zeros(2)
                
                target_collaborators_details[target_id].append({
                    'uav_id': uav_id, 
                    'arrival_time': task.get('arrival_time', 0), 
                    'resource_cost': resource_cost
                })

        # è®¡ç®—æ€»ä½“èµ„æºæ»¡è¶³æƒ…å†µ
        summary_text = ""
        if targets:
            satisfied_targets_count = 0
            resource_types = len(targets[0].resources) if targets else 2
            total_demand_all = np.sum([t.resources for t in targets], axis=0)

            # ã€ä¿®å¤æ•°æ®è®¡ç®—é”™è¯¯ã€‘ä¼˜å…ˆä½¿ç”¨æ¨ç†è¿‡ç¨‹ä¸­è®°å½•çš„æƒå¨æ€»è´¡çŒ®æ•°æ®
            # 1. é¦–å…ˆå°è¯•ä½¿ç”¨æ¨ç†è¿‡ç¨‹ä¸­ä¿å­˜çš„æƒå¨æ•°æ®
            if hasattr(self, '_inference_total_contribution') and self._inference_total_contribution is not None:
                total_contribution_all_for_summary = self._inference_total_contribution
                print(f"[DEBUG] ä½¿ç”¨æ¨ç†è¿‡ç¨‹ä¸­çš„æƒå¨æ€»è´¡çŒ®: {total_contribution_all_for_summary}")
            # 2. å…¶æ¬¡å°è¯•ä» evaluation_metrics ä¸­è§£æ
            elif evaluation_metrics and 'total_contribution' in evaluation_metrics:
                try:
                    contrib_str = evaluation_metrics['total_contribution']
                    # ç§»é™¤æ–¹æ‹¬å·å’Œå¤šä½™ç©ºæ ¼ï¼Œç„¶ååˆ†å‰²
                    contrib_str = contrib_str.strip('[]')
                    contrib_values = [float(x.strip()) for x in contrib_str.split()]
                    total_contribution_all_for_summary = np.array(contrib_values)
                    print(f"[DEBUG] ä½¿ç”¨è¯„ä¼°æŒ‡æ ‡ä¸­çš„æ€»è´¡çŒ®: {total_contribution_all_for_summary}")
                except Exception as e:
                    print(f"[WARNING] è§£æè¯„ä¼°æŒ‡æ ‡ä¸­çš„æ€»è´¡çŒ®å¤±è´¥: {e}")
                    # é™çº§åˆ°è®¡ç®—æ–¹æ¡ˆ
                    total_contribution_all_for_summary = self._calculate_contribution_from_plan(target_collaborators_details, resource_types)
            else:
                # 3. æœ€åé™çº§åˆ°ä» final_plan é‡æ–°è®¡ç®—
                total_contribution_all_for_summary = self._calculate_contribution_from_plan(target_collaborators_details, resource_types)

            for t in targets:
                current_target_contribution_sum = np.sum([d['resource_cost'] for d in target_collaborators_details.get(t.id, [])], axis=0)
                if np.all(current_target_contribution_sum >= t.resources - 1e-5):
                    satisfied_targets_count += 1
            
            num_targets = len(targets)
            satisfaction_rate_percent = (satisfied_targets_count / num_targets * 100) if num_targets > 0 else 100
            total_demand_safe = total_demand_all.copy()
            total_demand_safe[total_demand_safe == 0] = 1e-6
            overall_completion_rate_percent = np.mean(np.minimum(total_contribution_all_for_summary, total_demand_all) / total_demand_safe) * 100
            
            # è®¡ç®—èµ„æºå¯Œè£•åº¦
            total_supply_all = np.sum([u.initial_resources for u in uavs], axis=0)
            resource_surplus = total_supply_all - total_demand_all
            resource_abundance_rate = (resource_surplus / total_demand_safe) * 100
            
            summary_text = (f"æ€»ä½“èµ„æºæ»¡è¶³æƒ…å†µ:\n--------------------------\n"
                          f"- æ€»éœ€æ±‚/æ€»è´¡çŒ®: {np.array2string(total_demand_all, formatter={'float_kind':lambda x: '%.0f' % x})} / {np.array2string(total_contribution_all_for_summary, formatter={'float_kind':lambda x: '%.1f' % x})}\n"
                          f"- æ€»ä¾›ç»™/èµ„æºå¯Œè£•åº¦: {np.array2string(total_supply_all, formatter={'float_kind':lambda x: '%.0f' % x})} / {np.array2string(resource_abundance_rate, formatter={'float_kind':lambda x: '%.1f%%' % x})}\n"
                          f"- å·²æ»¡è¶³ç›®æ ‡: {satisfied_targets_count} / {num_targets} ({satisfaction_rate_percent:.1f}%)\n"
                          f"- æ»¡è¶³ç‡: {overall_completion_rate_percent  :.1f}% (ç›®æ ‡èµ„æºéœ€æ±‚æ»¡è¶³æƒ…å†µ)")

        # ç»˜åˆ¶æ— äººæœºèµ·ç‚¹
        ax.scatter([u.position[0] for u in uavs], [u.position[1] for u in uavs], 
                  c='blue', marker='s', s=150, label='æ— äººæœºèµ·ç‚¹', zorder=5, edgecolors='black')
        
        for u in uavs:
            ax.annotate(f"UAV{u.id}", xy=(u.position[0], u.position[1]), fontsize=12, fontweight='bold', 
                       xytext=(0, -25), textcoords='offset points', ha='center', va='top')
            ax.annotate(f"åˆå§‹: {np.array2string(u.initial_resources, formatter={'float_kind': lambda x: f'{x:.0f}'})}", 
                       xy=(u.position[0], u.position[1]), fontsize=8, xytext=(15, 10), 
                       textcoords='offset points', ha='left', color='navy')

        # ç»˜åˆ¶ç›®æ ‡
        ax.scatter([t.position[0] for t in targets], [t.position[1] for t in targets], 
                  c='red', marker='o', s=150, label='ç›®æ ‡', zorder=5, edgecolors='black')
        
        for t in targets:
            demand_str = np.array2string(t.resources, formatter={'float_kind': lambda x: "%.0f" % x})
            annotation_text = f"ç›®æ ‡ {t.id}\næ€»éœ€æ±‚: {demand_str}\n------------------"
            
            total_contribution = np.sum([d['resource_cost'] for d in target_collaborators_details.get(t.id, [])], axis=0)
            details_text = sorted(target_collaborators_details.get(t.id, []), key=lambda x: x['arrival_time'])
            
            if not details_text:
                annotation_text += "\næœªåˆ†é…æ— äººæœº"
            else:
                for detail in details_text:
                    annotation_text += f"\nUAV {detail['uav_id']} (T:{detail['arrival_time']:.1f}s) è´¡çŒ®:{np.array2string(detail['resource_cost'], formatter={'float_kind': lambda x: '%.1f' % x})}"
            
            if np.all(total_contribution >= t.resources - 1e-5):
                satisfaction_str, bbox_color = "[OK] éœ€æ±‚æ»¡è¶³", 'lightgreen'
            else:
                satisfaction_str, bbox_color = "[NG] èµ„æºä¸è¶³", 'mistyrose'
            
            annotation_text += f"\n------------------\nçŠ¶æ€: {satisfaction_str}"
            
            ax.annotate(f"T{t.id}", xy=(t.position[0], t.position[1]), fontsize=12, fontweight='bold', 
                       xytext=(0, 18), textcoords='offset points', ha='center', va='bottom')
            ax.annotate(annotation_text, xy=(t.position[0], t.position[1]), fontsize=7, 
                       xytext=(15, -15), textcoords='offset points', ha='left', va='top', 
                       bbox=dict(boxstyle='round,pad=0.4', fc=bbox_color, ec='black', alpha=0.9, lw=0.5), zorder=8)

        # ç»˜åˆ¶è·¯å¾„ - ä¿®å¤ï¼šç»˜åˆ¶è¿ç»­çš„ä»»åŠ¡è·¯å¾„
        colors = plt.cm.gist_rainbow(np.linspace(0, 1, len(uavs))) if uavs else []
        uav_color_map = {u.id: colors[i] for i, u in enumerate(uavs)}
        
        # ç»˜åˆ¶è·¯å¾„ï¼Œç¡®ä¿æ‰€æœ‰UAVçš„ä»»åŠ¡éƒ½æ­£ç¡®æ˜¾ç¤º
        print(f"[DEBUG] å¼€å§‹ç»˜åˆ¶æ‰€æœ‰UAVè·¯å¾„ï¼Œtotal UAVs: {len(final_plan)}")
        
        for uav_id, tasks in final_plan.items():
            print(f"[DEBUG] === å¤„ç†UAV {uav_id} ===")
            uav_color = uav_color_map.get(uav_id, 'gray')
            temp_resources = next(u for u in uavs if u.id == uav_id).initial_resources.copy().astype(float)
            
            # è·å–æ— äººæœºèµ·å§‹ä½ç½®
            uav = next(u for u in uavs if u.id == uav_id)
            current_pos = uav.position
            print(f"[DEBUG] UAV {uav_id} èµ·å§‹ä½ç½®: {current_pos}")
            
            # æŒ‰æ­¥éª¤é¡ºåºæ’åºä»»åŠ¡
            sorted_tasks = sorted(tasks, key=lambda x: x.get('step', 0))
            print(f"[DEBUG] UAV {uav_id} ä»»åŠ¡æ•°é‡: {len(sorted_tasks)}")
            
            # ç»˜åˆ¶è¿ç»­è·¯å¾„
            for i, task in enumerate(sorted_tasks):
                print(f"[DEBUG] UAV {uav_id} ä»»åŠ¡ {i+1}/{len(sorted_tasks)}: step{task.get('step', '?')}")
                
                # è·å–ç›®æ ‡ä½ç½®
                target_id = task['target_id']
                target = next(t for t in targets if t.id == target_id)
                target_pos = target.position
                
                print(f"[DEBUG] UAV {uav_id} -> ç›®æ ‡{target_id}: {current_pos} -> {target_pos}")
                
                # æ£€æŸ¥è·¯å¾„è·ç¦»
                distance_check = np.linalg.norm(np.array(target_pos) - np.array(current_pos))
                print(f"[DEBUG] UAV {uav_id} è·¯å¾„è·ç¦»: {distance_check:.2f}m")
                if distance_check < 1.0:
                    print(f"[WARNING] UAV {uav_id} èµ·ç‚¹ç»ˆç‚¹è¿‡è¿‘: {distance_check:.2f}m")
                
                planning_successful = True # æ–°å¢ï¼šåˆå§‹åŒ–è·¯å¾„è§„åˆ’æˆåŠŸæ ‡å¿—
                # ä½¿ç”¨PH-RRTç®—æ³•ç”Ÿæˆæ›²çº¿è·¯å¾„
                try:
                    from path_planning import PHCurveRRTPlanner
                    
                    # åˆ›å»ºPH-RRTè§„åˆ’å™¨
                    planner = PHCurveRRTPlanner(
                        start=current_pos,
                        goal=target_pos,
                        start_heading=0.0,  # å¯ä»¥ä»UAVè·å–å®é™…æœå‘
                        goal_heading=0.0,   # ç›®æ ‡æœå‘
                        obstacles=obstacles,
                        config=self.config
                    )
                    
                    # æ‰§è¡Œè·¯å¾„è§„åˆ’è·å–PHæ›²çº¿
                    result = planner.plan()
                    
                    if result is not None:
                        path_points, distance = result
                        path_points = np.array(path_points)
                        if len(path_points) <= 1:
                            print(f"[WARNING] UAV {uav_id} åˆ°ç›®æ ‡{target_id} PH-RRTè·¯å¾„ç‚¹æ•°ä¸è¶³({len(path_points)})ï¼Œä½¿ç”¨å¹³æ»‘æ›²çº¿")
                            path_points = self._generate_smooth_curve(current_pos, target_pos)
                            planning_successful = False
                        else:
                            print(f"[DEBUG] UAV {uav_id} åˆ°ç›®æ ‡{target_id} PH-RRTæˆåŠŸï¼Œè·¯å¾„ç‚¹æ•°: {len(path_points)}")
                            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å®é™…ç§»åŠ¨
                            start_point = path_points[0]
                            end_point = path_points[-1]
                            actual_distance = np.linalg.norm(end_point - start_point)
                            expected_distance = np.linalg.norm(np.array(target_pos) - np.array(current_pos))
                            print(f"[DEBUG] UAV {uav_id} è·¯å¾„æ£€æŸ¥: å®é™…è·ç¦»={actual_distance:.2f}m, æœŸæœ›è·ç¦»={expected_distance:.2f}m")
                            
                            if actual_distance < expected_distance * 0.5:  # å¦‚æœå®é™…è·¯å¾„è·ç¦»å°äºæœŸæœ›è·ç¦»çš„50%
                                print(f"[WARNING] UAV {uav_id} PH-RRTè·¯å¾„å¼‚å¸¸(è·ç¦»ä¸è¶³)ï¼Œä½¿ç”¨å¹³æ»‘æ›²çº¿")
                                path_points = self._generate_smooth_curve(current_pos, target_pos)
                                planning_successful = False
                    else:
                        # è§„åˆ’å¤±è´¥æ—¶ç”Ÿæˆå¹³æ»‘æ›²çº¿
                        path_points = self._generate_smooth_curve(current_pos, target_pos)
                        planning_successful = False # æ–°å¢ï¼šæ›´æ–°æ ‡å¿—ä½
                        
                except Exception as e:
                    print(f"[WARNING] UAV {uav_id} PH-RRTè§„åˆ’å¼‚å¸¸: {e}ï¼Œä½¿ç”¨å¹³æ»‘æ›²çº¿")
                    path_points = self._generate_smooth_curve(current_pos, target_pos)
                    planning_successful = False # æ–°å¢ï¼šæ›´æ–°æ ‡å¿—ä½
                
                # ç»˜åˆ¶è·¯å¾„
                line_style = '-' if planning_successful else '--'
                print(f"[DEBUG] UAV {uav_id} ç»˜åˆ¶è·¯å¾„: ç‚¹æ•°={len(path_points)}, çº¿å‹={line_style}")
                print(f"[DEBUG] UAV {uav_id} è·¯å¾„èŒƒå›´: X[{path_points[:, 0].min():.1f}, {path_points[:, 0].max():.1f}], Y[{path_points[:, 1].min():.1f}, {path_points[:, 1].max():.1f}]")
                
                ax.plot(path_points[:, 0], path_points[:, 1], 
                       color=uav_color, 
                       linestyle= line_style,#'-' if task.get('is_sync_feasible', True) else '--', 
                       linewidth=2, alpha=0.9, zorder=3)
                
                print(f"[DEBUG] UAV {uav_id} è·¯å¾„å·²ç»˜åˆ¶åˆ°å›¾è¡¨")
                
                # æ·»åŠ æ­¥éª¤æ ‡è®° - ä¼˜åŒ–ï¼šæ”¹è¿›åºåˆ—é¡ºåºçš„æ˜¾ç¤ºæ¸…æ™°åº¦
                mid_pos = path_points[len(path_points) // 2]
                step_number = task.get('step', i+1)
                
                # ä¸»æ­¥éª¤æ ‡è®°ï¼ˆå¤§åœ†åœˆï¼‰
                ax.text(mid_pos[0], mid_pos[1], str(step_number), 
                       color='white', backgroundcolor=uav_color, ha='center', va='center', 
                       fontsize=11, fontweight='bold', 
                       bbox=dict(boxstyle='circle,pad=0.3', fc=uav_color, ec='white', linewidth=2), zorder=6)
                
                # æ­¥éª¤ç®­å¤´æŒ‡ç¤ºï¼ˆæ˜¾ç¤ºæ–¹å‘ï¼‰
                if len(path_points) > 1:
                    # åœ¨è·¯å¾„çš„æ–¹å‘ä¸Šæ·»åŠ ç®­å¤´
                    arrow_start_idx = int(len(path_points) * 0.7)
                    arrow_end_idx = min(arrow_start_idx + 5, len(path_points) - 1)
                    
                    if arrow_start_idx < arrow_end_idx:
                        start_point = path_points[arrow_start_idx]
                        end_point = path_points[arrow_end_idx]
                        
                        ax.annotate('', xy=end_point, xytext=start_point,
                                   arrowprops=dict(arrowstyle='->', color=uav_color, lw=2, alpha=0.8),
                                   zorder=5)
                
                # åœ¨è·¯å¾„èµ·å§‹ç‚¹æ·»åŠ å°å‹æ­¥éª¤æ ‡è®°
                if i == 0:  # ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼Œæ˜¾ç¤ºâ€œèµ·â€
                    start_pos = path_points[0]
                    ax.text(start_pos[0], start_pos[1], 'èµ·', 
                           color=uav_color, ha='center', va='center', 
                           fontsize=8, fontweight='bold', 
                           bbox=dict(boxstyle='round,pad=0.2', fc='white', ec=uav_color, alpha=0.9), zorder=5)
                
                # åœ¨è·¯å¾„ç»“æŸç‚¹æ·»åŠ å°å‹æ­¥éª¤æ ‡è®°
                end_pos = path_points[-1]
                if i == len(sorted_tasks) - 1:  # æœ€åä¸€ä¸ªä»»åŠ¡ï¼Œæ˜¾ç¤ºâ€œç»ˆâ€
                    ax.text(end_pos[0], end_pos[1], 'ç»ˆ', 
                           color=uav_color, ha='center', va='center', 
                           fontsize=8, fontweight='bold', 
                           bbox=dict(boxstyle='round,pad=0.2', fc='white', ec=uav_color, alpha=0.9), zorder=5)
                else:
                    # ä¸­é—´ä»»åŠ¡ï¼Œæ˜¾ç¤ºä¸‹ä¸€æ­¥éª¤çš„æ–¹å‘
                    next_step = step_number + 1
                    ax.text(end_pos[0], end_pos[1], f'â†’{next_step}', 
                           color=uav_color, ha='center', va='center', 
                           fontsize=7, fontweight='bold', 
                           bbox=dict(boxstyle='round,pad=0.15', fc='lightyellow', ec=uav_color, alpha=0.8), zorder=5)
                
                # æ·»åŠ èµ„æºä¿¡æ¯
                resource_cost = task.get('resource_cost', np.zeros_like(temp_resources))
                temp_resources -= resource_cost
                end_pos = path_points[-1]
                remaining_res_str = f"R: {np.array2string(temp_resources.clip(0), formatter={'float_kind': lambda x: f'{x:.0f}'})}"
                ax.annotate(remaining_res_str, xy=(end_pos[0], end_pos[1]),
                           color=uav_color, ha='center', va='center', 
                           fontsize=7, fontweight='bold', 
                           bbox=dict(boxstyle='round,pad=0.15', fc='white', ec=uav_color, alpha=0.8, lw=0.5), 
                           xytext=(10, -10), textcoords='offset points', zorder=7)
                
                # æ›´æ–°å½“å‰ä½ç½®ä¸ºç›®æ ‡ä½ç½®ï¼Œä¸ºä¸‹ä¸€ä¸ªä»»åŠ¡åšå‡†å¤‡
                current_pos = target_pos

        # æ­»é”æ£€æµ‹ä¿¡æ¯
        deadlock_summary_text = ""
        if deadlocked_tasks and any(deadlocked_tasks.values()):
            deadlock_summary_text += "!!! æ­»é”æ£€æµ‹ !!!\n--------------------------\nä»¥ä¸‹æ— äººæœºæœªèƒ½å®Œæˆå…¶ä»»åŠ¡åºåˆ—ï¼Œå¯èƒ½é™·å…¥æ­»é”ï¼š\n"
            for uav_id, tasks in deadlocked_tasks.items():
                if tasks:
                    deadlock_summary_text += f"- UAV {uav_id}: ç­‰å¾…æ‰§è¡Œ -> {' -> '.join([f'T{t[0]}' for t in tasks])}\n"
            deadlock_summary_text += ("-"*30) + "\n\n"

        # æŠ¥å‘Šå¤´éƒ¨
        report_header = f"---------- {scenario_name} æ‰§è¡ŒæŠ¥å‘Š ----------\n\n" + deadlock_summary_text
        if summary_text:
            report_header += summary_text + "\n" + ("-"*30) + "\n\n"
        
        # æ·»åŠ è¯„ä¼°æŒ‡æ ‡åˆ°æŠ¥å‘Šä¸­
        if evaluation_metrics:
            report_header += "è¯„ä¼°æŒ‡æ ‡:\n--------------------------\n"
            # å®šä¹‰æŒ‡æ ‡çš„ä¸­æ–‡åç§°æ˜ å°„
            metric_names = {
                'resource_utilization_rate': 'èµ„æºåˆ©ç”¨ç‡',
                'completion_rate': 'èµ„æºæ»¡è¶³ç‡',
                'sync_feasibility_rate': 'åŒæ­¥å¯è¡Œç‡',
                'load_balance_score': 'è´Ÿè½½å‡è¡¡åº¦'
            }
            
            # ä¼˜å…ˆæ˜¾ç¤ºèµ„æºåˆ©ç”¨ç‡ï¼Œå»æ‰å½’ä¸€åŒ–ä¿¡æ¯
            priority_metrics = ['resource_utilization_rate']
            other_metrics = ['sync_feasibility_rate', 'load_balance_score']
            
            # ä¼˜å…ˆæ˜¾ç¤ºèµ„æºåˆ©ç”¨ç‡
            for key in priority_metrics:
                if key in evaluation_metrics:
                    value = evaluation_metrics[key]
                    report_header += f"  - {metric_names.get(key, key)}: {value:.4f}\n"
            
            # æ˜¾ç¤ºå…¶ä»–æŒ‡æ ‡
            for key in other_metrics:
                if key in evaluation_metrics:
                    value = evaluation_metrics[key]
                    report_header += f"  - {metric_names.get(key, key)}: {value:.4f}\n"
            
            report_header += "-" * 20 + "\n\n"

        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report_body_image = ""
        report_body_file = ""
        
        for uav in uavs:
            uav_header = f"* æ— äººæœº {uav.id} (åˆå§‹èµ„æº: {np.array2string(uav.initial_resources, formatter={'float_kind': lambda x: f'{x:.0f}'})})\n"
            report_body_image += uav_header
            report_body_file += uav_header
            
            details = sorted(final_plan.get(uav.id, []), key=lambda x: x.get('step', 0))
            if not details:
                no_task_str = "  - æœªåˆ†é…ä»»ä½•ä»»åŠ¡\n"
                report_body_image += no_task_str
                report_body_file += no_task_str
            else:
                temp_resources_report = uav.initial_resources.copy().astype(float)
                for detail in details:
                    resource_cost = detail.get('resource_cost', np.zeros_like(temp_resources_report))
                    temp_resources_report -= resource_cost
                    sync_status = "" if detail.get('is_sync_feasible', True) else " (è­¦å‘Š: æ— æ³•åŒæ­¥)"
                    
                    common_report_part = f"  {detail.get('step', 0)}. é£å‘ç›®æ ‡ {detail['target_id']}{sync_status}:\n"
                    common_report_part += f"     - é£è¡Œè·ç¦»: {detail.get('distance', 0):.2f} m, é€Ÿåº¦: {detail.get('speed', 15):.2f} m/s, åˆ°è¾¾æ—¶é—´ç‚¹: {detail.get('arrival_time', 0):.2f} s\n"
                    common_report_part += f"     - æ¶ˆè€—èµ„æº: {np.array2string(resource_cost, formatter={'float_kind': lambda x: '%.1f' % x})}\n"
                    common_report_part += f"     - å‰©ä½™èµ„æº: {np.array2string(temp_resources_report.clip(0), formatter={'float_kind': lambda x: f'{x:.1f}'})}\n"
                    
                    report_body_image += common_report_part
                    report_body_file += common_report_part
            
            report_body_image += "\n"
            report_body_file += "\n"

        final_report_for_image = report_header + report_body_image
        final_report_for_file = report_header + report_body_file + collaboration_log

        # æ·»åŠ æŠ¥å‘Šåˆ°å›¾ç‰‡
        plt.subplots_adjust(right=0.75)
        fig.text(0.77, 0.95, final_report_for_image, transform=plt.gcf().transFigure, 
                ha="left", va="top", fontsize=9, 
                bbox=dict(boxstyle='round,pad=0.5', fc='aliceblue', ec='grey', alpha=0.9))

        # å¤„ç†training_timeæ ¼å¼åŒ–
        if isinstance(training_time, (tuple, list)):
            actual_episodes = len(training_time[0]) if training_time and len(training_time) > 0 else 0
            estimated_time = actual_episodes * 0.13
            training_time_str = f"{estimated_time:.2f}s ({actual_episodes}è½®)"
        else:
            training_time_str = f"{training_time:.2f}s"

        train_mode_str = 'é«˜ç²¾åº¦PH-RRT' if getattr(self.config, 'USE_PHRRT_DURING_TRAINING', False) else 'å¿«é€Ÿè¿‘ä¼¼'
        plan_mode_str = 'é«˜ç²¾åº¦PH-RRT' if getattr(self.config, 'USE_PHRRT_DURING_PLANNING', False) else 'å¿«é€Ÿè¿‘ä¼¼'
        
        title_text = (
            f"å¤šæ— äººæœºä»»åŠ¡åˆ†é…ä¸è·¯å¾„è§„åˆ’ - {scenario_name} ({inference_mode})\n"
            f"UAV: {len(uavs)}, ç›®æ ‡: {len(targets)}, éšœç¢: {len(obstacles)} | è®­ç»ƒ: {train_mode_str} | è§„åˆ’: {plan_mode_str}\n"
            f"æ¨¡å‹è®­ç»ƒè€—æ—¶: {training_time_str} | æ–¹æ¡ˆç”Ÿæˆè€—æ—¶: {plan_generation_time:.2f}s"
        )
        ax.set_title(title_text, fontsize=12, fontweight='bold', pad=20)

        ax.set_xlabel("Xåæ ‡ (m)", fontsize=14)
        ax.set_ylabel("Yåæ ‡ (m)", fontsize=14)
        ax.legend(loc="lower left")
        ax.grid(True, linestyle='--', alpha=0.5, zorder=0)
        ax.set_aspect('equal', adjustable='box')

        # ä¿å­˜å›¾ç‰‡ - æ·»åŠ å®Œæˆç‡ä¿¡æ¯åˆ°æ–‡ä»¶å
        output_dir = "output/images"
        os.makedirs(output_dir, exist_ok=True)
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        clean_scenario_name = scenario_name.replace(' ', '_').replace(':', '')
        
        # è·å–å®Œæˆç‡ä¿¡æ¯ç”¨äºæ–‡ä»¶å - ä¿®å¤ï¼šç¡®ä¿ä½¿ç”¨æ ‡å‡†è¯„ä¼°æŒ‡æ ‡ä¸­çš„å®Œæˆç‡
        completion_rate_for_filename = 0.0
        if evaluation_metrics:
            completion_rate_for_filename = evaluation_metrics.get('completion_rate', 0.0)
        else:
            # å¦‚æœæ²¡æœ‰evaluation_metricsï¼Œä½¿ç”¨PlanVisualizerè®¡ç®—çš„å®Œæˆç‡ä½œä¸ºå¤‡é€‰
            completion_rate_for_filename = overall_completion_rate_percent / 100.0 if 'overall_completion_rate_percent' in locals() else 0.0
        
        # æ„å»ºåŒ…å«å®Œæˆç‡ä¿¡æ¯çš„æ–‡ä»¶å
        completion_str = f"comp{completion_rate_for_filename:.3f}"
        base_filename = f"{clean_scenario_name}_{timestamp}_{completion_str}{suffix}"
        img_filepath = os.path.join(output_dir, f"{base_filename}.jpg")
        
        try:
            plt.savefig(img_filepath, dpi=300, format='jpg')
            # ç§»é™¤é‡å¤çš„è¾“å‡ºï¼Œåªåœ¨ResultSaverä¸­è¾“å‡º
        except Exception as e:
            print(f"âŒ é”™è¯¯ï¼šæ— æ³•ä¿å­˜ç»“æœå›¾è‡³ {img_filepath}")
            print(f"ğŸ“„ æ–‡ä»¶å†™å…¥é”™è¯¯è¯¦æƒ…ï¼š")
            print(f"   - æ–‡ä»¶å: {base_filename}.jpg")
            print(f"   - å­˜å‚¨ä½ç½®: {output_dir}")
            print(f"   - å®Œæ•´è·¯å¾„: {img_filepath}")
            print(f"   - å›¾è¡¨å°ºå¯¸: {fig.get_size_inches()}")
            print(f"   - é”™è¯¯åŸå› : {e}")
            print(f"   - é”™è¯¯ç±»å‹: {type(e).__name__}")
            
            # å°è¯•è¾“å‡ºå›¾è¡¨å†…å®¹ä¿¡æ¯
            try:
                print(f"   - å›¾è¡¨è½´æ•°é‡: {len(fig.axes)}")
                print(f"   - å›¾è¡¨DPI: {fig.dpi}")
                print(f"   - è¾“å‡ºç›®å½•æ˜¯å¦å­˜åœ¨: {os.path.exists(output_dir)}")
                print(f"   - è¾“å‡ºç›®å½•æƒé™: {os.access(output_dir, os.W_OK) if os.path.exists(output_dir) else 'N/A'}")
            except Exception as inner_e:
                print(f"   - æ— æ³•è·å–è¯¦ç»†ä¿¡æ¯: {inner_e}")
        
        plt.close(fig)
        
        return final_report_for_file, img_filepath

    def _calculate_contribution_from_plan(self, target_collaborators_details, resource_types):
        """
        ä» final_plan è®¡ç®—æ€»è´¡çŒ®ï¼Œé¿å…é‡å¤è®¡ç®—
        
        Args:
            target_collaborators_details: ç›®æ ‡åä½œè¯¦æƒ…
            resource_types: èµ„æºç±»å‹æ•°é‡
            
        Returns:
            np.array: æ€»è´¡çŒ®å‘é‡
        """
        # æŒ‰ç›®æ ‡åˆ†ç»„è®¡ç®—ï¼Œé¿å…é‡å¤è®¡ç®—åŒä¸€ä¸ªç›®æ ‡çš„è´¡çŒ®
        target_contributions = {}
        
        for target_id, details in target_collaborators_details.items():
            # å¯¹æ¯ä¸ªç›®æ ‡ï¼Œè®¡ç®—æ‰€æœ‰UAVçš„è´¡çŒ®æ€»å’Œ
            target_total = np.zeros(resource_types)
            for detail in details:
                target_total += detail['resource_cost']
            target_contributions[target_id] = target_total
            print(f"[DEBUG] ç›®æ ‡ {target_id} æ€»è´¡çŒ®: {target_total}")
        
        # è®¡ç®—æ‰€æœ‰ç›®æ ‡çš„è´¡çŒ®æ€»å’Œ
        if target_contributions:
            total_contribution = np.sum(list(target_contributions.values()), axis=0)
            print(f"[DEBUG] ä»final_plané‡æ–°è®¡ç®—æ€»è´¡çŒ®: {total_contribution}")
            print(f"[DEBUG] è®¡ç®—åŸºç¡€: {len(target_contributions)} ä¸ªç›®æ ‡")
        else:
            total_contribution = np.zeros(resource_types)
            print(f"[DEBUG] æ— è´¡çŒ®æ•°æ®ï¼Œä½¿ç”¨é›¶å‘é‡")
        
        return total_contribution

    def _generate_smooth_curve(self, start_pos, end_pos):
        """ç”Ÿæˆå¹³æ»‘æ›²çº¿è·¯å¾„ä½œä¸ºPH-RRTçš„å¤‡é€‰æ–¹æ¡ˆ"""
        start_pos = np.array(start_pos)
        end_pos = np.array(end_pos)
        
        distance = np.linalg.norm(end_pos - start_pos)
        num_points = max(10, int(distance / 20))  # æ¯20ç±³ä¸€ä¸ªç‚¹
        
        path_points = []
        for i in range(num_points + 1):
            t = i / num_points
            
            # åŸºç¡€ç›´çº¿æ’å€¼
            base_point = start_pos + t * (end_pos - start_pos)
            
            # æ·»åŠ è´å¡å°”æ›²çº¿æ ·å¼çš„åç§»
            if i > 0 and i < num_points:
                # è®¡ç®—å‚ç›´äºç›´çº¿æ–¹å‘çš„å‘é‡
                direction = end_pos - start_pos
                perpendicular = np.array([-direction[1], direction[0]])
                if np.linalg.norm(perpendicular) > 0:
                    perpendicular = perpendicular / np.linalg.norm(perpendicular)
                
                # ä½¿ç”¨è´å¡å°”æ›²çº¿çš„æ§åˆ¶ç‚¹é€»è¾‘
                curve_factor = 4 * t * (1 - t)  # è´å¡å°”æ›²çº¿æƒé‡
                curve_offset = curve_factor * min(30, distance * 0.15)  # åŠ¨æ€åç§»é‡
                
                base_point += perpendicular * curve_offset
            
            path_points.append(base_point)
        
        return np.array(path_points)


class ResultSaver:
    """ç»“æœä¿å­˜å™¨ - ä»main-old.pyè¿ç§»"""
    
    def __init__(self, config):
        self.config = config
    
    def save_plan_details(self, report_content, scenario_name, timestamp=None, evaluation_metrics=None, suffix=""):
        """ä¿å­˜æ–¹æ¡ˆè¯¦æƒ…æ–‡ä»¶ - ä¿®æ”¹ä¸ºä¿å­˜åˆ°output/images/ç›®å½•ï¼Œå¹¶åˆå¹¶è¯„ä¼°æŒ‡æ ‡"""
        if timestamp is None:
            timestamp = time.strftime("%Y%m%d-%H%M%S")
        
        # ä¿®æ”¹ä¿å­˜è·¯å¾„åˆ°imagesç›®å½•
        report_dir = "output/images"
        os.makedirs(report_dir, exist_ok=True)
        
        clean_scenario_name = scenario_name.replace(' ', '_').replace(':', '')
        
        # è·å–å®Œæˆç‡ä¿¡æ¯ç”¨äºæ–‡ä»¶å
        completion_rate_for_filename = 0.0
        if evaluation_metrics:
            completion_rate_for_filename = evaluation_metrics.get('completion_rate', 0.0)
        
        # æ„å»ºåŒ…å«å®Œæˆç‡ä¿¡æ¯çš„æ–‡ä»¶å
        completion_str = f"comp{completion_rate_for_filename:.3f}"
        base_filename = f"{clean_scenario_name}_{timestamp}_{completion_str}{suffix}"
        report_filepath = os.path.join(report_dir, f"{base_filename}.txt")
        
        try:
            # åˆå¹¶è¯„ä¼°æŒ‡æ ‡åˆ°æŠ¥å‘Šå†…å®¹æœ«å°¾
            combined_content = report_content
            if evaluation_metrics:
                combined_content += "\n\n" + "=" * 80 + "\n"
                combined_content += "è¯„ä¼°æŒ‡æ ‡è¯¦æƒ…\n"
                combined_content += "=" * 80 + "\n"
                for key, value in evaluation_metrics.items():
                    if isinstance(value, float):
                        combined_content += f"{key}: {value:.4f}\n"
                    else:
                        combined_content += f"{key}: {value}\n"
                combined_content += "=" * 80 + "\n"
            
            with open(report_filepath, 'w', encoding='utf-8') as f:
                f.write(combined_content)
            print(f"è¯¦ç»†æ–¹æ¡ˆæŠ¥å‘Šå·²ä¿å­˜è‡³: {report_filepath}")
            return report_filepath
        except Exception as e:
            print(f"âŒ é”™è¯¯ï¼šæ— æ³•ä¿å­˜ä»»åŠ¡æŠ¥å‘Šè‡³ {report_filepath}")
            print(f"ğŸ“„ æ–‡ä»¶å†™å…¥é”™è¯¯è¯¦æƒ…ï¼š")
            print(f"   - æ–‡ä»¶å: {base_filename}.txt")
            print(f"   - å­˜å‚¨ä½ç½®: {report_dir}")
            print(f"   - å®Œæ•´è·¯å¾„: {report_filepath}")
            print(f"   - å†…å®¹é•¿åº¦: {len(combined_content)} å­—ç¬¦")
            print(f"   - å†…å®¹å‰100å­—ç¬¦: {combined_content[:100]}...")
            print(f"   - é”™è¯¯åŸå› : {e}")
            print(f"   - é”™è¯¯ç±»å‹: {type(e).__name__}")
            
            # å°è¯•è¾“å‡ºç›®å½•å’Œæƒé™ä¿¡æ¯
            try:
                print(f"   - ç›®å½•æ˜¯å¦å­˜åœ¨: {os.path.exists(report_dir)}")
                print(f"   - ç›®å½•æƒé™: {os.access(report_dir, os.W_OK) if os.path.exists(report_dir) else 'N/A'}")
                if hasattr(os, 'statvfs'):
                    stat = os.statvfs(report_dir)
                    free_space = stat.f_bavail * stat.f_frsize / (1024**3)
                    print(f"   - ç£ç›˜ç©ºé—´: {free_space:.2f} GB")
                else:
                    print(f"   - ç£ç›˜ç©ºé—´: æ— æ³•æ£€æµ‹")
            except Exception as inner_e:
                print(f"   - æ— æ³•è·å–è¯¦ç»†ä¿¡æ¯: {inner_e}")
            
            return None

class ModelEvaluator:
    """æ¨¡å‹è¯„ä¼°å™¨ - æ”¯æŒå•æ¨¡å‹å’Œé›†æˆæ¨ç†"""
    
    def __init__(self, config: Config):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"è¯„ä¼°è®¾å¤‡: {self.device}")
        
        # è¯„ä¼°ç»Ÿè®¡
        self.evaluation_stats = {
            'scenario_results': [],
            'average_completion_rate': 0.0,
            'average_efficiency': 0.0,
            'evaluation_time': 0.0
        }

    def _safe_evaluate_plan(self, final_plan, uavs, targets, **kwargs):
        """
        å®‰å…¨çš„è¯„ä¼°å‡½æ•°è°ƒç”¨ï¼Œä½¿ç”¨æ·±æ‹·è´é˜²æ­¢æ•°æ®æ±¡æŸ“
        
        Args:
            final_plan: åŸå§‹çš„ä»»åŠ¡åˆ†é…æ–¹æ¡ˆ
            uavs: æ— äººæœºåˆ—è¡¨
            targets: ç›®æ ‡åˆ—è¡¨
            **kwargs: å…¶ä»–ä¼ é€’ç»™ evaluate_plan çš„å‚æ•°
            
        Returns:
            dict: è¯„ä¼°æŒ‡æ ‡å­—å…¸
            
        Note:
            æ­¤å‡½æ•°åˆ›å»º final_plan çš„æ·±æ‹·è´å‰¯æœ¬ä¼ é€’ç»™ evaluate_planï¼Œ
            ç¡®ä¿åŸå§‹æ•°æ®ä¸è¢«ä¿®æ”¹ï¼Œç»´æŠ¤æ•°æ®æºçš„å”¯ä¸€æ€§ã€‚
        """
        try:
            # åˆ›å»ºæ·±æ‹·è´ä»¥é˜²æ­¢æ•°æ®æ±¡æŸ“
            final_plan_copy = copy.deepcopy(final_plan)
            print(f"[DEBUG] å·²åˆ›å»º final_plan æ·±æ‹·è´ï¼Œé˜²æ­¢æ•°æ®æ±¡æŸ“")
            
            # ä½¿ç”¨å‰¯æœ¬è°ƒç”¨è¯„ä¼°å‡½æ•°
            return evaluate_plan(final_plan_copy, uavs, targets, **kwargs)
            
        except Exception as e:
            print(f"[ERROR] æ·±æ‹·è´æ“ä½œå¤±è´¥: {type(e).__name__}: {e}")
            print(f"[WARNING] é™çº§åˆ°ä½¿ç”¨åŸå§‹å¯¹è±¡è¿›è¡Œè¯„ä¼°")
            print(f"[WARNING] è¿™å¯èƒ½å¯¼è‡´ evaluate_plan å‡½æ•°ä¿®æ”¹åŸå§‹æ•°æ®ï¼Œå­˜åœ¨æ•°æ®æ±¡æŸ“é£é™©")
            print(f"[DEBUG] å»ºè®®æ£€æŸ¥ final_plan æ•°æ®ç»“æ„æ˜¯å¦åŒ…å«ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡")
            
            # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨åŸå§‹å¯¹è±¡ä½†è®°å½•è­¦å‘Š
            return evaluate_plan(final_plan, uavs, targets, **kwargs)

    def _generate_complete_visualization(self, scenario_name: str, inference_mode: str, 
                                    uavs, targets, obstacles, results, suffix: str = ""):
        """ç”Ÿæˆå®Œæ•´çš„å¯è§†åŒ–ç»“æœ - é›†æˆPlanVisualizerå’ŒResultSaver"""
        try:
            # ä½¿ç”¨å·²ç»æ„å»ºå¥½çš„final_planï¼Œé¿å…é‡å¤æ„å»º
            final_plan = results.get('final_plan', {})
            
            # åˆ›å»ºå¯è§†åŒ–å™¨å’Œä¿å­˜å™¨
            visualizer = PlanVisualizer(self.config)
            saver = ResultSaver(self.config)
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆä½¿ç”¨æ·±æ‹·è´é˜²æ­¢æ•°æ®æ±¡æŸ“ï¼‰
            final_uav_states = results.get('final_uav_states', None)
            evaluation_metrics = self._safe_evaluate_plan(final_plan, uavs, targets, final_uav_states=final_uav_states)
            
            # ã€é‡è¦ä¿®æ”¹ã€‘ä»¥æ¨ç†ç»“æœä¸ºå‡†ï¼Œæ¨ç†ç»“æœå°±æ˜¯æœ€ç»ˆçš„åˆ†é…æ–¹æ¡ˆ
            if results and 'completion_rate' in results:
                # ä½¿ç”¨æ¨ç†ç»“æœä¸­çš„å®Œæˆç‡ä½œä¸ºæœ€ç»ˆç»“æœ
                evaluation_metrics['completion_rate'] = results['completion_rate']
                print(f"[DEBUG] ä½¿ç”¨æ¨ç†ç»“æœä¸­çš„å®Œæˆç‡: {results['completion_rate']:.4f}")
                
                # å¦‚æœæœ‰æ¨ç†ä»»åŠ¡åˆ†é…æ–¹æ¡ˆï¼Œä½¿ç”¨æ¨ç†ç»“æœè¦†ç›–evaluate_plançš„ç»“æœ
                if 'inference_task_assignments' in results and 'inference_target_status' in results:
                    print(f"[DEBUG] ä½¿ç”¨æ¨ç†ä»»åŠ¡åˆ†é…æ–¹æ¡ˆä½œä¸ºæœ€ç»ˆç»“æœ")
                    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ é€»è¾‘æ¥ä½¿ç”¨æ¨ç†ç»“æœè¦†ç›–evaluate_plançš„æŸäº›æŒ‡æ ‡
            else:
                print(f"[DEBUG] ä½¿ç”¨evaluate_planè®¡ç®—çš„å®Œæˆç‡: {evaluation_metrics.get('completion_rate', 0):.4f}")
            
            # ç”Ÿæˆå¯è§†åŒ–å’ŒæŠ¥å‘Š
            training_time = 0.0  # æ¨ç†é˜¶æ®µæ— è®­ç»ƒæ—¶é—´
            plan_generation_time = self.evaluation_stats['evaluation_time']
            
            # ä¼ é€’suffixå’Œæ¨ç†æ–¹å¼å‚æ•°
            report_content, img_filepath = visualizer.save(
                final_plan, uavs, targets, obstacles, scenario_name,
                training_time, plan_generation_time, evaluation_metrics, None, suffix, inference_mode
            )
            
            # ä¿å­˜è¯¦ç»†æŠ¥å‘Šï¼ŒåŒ…å«è¯„ä¼°æŒ‡æ ‡
            timestamp = time.strftime("%Y%m%d-%H%M%S")
            report_filepath = saver.save_plan_details(report_content, scenario_name, timestamp, evaluation_metrics, suffix)
            
            print(f"å®Œæ•´å¯è§†åŒ–ç»“æœå·²ç”Ÿæˆ: {scenario_name}")
            
        except Exception as e:
            print(f"ç”Ÿæˆå®Œæ•´å¯è§†åŒ–æ—¶å‡ºé”™: {e}")
    def _build_execution_plan_from_action_sequence(self, action_sequence: List[int], uavs: List[UAV], targets: List[Target], env: UAVTaskEnv, step_details: List[dict] = None) -> dict:
        """
        å‡½æ•°çº§æ³¨é‡Š: ä¸¥æ ¼æ ¹æ®åŠ¨ä½œåºåˆ—(action_sequence)æ„å»ºæœ€ç»ˆæ‰§è¡Œè®¡åˆ’ã€‚
        è¿™ä¸ªæ–¹æ³•èƒ½çœŸå®åæ˜ æ™ºèƒ½ä½“åœ¨æ¨ç†è¿‡ç¨‹ä¸­çš„å†³ç­–é¡ºåºã€‚
        
        Args:
            action_sequence: åŠ¨ä½œåºåˆ—
            uavs: UAVåˆ—è¡¨
            targets: ç›®æ ‡åˆ—è¡¨
            env: ç¯å¢ƒå¯¹è±¡
            step_details: æ­¥éª¤è¯¦ç»†ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨ï¼Œå¦åˆ™ä»action_sequenceé‡å»ºï¼‰
        """
        uav_assignments = {uav.id: [] for uav in uavs}
        temp_uav_positions = {u.id: u.position.copy().astype(float) for u in uavs}
        
        # å¦‚æœæä¾›äº†step_detailsï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™ä»action_sequenceé‡å»º
        if step_details:
            print(f"[DEBUG] ä½¿ç”¨æä¾›çš„step_detailsæ„å»ºæ‰§è¡Œè®¡åˆ’ï¼Œæ­¥éª¤æ•°: {len(step_details)}")
            for step, details in enumerate(step_details):
                uav_id = details['uav_id']
                target_id = details['target_id']
                # ä»åŸå§‹åˆ—è¡¨ä¸­æ‰¾åˆ°UAVå’ŒTargetå¯¹è±¡
                uav = next((u for u in uavs if u.id == uav_id), None)
                target = next((t for t in targets if t.id == target_id), None)

                if not uav or not target:
                    continue

                # è®¡ç®—é£è¡Œè·ç¦»å’Œåˆ°è¾¾æ—¶é—´
                distance = np.linalg.norm(temp_uav_positions[uav_id] - target.position)
                arrival_time = distance / uav.economic_speed if uav.economic_speed > 0 else float('inf')

                task_detail = {
                    'target_id': target_id,
                    'step': step + 1,
                    'distance': distance,
                    'arrival_time': arrival_time,
                    'resource_cost': details['contribution'], # ç›´æ¥ä½¿ç”¨æ•è·çš„çœŸå®è´¡çŒ®
                    'phi_idx': details['phi_idx'],
                    'is_sync_feasible': True # æ¨ç†ä¸­é»˜è®¤ä¸ºçœŸ
                }
                uav_assignments[uav_id].append(task_detail)
                print(f"[DEBUG] æ·»åŠ ä»»åŠ¡åˆ°UAV {uav_id}: {task_detail}")

                # æ›´æ–°UAVçš„å½“å‰ä½ç½®ï¼Œç”¨äºè®¡ç®—ä¸‹ä¸€æ®µèˆªç¨‹çš„è·ç¦»
                temp_uav_positions[uav_id] = target.position.copy()
        else:
            print(f"[DEBUG] ä»action_sequenceé‡å»ºæ‰§è¡Œè®¡åˆ’ï¼ŒåŠ¨ä½œæ•°: {len(action_sequence)}")
            # ä»action_sequenceé‡å»ºï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
            for step, action_idx in enumerate(action_sequence):
                try:
                    # è§£ç åŠ¨ä½œ
                    target_idx, uav_idx, phi_idx = env.decode_action(action_idx)
                    
                    if uav_idx < len(uavs) and target_idx < len(targets):
                        uav = uavs[uav_idx]
                        target = targets[target_idx]
                        
                        # è®¡ç®—é£è¡Œè·ç¦»å’Œåˆ°è¾¾æ—¶é—´
                        distance = np.linalg.norm(temp_uav_positions[uav.id] - target.position)
                        arrival_time = distance / uav.economic_speed if uav.economic_speed > 0 else float('inf')

                        # æ¨¡æ‹Ÿèµ„æºè´¡çŒ®ï¼ˆè¿™é‡Œåªèƒ½ä¼°ç®—ï¼Œå› ä¸ºæ²¡æœ‰çœŸå®çš„è´¡çŒ®æ•°æ®ï¼‰
                        contribution = np.minimum(uav.resources, target.resources)

                        task_detail = {
                            'target_id': target.id,
                            'step': step + 1,
                            'distance': distance,
                            'arrival_time': arrival_time,
                            'resource_cost': contribution,
                            'phi_idx': phi_idx,
                            'is_sync_feasible': True
                        }
                        uav_assignments[uav.id].append(task_detail)
                        print(f"[DEBUG] æ·»åŠ ä»»åŠ¡åˆ°UAV {uav.id}: {task_detail}")

                        # æ›´æ–°UAVçš„å½“å‰ä½ç½®
                        temp_uav_positions[uav.id] = target.position.copy()

                except Exception as e:
                    print(f"åœ¨é‡å»ºåŠ¨ä½œåºåˆ—æ—¶å‡ºé”™: {e}")
                    continue

        return {
            'uav_assignments': uav_assignments
        }


    def start_evaluation(self, model_paths: Union[str, List[str]], scenario_name: str = "small"):
        """
        å¯åŠ¨è¯„ä¼°è¿‡ç¨‹
        
        Args:
            model_paths (Union[str, List[str]]): æ¨¡å‹è·¯å¾„ï¼Œå•ä¸ªè·¯å¾„æˆ–è·¯å¾„åˆ—è¡¨
            scenario_name (str): åœºæ™¯åç§°
        """
        print("=" * 60)
        print("å¼€å§‹æ¨¡å‹è¯„ä¼°")
        print("=" * 60)
        
        # å¤„ç†æ¨¡å‹è·¯å¾„å¹¶å®šä¹‰æ–‡ä»¶ååç¼€
        if isinstance(model_paths, str):
            model_paths = [model_paths]
            inference_mode = "å•æ¨¡å‹æ¨ç†"
            suffix = '_single_inference'  # æ–°å¢ï¼šå•æ¨¡å‹æ¨ç†åç¼€
        elif len(model_paths) == 1:
            # åªæœ‰ä¸€ä¸ªæ¨¡å‹çš„æƒ…å†µï¼Œä¹Ÿè®¤ä¸ºæ˜¯å•æ¨¡å‹æ¨ç†
            inference_mode = "å•æ¨¡å‹æ¨ç†"
            suffix = '_single_inference'  # å•æ¨¡å‹æ¨ç†åç¼€
        else:
            inference_mode = "é›†æˆæ¨ç†"
            suffix = '_ensemble_inference'  # æ–°å¢ï¼šé›†æˆæ¨ç†åç¼€
        
        print(f"æ¨ç†æ¨¡å¼: {inference_mode}")
        print(f"æ¨¡å‹æ•°é‡: {len(model_paths)}")
        print(f"è¯„ä¼°åœºæ™¯: {scenario_name}")
        
        # æ˜¾ç¤ºè·¯å¾„è§„åˆ’ç®—æ³•ä¿¡æ¯
        train_algo = "é«˜ç²¾åº¦PH-RRT" if getattr(self.config, 'USE_PHRRT_DURING_TRAINING', False) else "å¿«é€Ÿè¿‘ä¼¼"
        plan_algo = "é«˜ç²¾åº¦PH-RRT" if getattr(self.config, 'USE_PHRRT_DURING_PLANNING', False) else "å¿«é€Ÿè¿‘ä¼¼"
        print(f"è®­ç»ƒç®—æ³•: {train_algo}")
        print(f"è§„åˆ’ç®—æ³•: {plan_algo}")
        print("=" * 60)
        
        start_time = time.time()
        
        # åŠ è½½åœºæ™¯
        uavs, targets, obstacles = self._load_scenario(scenario_name)
        
        if len(model_paths) == 1:
            results = self._single_model_inference(model_paths[0], uavs, targets, obstacles, scenario_name)
        else:
            results = self._ensemble_inference(model_paths, uavs, targets, obstacles, scenario_name)
        
        end_time = time.time()
        self.evaluation_stats['evaluation_time'] = end_time - start_time
        
        # --- å•ä¸€æ•°æ®æºå¤„ç†æµç¨‹ ---
        if results:
            # 1. é‡å»ºå¸¦æœ‰æ­£ç¡®èµ„æºæ¶ˆè€—çš„è§„åˆ’æ–¹æ¡ˆ            
            action_sequence = results.get('action_sequence', [])
            step_details = results.get('step_details', [])
            plan_data = self._build_execution_plan_from_action_sequence(action_sequence, uavs, targets, self.env, step_details)
            final_plan = plan_data.get('uav_assignments', {})

            # 2. è°ƒç”¨æƒå¨è¯„ä¼°å‡½æ•°ï¼Œç”Ÿæˆå”¯ä¸€çš„è¯„ä¼°æŒ‡æ ‡ï¼ˆä½¿ç”¨æ·±æ‹·è´é˜²æ­¢æ•°æ®æ±¡æŸ“ï¼‰
            evaluation_metrics = self._safe_evaluate_plan(
                final_plan, uavs, targets, final_uav_states=results.get('final_uav_states')
            )
            
            # 3. å°†final_planå­˜å‚¨åˆ°resultsä¸­ï¼Œé¿å…é‡å¤æ„å»º
            results['final_plan'] = final_plan
            
            # 4. ä¼˜å…ˆä½¿ç”¨æ¨ç†ç»“æœä¸­çš„å®Œæˆç‡ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
            if 'completion_rate' in results:
                print(f"[DEBUG] ä½¿ç”¨æ¨ç†ç»“æœä¸­çš„å®Œæˆç‡: {results['completion_rate']:.4f}")
                evaluation_metrics['completion_rate'] = results['completion_rate']
            else:
                print(f"[DEBUG] ä½¿ç”¨evaluate_planè®¡ç®—çš„å®Œæˆç‡: {evaluation_metrics.get('completion_rate', 0):.4f}")
            
            # 5. å°†æƒå¨è¯„ä¼°ç»“æœåˆå¹¶åˆ°resultsä¸­ï¼Œä½œä¸ºå”¯ä¸€æ•°æ®æº
            results.update(evaluation_metrics)

            # 6. å¤„ç†è¯„ä¼°ç»“æœï¼ˆç”¨äºæ§åˆ¶å°è¾“å‡ºï¼‰
            self._process_evaluation_results(results)

            # 7. ç”Ÿæˆå®Œæ•´çš„å¯è§†åŒ–ç»“æœï¼ˆç”¨äºæŠ¥å‘Šå’Œå›¾ç‰‡ï¼‰
            self._generate_complete_visualization(scenario_name, inference_mode, uavs, targets, obstacles, results, suffix)

        print(f"\nè¯„ä¼°å®Œæˆ! æ€»è€—æ—¶: {self.evaluation_stats['evaluation_time']:.2f}ç§’")
    
    def _load_scenario(self, scenario_name: str):
        """
        åŠ è½½æŒ‡å®šåœºæ™¯ - æ”¯æŒé™æ€å’ŒåŠ¨æ€åœºæ™¯
        
        Args:
            scenario_name (str): åœºæ™¯åç§°
            
        Returns:
            tuple: (uavs, targets, obstacles)
        """
        obstacle_tolerance = getattr(self.config, 'OBSTACLE_TOLERANCE', 50.0)
        
        # é™æ€é¢„å®šä¹‰åœºæ™¯
        if scenario_name == "balanced":
            return get_balanced_scenario(obstacle_tolerance)
        elif scenario_name == "small":
            print(f"ä½¿ç”¨é™æ€smallåœºæ™¯è¿›è¡Œæ¨ç†")
            return get_small_scenario(obstacle_tolerance)
        elif scenario_name == "complex":
            return get_complex_scenario(obstacle_tolerance)
        # åŠ¨æ€åœºæ™¯
        elif scenario_name in ["easy", "medium", "hard"]:
            print(f"ä½¿ç”¨åŠ¨æ€{scenario_name}åœºæ™¯è¿›è¡Œæ¨ç†")
            # å¯¹äºåŠ¨æ€åœºæ™¯ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚
            # çœŸæ­£çš„åœºæ™¯å°†åœ¨ env.reset() è°ƒç”¨ä¸­ç”Ÿæˆã€‚
            return [], [], []
            # # åˆ›å»ºä¸´æ—¶ç¯å¢ƒæ¥ç”ŸæˆåŠ¨æ€åœºæ™¯
            # from environment import UAVTaskEnv
            # # ç›´æ¥åˆ›å»ºä¸´æ—¶ç¯å¢ƒï¼Œè®©ç¯å¢ƒå†…éƒ¨å¤„ç†å›¾åˆ›å»º
            # temp_env = UAVTaskEnv([], [], None, [], self.config, obs_mode="graph")
            # temp_env._initialize_entities(scenario_name)
            # return temp_env.uavs, temp_env.targets, temp_env.obstacles
        else:
            print(f"æœªçŸ¥åœºæ™¯åç§°: {scenario_name}ï¼Œä½¿ç”¨é»˜è®¤smallåœºæ™¯")
            return get_small_scenario(obstacle_tolerance)
    
    def _single_model_inference(self, model_path: str, uavs, targets, obstacles, scenario_name='easy'):
        """
        å•æ¨¡å‹æ¨ç†ï¼ˆä½¿ç”¨Softmaxé‡‡æ ·ï¼‰
        
        Args:
            model_path (str): æ¨¡å‹è·¯å¾„
            uavs: UAVåˆ—è¡¨
            targets: ç›®æ ‡åˆ—è¡¨
            obstacles: éšœç¢ç‰©åˆ—è¡¨
            scenario_name (str): åœºæ™¯åç§°ï¼Œç”¨äºç¯å¢ƒé‡ç½®
            
        Returns:
            dict: æ¨ç†ç»“æœ
        """
        print(f"æ‰§è¡Œå•æ¨¡å‹æ¨ç†: {model_path}")
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            print(f"é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ - {model_path}")
            return None
        
        # åˆ›å»ºå›¾å’Œç¯å¢ƒ
        graph = DirectedGraph(uavs, targets, self.config.GRAPH_N_PHI, obstacles, self.config)
        
        # è®¡ç®—è¾“å…¥è¾“å‡ºç»´åº¦
        if self.config.NETWORK_TYPE == "ZeroShotGNN":
            obs_mode = "graph"
            i_dim = 64  # å ä½å€¼
            o_dim = len(targets) * len(uavs) * graph.n_phi

            if o_dim <= 0 and scenario_name in ["easy", "medium", "hard"]:
                # å¦‚æœæ˜¯åŠ¨æ€åœºæ™¯ä¸”åˆå§‹ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§å®ä½“æ•°æ¥åˆ›å»ºç½‘ç»œ
                max_o_dim = self.config.MAX_TARGETS * self.config.MAX_UAVS * self.config.GRAPH_N_PHI
                o_dim = max_o_dim
                # ä¸ºäº†åŒºåˆ†ï¼Œå¯ä»¥åœ¨æ—¥å¿—ä¸­æ·»åŠ ä¸åŒçš„æç¤º
                if "_ensemble" in self.start_evaluation.__name__: # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„åˆ¤æ–­ï¼Œå®é™…åº”çœ‹è°ƒç”¨æ ˆ
                     print(f"åŠ¨æ€åœºæ™¯é›†æˆæ¨ç†ï¼šä½¿ç”¨æœ€å¤§åŠ¨ä½œç©ºé—´å ä½ç¬¦ o_dim={o_dim}")
                else:
                     print(f"åŠ¨æ€åœºæ™¯å•æ¨¡å‹æ¨ç†ï¼šä½¿ç”¨æœ€å¤§åŠ¨ä½œç©ºé—´å ä½ç¬¦ o_dim={o_dim}")

        else:
            obs_mode = "flat"
            target_dim = 7 * len(targets)
            uav_dim = 8 * len(uavs)
            collaboration_dim = len(targets) * len(uavs)
            global_dim = 10
            i_dim = target_dim + uav_dim + collaboration_dim + global_dim
            o_dim = len(targets) * len(uavs) * graph.n_phi
        
        # åˆ›å»ºç½‘ç»œå¹¶åŠ è½½æ¨¡å‹
        network = create_network(
            self.config.NETWORK_TYPE, 
            i_dim, 
            self.config.hyperparameters.hidden_dim, 
            o_dim, 
            self.config
        ).to(self.device)
        
        try:
            # åŠ è½½æ¨¡å‹æ–‡ä»¶
            try:
                # é¦–å…ˆå°è¯•ä½¿ç”¨weights_only=FalseåŠ è½½
                try:
                    model_data = torch.load(model_path, map_location=self.device, weights_only=False)
                except TypeError as type_error:
                    # å¤„ç†PyTorch 2.6ç‰ˆæœ¬ä¸­weights_onlyå‚æ•°çš„å˜åŒ–
                    if "got an unexpected keyword argument 'weights_only'" in str(type_error):
                        print(f"å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒweights_onlyå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°åŠ è½½")
                        model_data = torch.load(model_path, map_location=self.device)
                    else:
                        raise
                except Exception as check_error:
                    print(f"æ ¼å¼æ£€æŸ¥æ—¶ä½¿ç”¨weights_only=FalseåŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨weights_only=True: {check_error}")
                    try:
                        model_data = torch.load(model_path, map_location=self.device, weights_only=True)
                    except TypeError as type_error:
                        # å¤„ç†PyTorch 2.6ç‰ˆæœ¬ä¸­weights_onlyå‚æ•°çš„å˜åŒ–
                        if "got an unexpected keyword argument 'weights_only'" in str(type_error):
                            print(f"å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒweights_onlyå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°åŠ è½½")
                            model_data = torch.load(model_path, map_location=self.device)
                        else:
                            raise
            except Exception as load_error:
                # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨weights_only=TrueåŠ è½½
                print(f"ä½¿ç”¨weights_only=FalseåŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨weights_only=True: {load_error}")
                try:
                    model_data = torch.load(model_path, map_location=self.device, weights_only=True)
                except TypeError as type_error:
                    # å¤„ç†PyTorch 2.6ç‰ˆæœ¬ä¸­weights_onlyå‚æ•°çš„å˜åŒ–
                    if "got an unexpected keyword argument 'weights_only'" in str(type_error):
                        print(f"å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒweights_onlyå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°åŠ è½½")
                        model_data = torch.load(model_path, map_location=self.device)
                    else:
                        raise
            
            # æ£€æŸ¥æ¨¡å‹æ•°æ®æ ¼å¼
            if isinstance(model_data, dict) and 'model_state_dict' in model_data:
                # æ–°æ ¼å¼ï¼šåŒ…å«æ¨¡å‹çŠ¶æ€å’Œé¢å¤–ä¿¡æ¯
                network.load_state_dict(model_data['model_state_dict'])
                print(f"æ¨¡å‹åŠ è½½æˆåŠŸ(æ–°æ ¼å¼): {os.path.basename(model_path)}")
            else:
                # æ—§æ ¼å¼ï¼šç›´æ¥æ˜¯çŠ¶æ€å­—å…¸
                network.load_state_dict(model_data)
                print(f"æ¨¡å‹åŠ è½½æˆåŠŸ(æ—§æ ¼å¼): {os.path.basename(model_path)}")
            
            network.eval()
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"å°è¯•æ£€æŸ¥æ¨¡å‹æ ¼å¼...")
            try:
                model_data = torch.load(model_path, map_location=self.device, weights_only=False)
                print(f"æ¨¡å‹æ•°æ®ç±»å‹: {type(model_data)}")
                if isinstance(model_data, dict):
                    print(f"æ¨¡å‹æ•°æ®é”®: {list(model_data.keys())}")
            except Exception as inner_e:
                print(f"æ¨¡å‹æ ¼å¼æ£€æŸ¥å¤±è´¥: {inner_e}")
            return None
        
        # åˆ›å»ºç¯å¢ƒ
        self.env = UAVTaskEnv(uavs, targets, graph, obstacles, self.config, obs_mode=obs_mode)
        
        # æ‰§è¡Œæ¨ç†ï¼Œä¼ é€’scenario_nameå‚æ•°
        results = self._run_inference(network, self.env, use_softmax_sampling=True, scenario_name=scenario_name)
        
        return results
    
    def _ensemble_inference(self, model_paths: List[str], uavs, targets, obstacles, scenario_name='easy'):
        """
        é›†æˆæ¨ç†ï¼ˆé›†æˆSoftmaxï¼‰
        
        Args:
            model_paths (List[str]): æ¨¡å‹è·¯å¾„åˆ—è¡¨
            uavs: UAVåˆ—è¡¨
            targets: ç›®æ ‡åˆ—è¡¨
            obstacles: éšœç¢ç‰©åˆ—è¡¨
            scenario_name (str): åœºæ™¯åç§°ï¼Œç”¨äºç¯å¢ƒé‡ç½®
            
        Returns:
            dict: æ¨ç†ç»“æœ
        """
        print(f"æ‰§è¡Œé›†æˆæ¨ç†ï¼Œæ¨¡å‹æ•°é‡: {len(model_paths)}")
        
        # æ£€æŸ¥æ‰€æœ‰æ¨¡å‹æ–‡ä»¶
        valid_models = []
        for path in model_paths:
            if os.path.exists(path):
                valid_models.append(path)
            else:
                print(f"è­¦å‘Š: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ - {path}")
        
        if not valid_models:
            print("é”™è¯¯: æ²¡æœ‰æœ‰æ•ˆçš„æ¨¡å‹æ–‡ä»¶")
            return None
        
        print(f"æœ‰æ•ˆæ¨¡å‹æ•°é‡: {len(valid_models)}")
        
        # åˆ›å»ºå›¾å’Œç¯å¢ƒ
        graph = DirectedGraph(uavs, targets, self.config.GRAPH_N_PHI, obstacles, self.config)
        
        # è®¡ç®—è¾“å…¥è¾“å‡ºç»´åº¦
        if self.config.NETWORK_TYPE == "ZeroShotGNN":
            obs_mode = "graph"
            i_dim = 64
            o_dim = len(targets) * len(uavs) * graph.n_phi
            if o_dim <= 0 and scenario_name in ["easy", "medium", "hard"]:
                # å¦‚æœæ˜¯åŠ¨æ€åœºæ™¯ä¸”åˆå§‹ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§å®ä½“æ•°æ¥åˆ›å»ºç½‘ç»œ
                max_o_dim = self.config.MAX_TARGETS * self.config.MAX_UAVS * self.config.GRAPH_N_PHI
                o_dim = max_o_dim
                # ä¸ºäº†åŒºåˆ†ï¼Œå¯ä»¥åœ¨æ—¥å¿—ä¸­æ·»åŠ ä¸åŒçš„æç¤º
                if "_ensemble" in self.start_evaluation.__name__: # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„åˆ¤æ–­ï¼Œå®é™…åº”çœ‹è°ƒç”¨æ ˆ
                     print(f"åŠ¨æ€åœºæ™¯é›†æˆæ¨ç†ï¼šä½¿ç”¨æœ€å¤§åŠ¨ä½œç©ºé—´å ä½ç¬¦ o_dim={o_dim}")
                else:
                     print(f"åŠ¨æ€åœºæ™¯å•æ¨¡å‹æ¨ç†ï¼šä½¿ç”¨æœ€å¤§åŠ¨ä½œç©ºé—´å ä½ç¬¦ o_dim={o_dim}")

        else:
            obs_mode = "flat"
            target_dim = 7 * len(targets)
            uav_dim = 8 * len(uavs)
            collaboration_dim = len(targets) * len(uavs)
            global_dim = 10
            i_dim = target_dim + uav_dim + collaboration_dim + global_dim
            o_dim = len(targets) * len(uavs) * graph.n_phi
        
        # åŠ è½½æ‰€æœ‰æ¨¡å‹
        networks = []
        for model_path in valid_models:
            network = create_network(
                self.config.NETWORK_TYPE,
                i_dim,
                self.config.hyperparameters.hidden_dim,
                o_dim,
                self.config
            ).to(self.device)
            
            try:
                # åŠ è½½æ¨¡å‹æ–‡ä»¶
                try:
                    # é¦–å…ˆå°è¯•ä½¿ç”¨weights_only=FalseåŠ è½½
                    model_data = torch.load(model_path, map_location=self.device, weights_only=False)
                except TypeError as type_error:
                    # å¤„ç†PyTorch 2.6ç‰ˆæœ¬ä¸­weights_onlyå‚æ•°çš„å˜åŒ–
                    if "got an unexpected keyword argument 'weights_only'" in str(type_error):
                        print(f"å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒweights_onlyå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°åŠ è½½")
                        model_data = torch.load(model_path, map_location=self.device)
                    else:
                        raise
                except Exception as load_error:
                    # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨weights_only=TrueåŠ è½½
                    print(f"ä½¿ç”¨weights_only=FalseåŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨weights_only=True: {load_error}")
                    try:
                        model_data = torch.load(model_path, map_location=self.device, weights_only=True)
                    except TypeError as type_error:
                        # å¤„ç†PyTorch 2.6ç‰ˆæœ¬ä¸­weights_onlyå‚æ•°çš„å˜åŒ–
                        if "got an unexpected keyword argument 'weights_only'" in str(type_error):
                            print(f"å½“å‰PyTorchç‰ˆæœ¬ä¸æ”¯æŒweights_onlyå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°åŠ è½½")
                            model_data = torch.load(model_path, map_location=self.device)
                        else:
                            raise
                
                # æ£€æŸ¥æ¨¡å‹æ•°æ®æ ¼å¼
                if isinstance(model_data, dict) and 'model_state_dict' in model_data:
                    # æ–°æ ¼å¼ï¼šåŒ…å«æ¨¡å‹çŠ¶æ€å’Œé¢å¤–ä¿¡æ¯
                    network.load_state_dict(model_data['model_state_dict'])
                    print(f"æ¨¡å‹åŠ è½½æˆåŠŸ(æ–°æ ¼å¼): {os.path.basename(model_path)}")
                else:
                    # æ—§æ ¼å¼ï¼šç›´æ¥æ˜¯çŠ¶æ€å­—å…¸
                    network.load_state_dict(model_data)
                    print(f"æ¨¡å‹åŠ è½½æˆåŠŸ(æ—§æ ¼å¼): {os.path.basename(model_path)}")
                
                network.eval()
                networks.append(network)
            except Exception as e:
                print(f"æ¨¡å‹åŠ è½½å¤±è´¥ {model_path}: {e}")
                print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                print(f"å°è¯•æ£€æŸ¥æ¨¡å‹æ ¼å¼...")
                try:
                    model_data = torch.load(model_path, map_location=self.device, weights_only=False)
                    print(f"æ¨¡å‹æ•°æ®ç±»å‹: {type(model_data)}")
                    if isinstance(model_data, dict):
                        print(f"æ¨¡å‹æ•°æ®é”®: {list(model_data.keys())}")
                except Exception as inner_e:
                    print(f"æ¨¡å‹æ ¼å¼æ£€æŸ¥å¤±è´¥: {inner_e}")
        
        if not networks:
            print("é”™è¯¯: æ²¡æœ‰æˆåŠŸåŠ è½½çš„æ¨¡å‹")
            return None
        
        # åˆ›å»ºç¯å¢ƒ
        env = UAVTaskEnv(uavs, targets, graph, obstacles, self.config, obs_mode=obs_mode)
        
        # æ‰§è¡Œé›†æˆæ¨ç†ï¼Œä¼ é€’scenario_nameå‚æ•°
        results = self._run_ensemble_inference(networks, env, scenario_name)
        
        # ã€ä¿®å¤ã€‘ä¸ºé›†æˆæ¨ç†ç»“æœæ„å»ºfinal_planï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
        if results:
            # 1. é‡å»ºå¸¦æœ‰æ­£ç¡®èµ„æºæ¶ˆè€—çš„è§„åˆ’æ–¹æ¡ˆ            
            action_sequence = results.get('action_sequence', [])
            step_details = results.get('step_details', [])
            plan_data = self._build_execution_plan_from_action_sequence(action_sequence, uavs, targets, env, step_details)
            final_plan = plan_data.get('uav_assignments', {})

            # 2. å°†final_planå­˜å‚¨åˆ°resultsä¸­ï¼Œä¾›å¯è§†åŒ–ä½¿ç”¨
            results['final_plan'] = final_plan
            
            # 3. ä¼˜å…ˆä½¿ç”¨æ¨ç†ç»“æœä¸­çš„å®Œæˆç‡ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
            if 'completion_rate' in results:
                print(f"[DEBUG] ä½¿ç”¨é›†æˆæ¨ç†ç»“æœä¸­çš„å®Œæˆç‡: {results['completion_rate']:.4f}")
        
        return results
    
    def _run_inference(self, network, env, use_softmax_sampling=True, scenario_name='easy'):
        """
        è¿è¡Œå•æ¨¡å‹æ¨ç†
        
        Args:
            network: ç¥ç»ç½‘ç»œæ¨¡å‹
            env: ç¯å¢ƒ
            use_softmax_sampling (bool): æ˜¯å¦ä½¿ç”¨Softmaxé‡‡æ ·
            scenario_name (str): åœºæ™¯åç§°ï¼Œç”¨äºç¯å¢ƒé‡ç½®
            
        Returns:
            dict: æ¨ç†ç»“æœ
        """
        # ã€ä¿®å¤ã€‘åœ¨ç¯å¢ƒé‡ç½®æ—¶ä¼ é€’æ­£ç¡®çš„scenario_nameå‚æ•°ï¼Œæ¨ç†æ—¶é™é»˜é‡ç½®
        reset_options = {'scenario_name': scenario_name, 'silent_reset': True}
        reset_result = env.reset(options=reset_options)
        # å¤„ç†resetè¿”å›çš„tupleæ ¼å¼ (state, info)
        if isinstance(reset_result, tuple):
            state = reset_result[0]
        else:
            state = reset_result
        total_reward = 0.0
        step_count = 0
        max_steps = 100
        action_sequence = []        
        step_details = [] # æ–°å¢ï¼šç”¨äºå­˜å‚¨æ¯ä¸€æ­¥çš„è¯¦ç»†æ‰§è¡Œâ€œäº‹å®â€

        with torch.no_grad():
            while step_count < max_steps:
                # å‡†å¤‡çŠ¶æ€å¼ é‡
                if env.obs_mode == "flat":
                    state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)
                else:  # graph mode
                    state_tensor = {}
                    for key, value in state.items():
                        if key == "masks":
                            mask_tensor = {}
                            for mask_key, mask_value in value.items():
                                mask_tensor[mask_key] = torch.tensor(mask_value).unsqueeze(0).to(self.device)
                            state_tensor[key] = mask_tensor
                        else:
                            state_tensor[key] = torch.FloatTensor(value).unsqueeze(0).to(self.device)
                
                # è·å–Qå€¼
                q_values = network(state_tensor)
                
                # è·å–åŠ¨ä½œæ©ç 
                action_mask = env.get_action_mask()
                valid_actions = np.where(action_mask)[0]
                
                if len(valid_actions) == 0:
                    break
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºåŠ¨ä½œå€™é€‰åˆ—è¡¨
                if self.config.ENABLE_DEBUG:
                    print(f"\n[DEBUG] æ­¥éª¤ {step_count + 1} åŠ¨ä½œå€™é€‰åˆ—è¡¨: "
                          f"  æœ‰æ•ˆåŠ¨ä½œæ•°é‡: {len(valid_actions)}"
                          f"  æœ‰æ•ˆåŠ¨ä½œç´¢å¼•: {valid_actions.tolist()}")
                    
                    # æ˜¾ç¤ºæ‰€æœ‰åŠ¨ä½œçš„è¯¦ç»†ä¿¡æ¯
                    for i, action_idx in enumerate(valid_actions):
                        try:
                            target_idx, uav_idx, phi_idx = env._action_to_assignment(action_idx)
                            target = env.targets[target_idx]
                            uav = env.uavs[uav_idx]
                            q_value = q_values[0][action_idx].item()
                            
                            # è®¡ç®—è·ç¦»å’Œèµ„æºä¿¡æ¯
                            uav_pos = uav.position
                            target_pos = target.position
                            distance = np.linalg.norm(uav_pos - target_pos)
                            
                            # è·å–UAVå½“å‰èµ„æºå’Œç›®æ ‡éœ€æ±‚
                            uav_resources = uav.resources
                            target_needs = target.resources
                            
                            # è®¡ç®—å¯èƒ½çš„èµ„æºè´¡çŒ®
                            possible_contribution = np.minimum(uav_resources, target_needs)
                            total_possible = np.sum(possible_contribution)
                        

                            print(f"    åŠ¨ä½œ{i+1} (ç´¢å¼•{action_idx}): UAV{uav.id}->Target{target.id}"
                                  f"      - Qå€¼: {q_value:.3f}"
                                  f"      - è·ç¦»: {distance:.2f}m"
                                  f"      - UAVèµ„æº: {uav_resources}"
                                  f"      - ç›®æ ‡éœ€æ±‚: {target_needs}"
                                  f"      - å¯èƒ½è´¡çŒ®: {possible_contribution} (æ€»è®¡: {total_possible:.1f})")

                        except Exception as e:
                            print(f"    åŠ¨ä½œ{i+1} (ç´¢å¼•{action_idx}): è§£æå¤±è´¥ - {e}"
                                  f"      - Qå€¼: {q_values[0][action_idx].item():.3f}")
                
                # é€‰æ‹©åŠ¨ä½œ
                if use_softmax_sampling:
                    # Softmaxé‡‡æ ·
                    valid_q_values = q_values[0][valid_actions]
                    probs = torch.softmax(valid_q_values / 0.1, dim=0)  # æ¸©åº¦å‚æ•°0.1
                    action_idx = torch.multinomial(probs, 1).item()
                    action = valid_actions[action_idx]
                    
                    # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºé€‰æ‹©è¿‡ç¨‹
                    if self.config.ENABLE_DEBUG:
                        selected_prob = probs[action_idx].item()
                        print(f"  [DEBUG] Softmaxé‡‡æ ·é€‰æ‹©è¿‡ç¨‹:" 
                            f"    - æœ‰æ•ˆQå€¼: {valid_q_values.tolist()}"
                            f"    - é€‰æ‹©æ¦‚ç‡: {probs.tolist()}"
                            f"    - é€‰æ‹©ç´¢å¼•: {action_idx} \n"
                            f"    - æœ€ç»ˆåŠ¨ä½œ: {action}, æ¦‚ç‡: {selected_prob:.4f}")
                else:
                    # è´ªå©ªé€‰æ‹©
                    masked_q_values = q_values[0].clone()
                    masked_q_values[~torch.tensor(action_mask, dtype=torch.bool)] = float('-inf')
                    action = masked_q_values.argmax().item()
                    
                    # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºè´ªå©ªé€‰æ‹©
                    if self.config.ENABLE_DEBUG:
                        max_q_value = masked_q_values[action].item()
                        print(f"  [DEBUG] è´ªå©ªé€‰æ‹©è¿‡ç¨‹:")
                        print(f"    - æœ€å¤§Qå€¼: {max_q_value:.3f}")
                        print(f"    - é€‰æ‹©åŠ¨ä½œ: {action}")
                
                # æ‰§è¡ŒåŠ¨ä½œå‰æ£€æŸ¥æ˜¯å¦æœ‰å®é™…è´¡çŒ®ï¼ˆåŒé‡éªŒè¯ï¼‰
                target_idx, uav_idx, phi_idx = env._action_to_assignment(action)
                target = env.targets[target_idx]
                uav = env.uavs[uav_idx]
                
                # åŒé‡æ£€æŸ¥ï¼šç¡®ä¿åŠ¨ä½œæœ‰æ•ˆä¸”æœ‰å®é™…è´¡çŒ®
                if not env._is_valid_action(target, uav, phi_idx) or not env._has_actual_contribution(target, uav):
                    # è·³è¿‡æ— æ•ˆæˆ–æ— è´¡çŒ®çš„åŠ¨ä½œ
                    print(f"âš ï¸ è·³è¿‡æ— æ•ˆåŠ¨ä½œ: UAV{uav.id} -> Target{target.id} (æ— èµ„æºè´¡çŒ®)")
                    continue
                uav_res_before = uav.resources.copy()

                # æ‰§è¡ŒåŠ¨ä½œ
                next_state, reward, done, truncated, info = env.step(action)
                # ä»infoä¸­æå–reward_breakdown
                reward_breakdown = info.get('reward_breakdown', {})
                actual_contribution = uav_res_before - uav.resources

                # è®°å½•è¿™ä¸€æ­¥çš„è¯¦ç»†â€œäº‹å®â€
                step_details.append({
                    'action_idx': action,
                    'uav_id': uav.id,
                    'target_id': target.id,
                    'contribution': actual_contribution,
                    'phi_idx': phi_idx
                })
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                if self.config.ENABLE_DEBUG:
                    print(f"[DEBUG] æ­¥éª¤ {step_count + 1}: UAV{uav.id} -> Target{target.id}, åŠ¨ä½œ={action}, å¥–åŠ±={reward:.2f}")

                # å¦‚æœå¥–åŠ±å¼‚å¸¸ï¼ˆå°äº-100ï¼‰ï¼Œæ‰“å°è¯¦ç»†çš„å¥–åŠ±åˆ†è§£
                if reward < -100:
                    print(f"\n[DEBUG] å¼‚å¸¸å¥–åŠ±æ£€æµ‹! å¥–åŠ±å€¼: {reward:.2f}")
                    print("è¯¦ç»†å¥–åŠ±åˆ†è§£:")
                    if reward_breakdown:
                        # æ‰“å°ç¬¬ä¸€å±‚å¥–åŠ±åˆ†è§£
                        if 'layer1_breakdown' in reward_breakdown:
                            print("  ç¬¬ä¸€å±‚å¥–åŠ± (èµ„æºåŒ¹é…):")
                            for key, value in reward_breakdown['layer1_breakdown'].items():
                                print(f"    {key}: {value:.4f}")
                            print(f"  ç¬¬ä¸€å±‚æ€»è®¡: {reward_breakdown.get('layer1_total', 0):.4f}")
                        
                        # æ‰“å°ç¬¬äºŒå±‚å¥–åŠ±åˆ†è§£
                        if 'layer2_breakdown' in reward_breakdown:
                            print("  ç¬¬äºŒå±‚å¥–åŠ± (ä¼˜åŒ–é€‰æ‹©):")
                            for key, value in reward_breakdown['layer2_breakdown'].items():
                                print(f"    {key}: {value:.4f}")
                            print(f"  ç¬¬äºŒå±‚æ€»è®¡: {reward_breakdown.get('layer2_total', 0):.4f}")
                        
                        # æ‰“å°å…¶ä»–å¥–åŠ±ä¿¡æ¯
                        other_keys = ['base_reward', 'shaping_reward', 'final_total_reward', 'was_clipped']
                        for key in other_keys:
                            if key in reward_breakdown:
                                print(f"  {key}: {reward_breakdown[key]}")
                    else:
                        print("  æœªæ‰¾åˆ°è¯¦ç»†å¥–åŠ±åˆ†è§£ä¿¡æ¯")
                    print()

                total_reward += reward
                action_sequence.append(action)
                state = next_state
                step_count += 1
                
                if done or truncated:
                    break
        
        # ã€é‡è¦ä¿®å¤ã€‘ä»¥æ¨ç†ç»“æœä¸ºå‡†ï¼Œè®°å½•æ¨ç†ç»“æŸæ—¶çš„ä»»åŠ¡åˆ†é…æ–¹æ¡ˆ
        # æ¨ç†è¿‡ç¨‹å·²ç»å®Œæˆäº†ä»»åŠ¡åˆ†é…å†³ç­–ï¼Œå®é™…æ‰§è¡Œåªæ˜¯è¿›è¡Œè·¯å¾„è§„åˆ’ç­‰åç»­å·¥ä½œ
        
        # è®¡ç®—æ¨ç†ç»“æŸæ—¶çš„å®Œæˆç‡ï¼ˆåŸºäºUAVèµ„æºæ¶ˆè€—ï¼Œä¸evaluate.pyä¿æŒä¸€è‡´ï¼‰
        total_demand = np.sum([t.resources for t in env.targets], axis=0)
        
        # ä½¿ç”¨UAVçš„åˆå§‹èµ„æºå’Œæœ€ç»ˆèµ„æºè®¡ç®—æ€»è´¡çŒ®ï¼ˆä¸evaluate.pyä¸­çš„é€»è¾‘ä¸€è‡´ï¼‰
        total_initial = np.sum([uav.initial_resources for uav in env.uavs], axis=0)
        total_final = np.sum([uav.resources for uav in env.uavs], axis=0)
        total_contribution = total_initial - total_final
        
        total_demand_sum = np.sum(total_demand)
        total_contribution_sum = np.sum(np.minimum(total_contribution, total_demand))
        completion_rate = total_contribution_sum / total_demand_sum if total_demand_sum > 0 else 1.0
        
        # ã€ä¿®å¤ã€‘ä¿å­˜æ¨ç†ç»“æœä¸­çš„æ€»è´¡çŒ®æ•°æ®ï¼Œä¾›æŠ¥å‘Šç”Ÿæˆä½¿ç”¨
        self._inference_total_contribution = total_contribution
        
        # ã€è°ƒè¯•ã€‘æ˜¾ç¤ºæ¨ç†ç»“æŸæ—¶çš„ä»»åŠ¡åˆ†é…ç»“æœ
        print(f"[DEBUG] æ¨ç†ä»»åŠ¡åˆ†é…ç»“æœ:")
        print(f"  - æ€»éœ€æ±‚: {total_demand} (æ€»å’Œ: {total_demand_sum})")
        print(f"  - æ¨ç†åˆ†é…æ€»è´¡çŒ®: {total_contribution} (æ€»å’Œ: {total_contribution_sum})")
        print(f"  - æ¨ç†å®Œæˆç‡: {completion_rate:.4f}")
        
        # è®¡ç®—ç›®æ ‡å®Œæˆç‡ï¼ˆå®Œå…¨æ»¡è¶³çš„ç›®æ ‡æ•°é‡æ¯”ä¾‹ï¼‰
        satisfied_targets = sum(1 for t in env.targets if np.all(t.remaining_resources <= 1e-6))
        total_targets = len(env.targets)
        target_completion_rate = satisfied_targets / total_targets if total_targets > 0 else 1.0
        print(f"  - æ¨ç†æ—¶å®Œå…¨æ»¡è¶³ç›®æ ‡æ•°: {satisfied_targets}/{total_targets}")
        print(f"  - æ¨ç†æ—¶ç›®æ ‡å®Œæˆç‡: {target_completion_rate:.4f}")
        
        # æ˜¾ç¤ºæ¯ä¸ªç›®æ ‡çš„è¯¦ç»†çŠ¶æ€
        for i, target in enumerate(env.targets):
            remaining = target.remaining_resources
            is_satisfied = np.all(remaining <= 1e-6)
            print(f"  - ç›®æ ‡{i+1}: å‰©ä½™éœ€æ±‚{remaining}, å®Œå…¨æ»¡è¶³: {is_satisfied}")
        
        # è®°å½•æ¨ç†ç»“æŸæ—¶çš„ä»»åŠ¡åˆ†é…æ–¹æ¡ˆ
        inference_task_assignments = {}
        for uav in env.uavs:
            inference_task_assignments[uav.id] = {
                'initial_resources': uav.initial_resources.copy(),
                'final_resources': uav.resources.copy(),
                'consumed_resources': uav.initial_resources - uav.resources
            }
        
        inference_target_status = {}
        for target in env.targets:
            inference_target_status[target.id] = {
                'required_resources': target.resources.copy(),
                'remaining_resources': target.remaining_resources.copy(),
                'contributed_resources': target.resources - target.remaining_resources
            }
        
        print(f"[DEBUG] æ¨ç†ä»»åŠ¡åˆ†é…æ–¹æ¡ˆå·²è®°å½•ï¼ŒåŒ…å«{len(inference_task_assignments)}ä¸ªUAVå’Œ{len(inference_target_status)}ä¸ªç›®æ ‡")
    
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºåŠ¨ä½œåºåˆ—
        if self.config.ENABLE_DEBUG:
            print(f"\n[DEBUG] æ¨ç†å®Œæˆï¼ŒåŠ¨ä½œåºåˆ—: {action_sequence}")
            print(f"[DEBUG] æ€»æ­¥æ•°: {step_count}, æ€»å¥–åŠ±: {total_reward:.2f}, å®Œæˆç‡: {completion_rate:.4f}")
        
        # ä¿å­˜æ¨ç†å®Œæˆåçš„UAVçŠ¶æ€ï¼Œç”¨äºèµ„æºåˆ©ç”¨ç‡è®¡ç®—
        final_uav_states = []
        for uav in env.uavs:
            final_uav_states.append({
                'id': uav.id,
                'initial_resources': uav.initial_resources.copy(),
                'final_resources': uav.resources.copy()
            })
        
        return {
            'total_reward': total_reward,
            'completion_rate': completion_rate,  # åŸºäºæ¨ç†ç»“æœè®¡ç®—çš„å®Œæˆç‡
            'step_count': step_count,
            'action_sequence': action_sequence,
            'step_details': step_details, # æ–°å¢ï¼šä¼ é€’è¯¦ç»†çš„æ‰§è¡Œæ­¥éª¤
            'final_state': state,
            'final_uav_states': final_uav_states,
            'inference_task_assignments': inference_task_assignments,  # æ¨ç†ä»»åŠ¡åˆ†é…æ–¹æ¡ˆ
            'inference_target_status': inference_target_status  # æ¨ç†ç›®æ ‡çŠ¶æ€
        }
    
    def _run_ensemble_inference(self, networks, env, scenario_name='easy'):
        """
        è¿è¡Œé›†æˆæ¨ç†
        
        Args:
            networks: ç½‘ç»œæ¨¡å‹åˆ—è¡¨
            env: ç¯å¢ƒ
            scenario_name (str): åœºæ™¯åç§°ï¼Œç”¨äºç¯å¢ƒé‡ç½®
            
        Returns:
            dict: æ¨ç†ç»“æœ
        """
        # ã€ä¿®å¤ã€‘åœ¨ç¯å¢ƒé‡ç½®æ—¶ä¼ é€’æ­£ç¡®çš„scenario_nameå‚æ•°ï¼Œæ¨ç†æ—¶é™é»˜é‡ç½®
        reset_options = {'scenario_name': scenario_name, 'silent_reset': True}
        reset_result = env.reset(options=reset_options)
        # å¤„ç†resetè¿”å›çš„tupleæ ¼å¼ (state, info)
        if isinstance(reset_result, tuple):
            state = reset_result[0]
        else:
            state = reset_result
        total_reward = 0.0
        step_count = 0
        max_steps = 100
        action_sequence = []
        step_details = [] # æ–°å¢ï¼šç”¨äºå­˜å‚¨æ¯ä¸€æ­¥çš„è¯¦ç»†æ‰§è¡Œ"äº‹å®"
        
        with torch.no_grad():
            while step_count < max_steps:
                # å‡†å¤‡çŠ¶æ€å¼ é‡
                if env.obs_mode == "flat":
                    state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)
                else:  # graph mode
                    state_tensor = {}
                    for key, value in state.items():
                        if key == "masks":
                            mask_tensor = {}
                            for mask_key, mask_value in value.items():
                                mask_tensor[mask_key] = torch.tensor(mask_value).unsqueeze(0).to(self.device)
                            state_tensor[key] = mask_tensor
                        else:
                            state_tensor[key] = torch.FloatTensor(value).unsqueeze(0).to(self.device)
                
                # è·å–æ‰€æœ‰æ¨¡å‹çš„Qå€¼å¹¶å¹³å‡
                ensemble_q_values = None
                for network in networks:
                    q_values = network(state_tensor)
                    if ensemble_q_values is None:
                        ensemble_q_values = q_values
                    else:
                        ensemble_q_values += q_values
                
                ensemble_q_values /= len(networks)
                
                # è·å–åŠ¨ä½œæ©ç 
                action_mask = env.get_action_mask()
                valid_actions = np.where(action_mask)[0]
                
                if len(valid_actions) == 0:
                    break
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºåŠ¨ä½œå€™é€‰åˆ—è¡¨
                if self.config.ENABLE_DEBUG:
                    print(f"\n[DEBUG] é›†æˆæ¨ç†æ­¥éª¤ {step_count + 1} åŠ¨ä½œå€™é€‰åˆ—è¡¨:")
                    print(f"  æœ‰æ•ˆåŠ¨ä½œæ•°é‡: {len(valid_actions)}")
                    print(f"  æœ‰æ•ˆåŠ¨ä½œç´¢å¼•: {valid_actions.tolist()}")
                    
                    # æ˜¾ç¤ºæ‰€æœ‰åŠ¨ä½œçš„è¯¦ç»†ä¿¡æ¯
                    for i, action_idx in enumerate(valid_actions):
                        try:
                            target_idx, uav_idx, phi_idx = env._action_to_assignment(action_idx)
                            target = env.targets[target_idx]
                            uav = env.uavs[uav_idx]
                            q_value = ensemble_q_values[0][action_idx].item()
                            
                            # è®¡ç®—è·ç¦»å’Œèµ„æºä¿¡æ¯
                            uav_pos = uav.position
                            target_pos = target.position
                            distance = np.linalg.norm(uav_pos - target_pos)
                            
                            # è·å–UAVå½“å‰èµ„æºå’Œç›®æ ‡éœ€æ±‚
                            uav_resources = uav.resources
                            target_needs = target.resources
                            
                            # è®¡ç®—å¯èƒ½çš„èµ„æºè´¡çŒ®
                            possible_contribution = np.minimum(uav_resources, target_needs)
                            total_possible = np.sum(possible_contribution)
                            
                            print(f"    åŠ¨ä½œ{i+1} (ç´¢å¼•{action_idx}): UAV{uav.id}->Target{target.id}")
                            print(f"      - Qå€¼: {q_value:.3f}")
                            print(f"      - è·ç¦»: {distance:.2f}m")
                            print(f"      - UAVèµ„æº: {uav_resources}")
                            print(f"      - ç›®æ ‡éœ€æ±‚: {target_needs}")
                            print(f"      - å¯èƒ½è´¡çŒ®: {possible_contribution} (æ€»è®¡: {total_possible:.1f})")
                        except Exception as e:
                            print(f"    åŠ¨ä½œ{i+1} (ç´¢å¼•{action_idx}): è§£æå¤±è´¥ - {e}")
                            print(f"      - Qå€¼: {ensemble_q_values[0][action_idx].item():.3f}")
                
                # é›†æˆSoftmaxé‡‡æ ·
                valid_q_values = ensemble_q_values[0][valid_actions]
                probs = torch.softmax(valid_q_values / 0.1, dim=0)
                action_idx = torch.multinomial(probs, 1).item()
                action = valid_actions[action_idx]
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºé€‰æ‹©è¿‡ç¨‹
                if self.config.ENABLE_DEBUG:
                    selected_prob = probs[action_idx].item()
                    print(f"  [DEBUG] é›†æˆSoftmaxé‡‡æ ·é€‰æ‹©è¿‡ç¨‹:")
                    print(f"    - æœ‰æ•ˆQå€¼: {valid_q_values.tolist()}")
                    print(f"    - é€‰æ‹©æ¦‚ç‡: {probs.tolist()}")
                    print(f"    - é€‰æ‹©ç´¢å¼•: {action_idx}")
                    print(f"    - æœ€ç»ˆåŠ¨ä½œ: {action}, æ¦‚ç‡: {selected_prob:.4f}")
                
                # æ‰§è¡ŒåŠ¨ä½œå‰æ£€æŸ¥æ˜¯å¦æœ‰å®é™…è´¡çŒ®ï¼ˆåŒé‡éªŒè¯ï¼‰
                target_idx, uav_idx, phi_idx = env._action_to_assignment(action)
                target = env.targets[target_idx]
                uav = env.uavs[uav_idx]
                
                # åŒé‡æ£€æŸ¥ï¼šç¡®ä¿åŠ¨ä½œæœ‰æ•ˆä¸”æœ‰å®é™…è´¡çŒ®
                if not env._is_valid_action(target, uav, phi_idx) or not env._has_actual_contribution(target, uav):
                    # è·³è¿‡æ— æ•ˆæˆ–æ— è´¡çŒ®çš„åŠ¨ä½œ
                    print(f"âš ï¸ è·³è¿‡æ— æ•ˆåŠ¨ä½œ: UAV{uav.id} -> Target{target.id} (æ— èµ„æºè´¡çŒ®)")
                    continue
                
                # è®°å½•æ‰§è¡Œå‰çš„UAVèµ„æºçŠ¶æ€
                uav_res_before = uav.resources.copy()
                
                # æ‰§è¡ŒåŠ¨ä½œ
                next_state, reward, done, truncated, info = env.step(action)
                
                # è®°å½•è¿™ä¸€æ­¥çš„è¯¦ç»†"äº‹å®"
                actual_contribution = uav_res_before - uav.resources
                step_details.append({
                    'action_idx': action,
                    'uav_id': uav.id,
                    'target_id': target.id,
                    'contribution': actual_contribution,
                    'phi_idx': phi_idx
                })
                
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                if self.config.ENABLE_DEBUG:
                    print(f"[DEBUG] æ­¥éª¤ {step_count + 1}: UAV{uav.id} -> Target{target.id}, åŠ¨ä½œ={action}, å¥–åŠ±={reward:.2f}")
                
                total_reward += reward
                action_sequence.append(action)
                state = next_state
                step_count += 1
                
                if done or truncated:
                    break
        
        # è®¡ç®—é›†æˆæ¨ç†ç»“æŸæ—¶çš„å®Œæˆç‡ï¼ˆåŸºäºUAVèµ„æºæ¶ˆè€—ï¼Œä¸å•æ¨¡å‹æ¨ç†ä¿æŒä¸€è‡´ï¼‰
        total_demand = np.sum([t.resources for t in env.targets], axis=0)
        
        # ä½¿ç”¨UAVçš„åˆå§‹èµ„æºå’Œæœ€ç»ˆèµ„æºè®¡ç®—æ€»è´¡çŒ®ï¼ˆä¸å•æ¨¡å‹æ¨ç†ä¸­çš„é€»è¾‘ä¸€è‡´ï¼‰
        total_initial = np.sum([uav.initial_resources for uav in env.uavs], axis=0)
        total_final = np.sum([uav.resources for uav in env.uavs], axis=0)
        total_contribution = total_initial - total_final
        
        total_demand_sum = np.sum(total_demand)
        total_contribution_sum = np.sum(np.minimum(total_contribution, total_demand))
        completion_rate = total_contribution_sum / total_demand_sum if total_demand_sum > 0 else 1.0
        
        # ã€ä¿®å¤ã€‘ä¿å­˜é›†æˆæ¨ç†ç»“æœä¸­çš„æ€»è´¡çŒ®æ•°æ®ï¼Œä¾›æŠ¥å‘Šç”Ÿæˆä½¿ç”¨
        self._inference_total_contribution = total_contribution
       
        # ã€è°ƒè¯•ã€‘æ˜¾ç¤ºé›†æˆæ¨ç†ç»“æŸæ—¶çš„ä»»åŠ¡åˆ†é…ç»“æœ
        print(f"[DEBUG] é›†æˆæ¨ç†ä»»åŠ¡åˆ†é…ç»“æœ:")
        print(f"  - æ€»éœ€æ±‚: {total_demand} (æ€»å’Œ: {total_demand_sum})")
        print(f"  - é›†æˆæ¨ç†åˆ†é…æ€»è´¡çŒ®: {total_contribution} (æ€»å’Œ: {total_contribution_sum})")
        print(f"  - é›†æˆæ¨ç†å®Œæˆç‡: {completion_rate:.4f}")
        
        # è®¡ç®—ç›®æ ‡å®Œæˆç‡ï¼ˆå®Œå…¨æ»¡è¶³çš„ç›®æ ‡æ•°é‡æ¯”ä¾‹ï¼‰
        satisfied_targets = sum(1 for t in env.targets if np.all(t.remaining_resources <= 1e-6))
        total_targets = len(env.targets)
        target_completion_rate = satisfied_targets / total_targets if total_targets > 0 else 1.0
        print(f"  - é›†æˆæ¨ç†æ—¶å®Œå…¨æ»¡è¶³ç›®æ ‡æ•°: {satisfied_targets}/{total_targets}")
        print(f"  - é›†æˆæ¨ç†æ—¶ç›®æ ‡å®Œæˆç‡: {target_completion_rate:.4f}")
        
        # æ˜¾ç¤ºæ¯ä¸ªç›®æ ‡çš„è¯¦ç»†çŠ¶æ€
        for i, target in enumerate(env.targets):
            remaining = target.remaining_resources
            is_satisfied = np.all(remaining <= 1e-6)
            print(f"  - ç›®æ ‡{i+1}: å‰©ä½™éœ€æ±‚{remaining}, å®Œå…¨æ»¡è¶³: {is_satisfied}")
        
        # è®°å½•æ¨ç†ç»“æŸæ—¶çš„ä»»åŠ¡åˆ†é…æ–¹æ¡ˆ
        inference_task_assignments = {}
        for uav in env.uavs:
            inference_task_assignments[uav.id] = {
                'initial_resources': uav.initial_resources.copy(),
                'final_resources': uav.resources.copy(),
                'consumed_resources': uav.initial_resources - uav.resources
            }
        
        inference_target_status = {}
        for target in env.targets:
            inference_target_status[target.id] = {
                'required_resources': target.resources.copy(),
                'remaining_resources': target.remaining_resources.copy(),
                'contributed_resources': target.resources - target.remaining_resources
            }
        
        print(f"[DEBUG] é›†æˆæ¨ç†ä»»åŠ¡åˆ†é…æ–¹æ¡ˆå·²è®°å½•ï¼ŒåŒ…å«{len(inference_task_assignments)}ä¸ªUAVå’Œ{len(inference_target_status)}ä¸ªç›®æ ‡")
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºåŠ¨ä½œåºåˆ—
        if self.config.ENABLE_DEBUG:
            print(f"\n[DEBUG] é›†æˆæ¨ç†å®Œæˆï¼ŒåŠ¨ä½œåºåˆ—: {action_sequence}")
            print(f"[DEBUG] æ€»æ­¥æ•°: {step_count}, æ€»å¥–åŠ±: {total_reward:.2f}, å®Œæˆç‡: {completion_rate:.4f}")
        
        # ä¿å­˜æ¨ç†å®Œæˆåçš„UAVçŠ¶æ€ï¼Œç”¨äºèµ„æºåˆ©ç”¨ç‡è®¡ç®—
        final_uav_states = []
        for uav in env.uavs:
            final_uav_states.append({
                'id': uav.id,
                'initial_resources': uav.initial_resources.copy(),
                'final_resources': uav.resources.copy()
            })
        
        return {
            'total_reward': total_reward,
            'completion_rate': completion_rate,
            'step_count': step_count,
            'action_sequence': action_sequence,
            'step_details': step_details, # æ–°å¢ï¼šä¼ é€’è¯¦ç»†çš„æ‰§è¡Œæ­¥éª¤
            'final_state': state,
            'ensemble_size': len(networks),
            'final_uav_states': final_uav_states,
            'inference_task_assignments': inference_task_assignments,  # é›†æˆæ¨ç†ä»»åŠ¡åˆ†é…æ–¹æ¡ˆ
            'inference_target_status': inference_target_status  # é›†æˆæ¨ç†ç›®æ ‡çŠ¶æ€
        }
    
    def _process_evaluation_results(self, results):
        """å¤„ç†è¯„ä¼°ç»“æœ"""
        if results is None:
            print("è¯„ä¼°å¤±è´¥ï¼Œæ— æœ‰æ•ˆç»“æœ")
            return
        
        self.evaluation_stats['scenario_results'].append(results)
        self.evaluation_stats['average_completion_rate'] = results['completion_rate']
        
        # è®¡ç®—æ•ˆç‡ï¼ˆå¥–åŠ±/æ­¥æ•°ï¼‰
        efficiency = results['total_reward'] / max(results['step_count'], 1)
        self.evaluation_stats['average_efficiency'] = efficiency
        
        print(f"\nè¯„ä¼°ç»“æœ:"
            f"  æ€»å¥–åŠ±: {results['total_reward']:.2f}"
            f"  æ»¡è¶³ç‡: {results['completion_rate']:.3f}"
            f"  æ­¥æ•°: {results['step_count']}"
            f"  æ•ˆç‡: {efficiency:.2f}")
        
        if 'ensemble_size' in results:
            print(f"  é›†æˆè§„æ¨¡: {results['ensemble_size']}")
    



def start_evaluation(config: Config, model_paths: Union[str, List[str]], scenario_name: str = "small"):
    """
    è¯„ä¼°å…¥å£å‡½æ•°
    
    Args:
        config (Config): é…ç½®å¯¹è±¡
        model_paths (Union[str, List[str]]): æ¨¡å‹è·¯å¾„
        scenario_name (str): åœºæ™¯åç§°
    """
    evaluator = ModelEvaluator(config)
    evaluator.start_evaluation(model_paths, scenario_name)


# =============================================================================
# æµ‹è¯•å‡½æ•° - éªŒè¯é‡æ„åçš„æ•°æ®ä¸€è‡´æ€§
# =============================================================================

def test_data_isolation():
    """
    æµ‹è¯•æ•°æ®éš”ç¦»åŠŸèƒ½ï¼ŒéªŒè¯æ·±æ‹·è´é˜²æ­¢æ•°æ®æ±¡æŸ“
    
    Returns:
        bool: æµ‹è¯•æ˜¯å¦é€šè¿‡
    """
    print("=" * 60)
    print("æ‰§è¡Œæ•°æ®éš”ç¦»æµ‹è¯•")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæµ‹è¯•é…ç½®å’Œè¯„ä¼°å™¨
        from config import Config
        config = Config()
        evaluator = ModelEvaluator(config)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_final_plan = {
            0: [
                {
                    'target_id': 1,
                    'resource_cost': np.array([10.0, 5.0]),
                    'arrival_time': 2.5,
                    'distance': 100.0,
                    'step': 1,
                    'is_sync_feasible': True
                }
            ],
            1: [
                {
                    'target_id': 2,
                    'resource_cost': np.array([8.0, 12.0]),
                    'arrival_time': 3.0,
                    'distance': 120.0,
                    'step': 1,
                    'is_sync_feasible': True
                }
            ]
        }
        
        # åˆ›å»ºæµ‹è¯• UAV å’Œç›®æ ‡
        from entities import UAV, Target
        test_uavs = [
            UAV(0, np.array([0, 0]), 0.0, np.array([20.0, 15.0]), 1000.0, (10.0, 30.0), 15.0),
            UAV(1, np.array([10, 10]), 0.0, np.array([15.0, 20.0]), 1000.0, (10.0, 30.0), 15.0)
        ]
        test_targets = [
            Target(1, np.array([50, 50]), np.array([10.0, 5.0]), 100.0),
            Target(2, np.array([80, 80]), np.array([8.0, 12.0]), 120.0)
        ]
        
        # ä¿å­˜åŸå§‹æ•°æ®çš„å‰¯æœ¬ç”¨äºæ¯”è¾ƒ
        original_plan_copy = copy.deepcopy(test_final_plan)
        
        # è°ƒç”¨å®‰å…¨è¯„ä¼°å‡½æ•°
        print("è°ƒç”¨ _safe_evaluate_plan å‡½æ•°...")
        evaluation_metrics = evaluator._safe_evaluate_plan(
            test_final_plan, test_uavs, test_targets
        )
        
        # éªŒè¯åŸå§‹æ•°æ®æœªè¢«ä¿®æ”¹ - ä½¿ç”¨æ·±åº¦æ¯”è¾ƒ
        def deep_compare_plans(plan1, plan2):
            """æ·±åº¦æ¯”è¾ƒä¸¤ä¸ª final_plan å¯¹è±¡"""
            if set(plan1.keys()) != set(plan2.keys()):
                return False
            
            for uav_id in plan1.keys():
                tasks1 = plan1[uav_id]
                tasks2 = plan2[uav_id]
                
                if len(tasks1) != len(tasks2):
                    return False
                
                for i, (task1, task2) in enumerate(zip(tasks1, tasks2)):
                    # æ¯”è¾ƒåŸºæœ¬å­—æ®µ
                    if task1.get('target_id') != task2.get('target_id'):
                        return False
                    if task1.get('step') != task2.get('step'):
                        return False
                    
                    # æ¯”è¾ƒ numpy æ•°ç»„
                    rc1 = task1.get('resource_cost')
                    rc2 = task2.get('resource_cost')
                    if rc1 is not None and rc2 is not None:
                        if not np.array_equal(rc1, rc2):
                            return False
                    elif rc1 != rc2:  # ä¸€ä¸ªæ˜¯ Noneï¼Œå¦ä¸€ä¸ªä¸æ˜¯
                        return False
            
            return True
        
        plan_unchanged = deep_compare_plans(test_final_plan, original_plan_copy)
        
        if plan_unchanged:
            print("âœ… æµ‹è¯•é€šè¿‡: åŸå§‹ final_plan æ•°æ®æœªè¢«ä¿®æ”¹")
            print(f"âœ… è¯„ä¼°æŒ‡æ ‡æˆåŠŸç”Ÿæˆ: {list(evaluation_metrics.keys())}")
            return True
        else:
            print("âŒ æµ‹è¯•å¤±è´¥: åŸå§‹ final_plan æ•°æ®è¢«ä¿®æ”¹")
            print(f"åŸå§‹æ•°æ®: {original_plan_copy}")
            print(f"ä¿®æ”¹åæ•°æ®: {test_final_plan}")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_visualization_consistency():
    """
    æµ‹è¯•å¯è§†åŒ–ä¸€è‡´æ€§ï¼ŒéªŒè¯é‡æ„å‰åè¾“å‡ºçš„å…³é”®æŒ‡æ ‡ä¸€è‡´
    
    Returns:
        bool: æµ‹è¯•æ˜¯å¦é€šè¿‡
    """
    print("=" * 60)
    print("æ‰§è¡Œå¯è§†åŒ–ä¸€è‡´æ€§æµ‹è¯•")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæµ‹è¯•é…ç½®
        from config import Config
        config = Config()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_final_plan = {
            0: [
                {
                    'target_id': 1,
                    'resource_cost': np.array([10.0, 5.0]),
                    'arrival_time': 2.5,
                    'distance': 100.0,
                    'step': 1,
                    'is_sync_feasible': True
                }
            ]
        }
        
        from entities import UAV, Target
        test_uavs = [UAV(0, np.array([0, 0]), 0.0, np.array([20.0, 15.0]), 1000.0, (10.0, 30.0), 15.0)]
        test_targets = [Target(1, np.array([50, 50]), np.array([10.0, 5.0]), 100.0)]
        test_obstacles = []
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = PlanVisualizer(config)
        
        # æµ‹è¯•å¯è§†åŒ–åŠŸèƒ½ï¼ˆä¸ä¿å­˜æ–‡ä»¶ï¼ŒåªéªŒè¯æ•°æ®å¤„ç†ï¼‰
        print("æµ‹è¯•å¯è§†åŒ–æ•°æ®å¤„ç†...")
        
        # éªŒè¯ç›®æ ‡åä½œè¯¦æƒ…è®¡ç®—
        target_collaborators_details = defaultdict(list)
        for uav_id, tasks in test_final_plan.items():
            for task in sorted(tasks, key=lambda x: x.get('step', 0)):
                target_id = task['target_id']
                if 'resource_cost' in task and task['resource_cost'] is not None:
                    resource_cost = task['resource_cost']
                    target_collaborators_details[target_id].append({
                        'uav_id': uav_id, 
                        'arrival_time': task.get('arrival_time', 0), 
                        'resource_cost': resource_cost
                    })
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        if len(target_collaborators_details) > 0:
            print("âœ… æµ‹è¯•é€šè¿‡: ç›®æ ‡åä½œè¯¦æƒ…è®¡ç®—æ­£å¸¸")
            
            # éªŒè¯èµ„æºè´¡çŒ®è®¡ç®—
            all_resource_costs = [d['resource_cost'] for details in target_collaborators_details.values() for d in details]
            if len(all_resource_costs) > 0:
                total_contribution = np.sum(all_resource_costs, axis=0)
                print(f"âœ… æµ‹è¯•é€šè¿‡: æ€»è´¡çŒ®è®¡ç®—æ­£å¸¸ {total_contribution}")
                return True
            else:
                print("âŒ æµ‹è¯•å¤±è´¥: æ— æ³•è®¡ç®—æ€»è´¡çŒ®")
                return False
        else:
            print("âŒ æµ‹è¯•å¤±è´¥: ç›®æ ‡åä½œè¯¦æƒ…ä¸ºç©º")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_all_tests():
    """
    è¿è¡Œæ‰€æœ‰æµ‹è¯•
    
    Returns:
        bool: æ‰€æœ‰æµ‹è¯•æ˜¯å¦é€šè¿‡
    """
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ evaluator.py é‡æ„éªŒè¯æµ‹è¯•")
    print("=" * 80)
    
    tests = [
        ("æ•°æ®éš”ç¦»æµ‹è¯•", test_data_isolation),
        ("å¯è§†åŒ–ä¸€è‡´æ€§æµ‹è¯•", test_visualization_consistency)
    ]
    
    passed_tests = 0
    total_tests = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ“‹ æ‰§è¡Œæµ‹è¯•: {test_name}")
        try:
            if test_func():
                passed_tests += 1
                print(f"âœ… {test_name} é€šè¿‡")
            else:
                print(f"âŒ {test_name} å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} æ‰§è¡Œå¼‚å¸¸: {e}")
    
    print("\n" + "=" * 80)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed_tests}/{total_tests} é€šè¿‡")
    
    if passed_tests == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é‡æ„æˆåŠŸå®Œæˆã€‚")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥ã€‚")
        return False


if __name__ == "__main__":
    # å½“ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶ï¼Œæ‰§è¡Œæµ‹è¯•
    run_all_tests()